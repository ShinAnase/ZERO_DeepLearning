{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import Vol6Utl as utl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key]*grads[key]\n",
    "            params[key] -= self.lr * grads[key]/(np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight_init_activation_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYGUlEQVR4nO3dfbBcdX3H8feHhAcLlASJKSaRixLBWMvTNcHxoWg0CWANnUEmVOGWiZNWwUqnnRKcTqE8WJypRRmVNiWRAApkQCUFKr0ToY4OTxdBHsVcIWkSCblwk/AkYPDbP85vyZK79+5u7t7dvfv7vGZ29uzv/M7Z3/lm72fPnnN2o4jAzMzysEerB2BmZs3j0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy0hWoS9pnaSPt3oc7cZ1Gco1GUpSSDqs1eNoN+OtLuM+9CWdLalP0quSrmr1eNqBpL0lLZe0XtILkh6UdEKrx9Vqkq6V9LSk5yX9StLnWj2mdiFppqRXJF3b6rG0A0l3pnq8mG5PtHpMjTLuQx/4DXAxsKLVA6lE0sQWPO1EYAPwp8ABwD8CqyR1tWAsFbWoLv8CdEXEHwKfAi6WdGwLxlFRi2pS8i3gvhY+f0WSJrTw6c+OiP3S7fAWjmOI0dRl3Id+RHw/In4IPFfPcpJmS7pL0ra09/dNSXuled+S9LVd+q+W9Ldp+u2SbpI0IOkpSX9T1u8CSTemvcrngb8c7TbWKyJeiogLImJdRPw+Im4BngKqBlyH1+XRiHi19DDd3lVtuU6uSRrHImAbsKaOZU6S9ED61LRB0gVl826V9MVd+j8k6c/T9BGSeiUNSnpC0qll/a6SdIWk2yS9BHx0lJvXVOOiLhHRETeKvf2rqvRZB3w8TR8LHEexV9wFPA6ck+bNpvgEsUd6fBDwMjCV4o3yfuCfgL2AdwJPAvNT3wuA3wEnp75vaYPaTAVeAY7IvS7At9OYA/g5sF/ONQH+EPgVMD2N59oR+gZwWJo+HnhfGvefAM8AJ6d5pwL3lC13JMVO2V7AvhSfQs9M9TwaeBaYlfpeBWwHPpjWvU+LXid3AgNpbD8Dju+Uuoz7Pf3dFRH3R8TdEbEjItYB/0FxOISIuJeiwHNT90XAnRHxDPB+YEpEXBgRr0XEk8B/pj4ld0XED6PYy/5ts7apEkl7At8FVkbEL6v17/S6RMQXgP2BDwPfB14deYmOr8lFwPKI2FjPQhFxZ0Q8nMb9EHAdqSbAauDdkmamx6cDN0TEa8AngXUR8Z1UzweAm4BPl63+5oj4WVr3K6PZuFE4l+JNehqwDPgvSVU/FY6HunRs6Ev677KTMJ+pMP/dkm6RtDl9tP4KxV5ayUrgs2n6s8A1afoQ4O3po/42SduAL1Ps2ZVsaPT27A5Je1CM+zXg7NSWfV0i4vWI+CnF3u3nc62JpKOAjwOXVZj3aFlNPlxh/hxJd6TDVtuBvybVJAXSDcBn02vwNN5ckzm71OQzwB+Vrb7lr5OIuCciXoiIVyNiJcXe/omdUJdWnjgaUxFR7WqVK4AHgNMi4gVJ5wCnlM2/FnhE0pHAe4AfpvYNwFMRMZPhtfynSyUJWE4RMCdGxO/AddnFROBdGdfkeIrDVf9XvFzYD5ggaVZEvLfKst8DvgmcEBGvSPo6Q98IrwF+CrwcEXel9g3A/0bEJ0ZYd7u9TqAYkzqhLuN+T1/SREn7ABMoXrD7qLarIPYHngdelHQE8Pnymenj7n0U/0A3lX30vhd4QdK5kt4iaYKkP5b0/oZtVGNcQRFAf1bnYYOOrIukt0laJGm/NLb5FHtatZy87MiaUBy2eBdwVLr9O3ArML+GZfcHBlOwzQb+onxmCrPfA19j594swC0UhzhOl7Rnur1f0ntGuzGNImmSpPmlLEmf/j4C/KiGxdu+LuM+9CkuR/wtsJTio/VvU1s1f0/xD/ICxXHWGyr0WUlxUuaNf5yIeJ3i+NtRFFfEPAtcSXFpZFuQdAjwVxRj3DzSoYsKOrUuQRHWG4GtwL9SnIxdXcOyHVmTiHg5IjaXbsCLwCsRMVDD4l8ALpT0AsWJ6lUV+lxNUZM3rv2PiBeAeRTnNX4DbAa+Cuw9qo1prD0pLgwpncj9IsXJ2F/VsGzb10UR7fhJqj1I+gjFP8wh4UK9wXUZyjUZStIZwJKI+FCrx9JOWl2XTtjTHxMqrnr5EnCl/4h3cl2Gck2GkvQHFHu9y1o9lnbSDnWpGvqSDlfxNf7S7XlJ50g6UMUXCdam+8mpvyRdLqlfxRcPjilbV0/qv1ZSz1hu2Gik42jbgIOBr7d0MG3EdRnKNRkqnS8ZoLhG/XstHk7baJe61HV4R8VXfzcBc4CzKE5YXCppKTA5Is6VdCLFMbATU79vRMQcSQcCfUA3xfHV+4FjI2JrQ7fIzMyGVe/hnbnAryNiPbCQ4uQV6f7kNL0QuDoKdwOTJB1McUVAb0QMpqDvBRaMdgPMzKx29V6nv4jiG2YAUyPi6TS9mZ1fOJnGm79EsDG1Ddf+JpKWAEsA9t1332OPOOIIAB7etB2A901riwsfGur+++9/NiKm1Nr/oIMOiq6uLtekTA41gfrqUqoJ+O+nxDWpI/RV/MDUp4Dzdp0XESGpISewImIZ6SRHd3d39PX1AdC19FYA+i49qRFP01Ykra+nf1dXF319fa5JmRxqAvXVpVQT8N9PiWtS3+GdE4Cfp98UAXgmHbYh3W9J7ZuAGWXLTU9tw7WbmVmT1BP6p7Hz0A4UPx5UugKnB7i5rP2MdBXPccD2dBjodmCepMnpSp95qc3MzJqkpsM7kvYFPkHxLc+SSyn+Y47FwHqKnw0FuI3iyp1+ip+YPRMgIgYlXcTO/6jhwogYHPUWmJlZzWoK/Yh4CXjrLm3PsfPnZMvbg+JyzkrrWUGb/g9XZmY58Ddyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tITaEvaZKkGyX9UtLjkj4g6UBJvZLWpvvJqa8kXS6pX9JDko4pW09P6r9WUs9YbZSZmVVW657+N4AfRcQRwJHA48BSYE1EzATWpMcAJwAz020JcAWApAOB84E5wGzg/NIbhZmZNUfV0Jd0APARYDlARLwWEduAhcDK1G0lcHKaXghcHYW7gUmSDgbmA70RMRgRW4FeYEEDt8XMzKqoZU//UGAA+I6kByRdKWlfYGpEPJ36bAampulpwIay5TemtuHa30TSEkl9kvoGBgbq2xozMxtRLaE/ETgGuCIijgZeYuehHAAiIoBoxIAiYllEdEdE95QpUxqxSjMzS2oJ/Y3Axoi4Jz2+keJN4Jl02IZ0vyXN3wTMKFt+emobrt3MzJqkauhHxGZgg6TDU9Nc4DFgNVC6AqcHuDlNrwbOSFfxHAdsT4eBbgfmSZqcTuDOS21mZtYkE2vs90Xgu5L2Ap4EzqR4w1glaTGwHjg19b0NOBHoB15OfYmIQUkXAfelfhdGxGBDtsLMzGpSU+hHxINAd4VZcyv0DeCsYdazAlhRx/jMzKyB/I1cM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDJSU+hLWifpYUkPSupLbQdK6pW0Nt1PTu2SdLmkfkkPSTqmbD09qf9aST1js0lmZjacevb0PxoRR0VEd3q8FFgTETOBNekxwAnAzHRbAlwBxZsEcD4wB5gNnF96ozAzs+YYzeGdhcDKNL0SOLms/eoo3A1MknQwMB/ojYjBiNgK9AILRvH8ZmZWp1pDP4D/kXS/pCWpbWpEPJ2mNwNT0/Q0YEPZshtT23DtbyJpiaQ+SX0DAwM1Ds/MzGoxscZ+H4qITZLeBvRK+mX5zIgISdGIAUXEMmAZQHd3d0PWaWZmhZr29CNiU7rfAvyA4pj8M+mwDel+S+q+CZhRtvj01DZcu5mZNUnV0Je0r6T9S9PAPOARYDVQugKnB7g5Ta8GzkhX8RwHbE+HgW4H5kmanE7gzkttZmbWJLUc3pkK/EBSqf/3IuJHku4DVklaDKwHTk39bwNOBPqBl4EzASJiUNJFwH2p34URMdiwLTEzs6qqhn5EPAkcWaH9OWBuhfYAzhpmXSuAFfUP08zMGsHfyDUzy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIzWHvqQJkh6QdEt6fKikeyT1S7pB0l6pfe/0uD/N7ypbx3mp/QlJ8xu+NWZmNqJ69vS/BDxe9virwGURcRiwFVic2hcDW1P7ZakfkmYBi4D3AguAb0uaMLrhm5lZPWoKfUnTgZOAK9NjAR8DbkxdVgInp+mF6TFp/tzUfyFwfUS8GhFPAf3A7AZsg5mZ1ajWPf2vA/8A/D49fiuwLSJ2pMcbgWlpehqwASDN3576v9FeYRkzM2uCqqEv6ZPAloi4vwnjQdISSX2S+gYGBprxlGZm2ahlT/+DwKckrQOupzis8w1gkqSJqc90YFOa3gTMAEjzDwCeK2+vsMwbImJZRHRHRPeUKVPq3iAzMxte1dCPiPMiYnpEdFGciP1xRHwGuAM4JXXrAW5O06vTY9L8H0dEpPZF6eqeQ4GZwL0N2xIzM6tqYvUuwzoXuF7SxcADwPLUvhy4RlI/MEjxRkFEPCppFfAYsAM4KyJeH8Xzm5lZneoK/Yi4E7gzTT9JhatvIuIV4NPDLH8JcEm9gzQzs8bwN3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy0jV0Je0j6R7Jf1C0qOS/jm1HyrpHkn9km6QtFdq3zs97k/zu8rWdV5qf0LS/DHbKjMzq6iWPf1XgY9FxJHAUcACSccBXwUui4jDgK3A4tR/MbA1tV+W+iFpFrAIeC+wAPi2pAkN3BYzM6uiauhH4cX0cM90C+BjwI2pfSVwcppemB6T5s+VpNR+fUS8GhFPAf3A7EZshJmZ1aamY/qSJkh6ENgC9AK/BrZFxI7UZSMwLU1PAzYApPnbgbeWt1dYxszMmqCm0I+I1yPiKGA6xd75EWM1IElLJPVJ6hsYGBirpzEzy1JdV+9ExDbgDuADwCRJE9Os6cCmNL0JmAGQ5h8APFfeXmGZ8udYFhHdEdE9ZcqUeoZnZmZV1HL1zhRJk9L0W4BPAI9ThP8pqVsPcHOaXp0ek+b/OCIitS9KV/ccCswE7m3QdpiZWQ0mVu/CwcDKdKXNHsCqiLhF0mPA9ZIuBh4Alqf+y4FrJPUDgxRX7BARj0paBTwG7ADOiojXG7s5ZmY2kqqhHxEPAUdXaH+SClffRMQrwKeHWdclwCX1D9PMzBrB38g1M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjFQNfUkzJN0h6TFJj0r6Umo/UFKvpLXpfnJql6TLJfVLekjSMWXr6kn910rqGbvNMjOzSmrZ098B/F1EzAKOA86SNAtYCqyJiJnAmvQY4ARgZrotAa6A4k0COB+YA8wGzi+9UZiZWXNUDf2IeDoifp6mXwAeB6YBC4GVqdtK4OQ0vRC4Ogp3A5MkHQzMB3ojYjAitgK9wIJGboyZmY2srmP6krqAo4F7gKkR8XSatRmYmqanARvKFtuY2oZr3/U5lkjqk9Q3MDBQz/DMzKyKmkNf0n7ATcA5EfF8+byICCAaMaCIWBYR3RHRPWXKlEas0szMkppCX9KeFIH/3Yj4fmp+Jh22Id1vSe2bgBlli09PbcO1m5lZk9Ry9Y6A5cDjEfFvZbNWA6UrcHqAm8vaz0hX8RwHbE+HgW4H5kmanE7gzkttZmbWJBNr6PNB4HTgYUkPprYvA5cCqyQtBtYDp6Z5twEnAv3Ay8CZABExKOki4L7U78KIGGzERpiZWW2qhn5E/BTQMLPnVugfwFnDrGsFsKKeAZqZWeP4G7lmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZaRq6EtaIWmLpEfK2g6U1CtpbbqfnNol6XJJ/ZIeknRM2TI9qf9aST1jszlmo9O19Fa6lt7a6mE0RU7bajvVsqd/FbBgl7alwJqImAmsSY8BTgBmptsS4Aoo3iSA84E5wGzg/NIbhdlYqiXYRppfad54D8t6xj+et9Mqm1itQ0T8RFLXLs0LgePT9ErgTuDc1H51RARwt6RJkg5OfXsjYhBAUi/FG8l1o98Es+q6lt7KuktPemO60vzhHtcSfKU+pecYrzplO2x4VUN/GFMj4uk0vRmYmqanARvK+m1MbcO1DyFpCcWnBN7xjncMmV/+B+gX5puVB1ut/aEz61hLsOeo1rrU0rbu0pM6+jXUqXY39N8QESEpGjGYtL5lwDKA7u7uEddby4uw3jeJ8fgidpi1Tg61H24bO23bR/o0OJ7yoJrdDf1nJB0cEU+nwzdbUvsmYEZZv+mpbRM7DweV2u/czeeuSS3HaTvpH7JkpG3r5O1uhWp7w7sGSHndOy1UKu1sjZdtqvfNa3d3LNvl7293Q3810ANcmu5vLms/W9L1FCdtt6c3htuBr5SdvJ0HnLf7w65sNCfsaunb6n+setRzcrJaXUYKLxvecHXOpX7j8Y1tpE819RwpKCk/+lDrc5WWGytVQ1/SdRR76QdJ2khxFc6lwCpJi4H1wKmp+23AiUA/8DJwJkBEDEq6CLgv9buwdFK3lXb3Hb5kPLyIG6HTPsa3Wq07J+Px9VXrSe9O2LZ6TvDXu1x5v0bXqpard04bZtbcCn0DOGuY9awAVtQ1unFoPP/B1mq8fwpqRyOFQ6fUdqQrojplGxul2tVjo6nXqE/k5sxXEo2s00LLxt54/RTQKrvz5unQb5DdPU7eKXK6lt0az58C6jOaQ64OfRtzPidgo1G+s+Adh9Fz6FvT5XI9tFk7cuhbS3jv3+rl10xj+KeVzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy0vTQl7RA0hOS+iUtbfbzm5nlrKmhL2kC8C3gBGAWcJqkWc0cg5lZzpq9pz8b6I+IJyPiNeB6YGGTx2Bmli1FRPOeTDoFWBARn0uPTwfmRMTZZX2WAEvSw8OBJ9L0QcCzTRvs2CvfnkMiYkqtC0oaANbTeTWBndvkmuy0W6+Vsprsuo5O4JpUVvXvZ2Jzx1NdRCwDlu3aLqkvIrpbMKQxMZrtKf1jdlpNYPe3yTUZqvyPvtPq4ppUVss2NfvwziZgRtnj6anNzMyaoNmhfx8wU9KhkvYCFgGrmzwGM7NsNfXwTkTskHQ2cDswAVgREY/WuPiQQz7jXCO2p9NqAqPfJtdk7NbRTlyTyqpuU1NP5JqZWWv5G7lmZhlx6JuZZaTtQ7/TfrZB0gpJWyQ9Msr1uC5D1+GaDF2Ha1J5PR1Tl7prEhFte6M42ftr4J3AXsAvgFmtHtcot+kjwDHAI65L4+rimrgmudal3pq0+55+x/1sQ0T8BBgc5Wpcl6Fck6Fck8o6qi711qTdQ38asKHs8cbUljvXZSjXZCjXpLKs69LuoW9mZg3U7qHvn22ozHUZyjUZyjWpLOu6tHvo+2cbKnNdhnJNhnJNKsu6Lm0d+hGxAyj9bMPjwKqo/Wcb2pKk64C7gMMlbZS0uN51uC5DuSZDuSaVdVpd6q2Jf4bBzCwjbb2nb2ZmjeXQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwj/w+iObb7PVSjNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "    \n",
    "input_data = np.random.randn(1000, 100)  # 1000個のデータ\n",
    "node_num = 100  # 各隠れ層のノード（ニューロン）の数\n",
    "hidden_layer_size = 5  # 隠れ層が5層\n",
    "activations = {}  # ここにアクティベーションの結果を格納する\n",
    "\n",
    "x = input_data\n",
    "\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "\n",
    "    # 初期値の値をいろいろ変えて実験しよう！\n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "\n",
    "\n",
    "    a = np.dot(x, w)\n",
    "\n",
    "\n",
    "    # 活性化関数の種類も変えて実験しよう！\n",
    "    #z = sigmoid(a)\n",
    "    z = ReLU(a)\n",
    "    #z = tanh(a)\n",
    "\n",
    "    activations[i] = z\n",
    "\n",
    "# ヒストグラムを描画\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    if i != 0: plt.yticks([], [])\n",
    "    # plt.xlim(0.1, 1)\n",
    "    plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTによる比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DLfromscratch.dataset.mnist import load_mnist\n",
    "\n",
    "def smooth_curve(x):\n",
    "    \"\"\"損失関数のグラフを滑らかにするために用いる\n",
    "\n",
    "    参考：http://glowingpython.blogspot.jp/2012/02/convolution-with-numpy.html\n",
    "    \"\"\"\n",
    "    window_len = 11\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
    "    w = np.kaiser(window_len, 2)\n",
    "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
    "    return y[5:len(y)-5]\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from DLfromscratch.common.layers import *\n",
    "from DLfromscratch.common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class MultiLayerNet:\n",
    "    \"\"\"全結合による多層ニューラルネットワーク\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    weight_decay_lambda : Weight Decay（L2ノルム）の強さ\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size_list, output_size,\n",
    "                 activation='relu', weight_init_std='relu', weight_decay_lambda=0):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "        self.weight_decay_lambda = weight_decay_lambda\n",
    "        self.params = {}\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.__init_weight(weight_init_std)\n",
    "\n",
    "        # レイヤの生成\n",
    "        activation_layer = {'sigmoid': Sigmoid, 'relu': Relu}\n",
    "        self.layers = OrderedDict()\n",
    "        for idx in range(1, self.hidden_layer_num+1):\n",
    "            self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
    "                                                      self.params['b' + str(idx)])\n",
    "            self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\n",
    "\n",
    "        idx = self.hidden_layer_num + 1\n",
    "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
    "            self.params['b' + str(idx)])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def __init_weight(self, weight_init_std):\n",
    "        \"\"\"重みの初期値設定\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "            'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "            'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "        \"\"\"\n",
    "        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "        for idx in range(1, len(all_size_list)):\n",
    "            scale = weight_init_std\n",
    "            if str(weight_init_std).lower() in ('relu', 'he'):\n",
    "                scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLUを使う場合に推奨される初期値\n",
    "            elif str(weight_init_std).lower() in ('sigmoid', 'xavier'):\n",
    "                scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoidを使う場合に推奨される初期値\n",
    "\n",
    "            self.params['W' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])\n",
    "            self.params['b' + str(idx)] = np.zeros(all_size_list[idx])\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        損失関数の値\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "\n",
    "        weight_decay = 0\n",
    "        for idx in range(1, self.hidden_layer_num + 2):\n",
    "            W = self.params['W' + str(idx)]\n",
    "            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W ** 2)\n",
    "\n",
    "        return self.last_layer.forward(y, t) + weight_decay\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in range(1, self.hidden_layer_num+2):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_W, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_W, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        for idx in range(1, self.hidden_layer_num+2):\n",
    "            grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW + self.weight_decay_lambda * self.layers['Affine' + str(idx)].W\n",
    "            grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DLfromscratch.dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True) #Mnistダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 過学習を再現するために、学習データを削減\n",
    "#x_train = x_train[:300]\n",
    "#t_train = t_train[:300]\n",
    "#\n",
    "## weight decay（荷重減衰）の設定 =======================\n",
    "#weight_decay_lambda = 0 # weight decayを使用しない場合\n",
    "##weight_decay_lambda = 0.1\n",
    "## ====================================================\n",
    "#\n",
    "#network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
    "#                        weight_decay_lambda=weight_decay_lambda)\n",
    "#optimizer = SGD(lr=0.01)\n",
    "#\n",
    "#max_epochs = 201\n",
    "#train_size = x_train.shape[0]\n",
    "#batch_size = 100\n",
    "#\n",
    "#train_loss_list = []\n",
    "#train_acc_list = []\n",
    "#test_acc_list = []\n",
    "#\n",
    "#iter_per_epoch = max(train_size / batch_size, 1)\n",
    "#epoch_cnt = 0\n",
    "#\n",
    "#for i in range(1000000000):\n",
    "#    batch_mask = np.random.choice(train_size, batch_size)\n",
    "#    x_batch = x_train[batch_mask]\n",
    "#    t_batch = t_train[batch_mask]\n",
    "#\n",
    "#    grads = network.gradient(x_batch, t_batch)\n",
    "#    optimizer.update(network.params, grads)\n",
    "#    \n",
    "#    if i % iter_per_epoch == 0:\n",
    "#        train_acc = network.accuracy(x_train, t_train)\n",
    "#        test_acc = network.accuracy(x_test, t_test)\n",
    "#        train_acc_list.append(train_acc)\n",
    "#        test_acc_list.append(test_acc)\n",
    "#\n",
    "#        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "#\n",
    "#        epoch_cnt += 1\n",
    "#        if epoch_cnt >= max_epochs:\n",
    "#            break\n",
    "#\n",
    "## 3.グラフの描画==========\n",
    "#markers = {'train': 'o', 'test': 's'}\n",
    "#x = np.arange(max_epochs)\n",
    "#plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "#plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "#plt.xlabel(\"epochs\")\n",
    "#plt.ylabel(\"accuracy\")\n",
    "#plt.ylim(0, 1.0)\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio #入力と同じサイズのマスクのarrayを生成\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1. - self.dropout_ratio)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout*self.mask #maskでfalseとなっている要素は0に置き換わる(Reluと同じ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.random.rand(*(2,3))>0.5\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3],\n",
       "       [0, 5, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=np.array([[1,2,3],\n",
    "             [4,5,6]])\n",
    "tmp*mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution レイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x, train_flg=True):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T #フィルタ展開\n",
    "        \n",
    "        #print(f\"col.shape:{col.shape}\")\n",
    "        #print(f\"col_W.shape:{col_W.shape}\")\n",
    "        \n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        #フィルタ側\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        #イメージ側\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pool_h - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pool_w - FW) / self.stride)\n",
    "        \n",
    "        #展開(１)\n",
    "        col = imcol(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        #最大値(２)\n",
    "        arg_max = np.argmax(col, axis=1)#一番大きい値の位置を覚えておく\n",
    "        out = np.max(col, axis=1)\n",
    "        #整形(3)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #poolingの場合学習パラメータは存在しない。\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        #覚えておいたMAXの位置のみにdoutを返す。(他は0のまま)\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim={1, 28, 28},\n",
    "                conv_param={'filter_num':30, 'filter_size':5, \n",
    "                           'pad':0, 'stride':1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad)/filter_stride + 1\n",
    "        pool_output_size = int(filter_num*(conv_output_size/2)*(conv_output_size/2))\n",
    "        \n",
    "        #重みパラメータ\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        #レイヤ\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'],\n",
    "                                          self.params['b1'],\n",
    "                                          conv_param['stride'],\n",
    "                                          conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'],\n",
    "                                       self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'],\n",
    "                                       self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        #forward\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        #backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout - layer.backward(dout)\n",
    "        \n",
    "        #設定\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].dW\n",
    "        \n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLfromscratch.common.optimizer import *\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"ニューラルネットの訓練を行うクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, network, x_train, t_train, x_test, t_test,\n",
    "                 epochs=20, mini_batch_size=100,\n",
    "                 optimizer='SGD', optimizer_param={'lr':0.01}, \n",
    "                 evaluate_sample_num_per_epoch=None, verbose=True):\n",
    "        self.network = network\n",
    "        self.verbose = verbose\n",
    "        self.x_train = x_train\n",
    "        self.t_train = t_train\n",
    "        self.x_test = x_test\n",
    "        self.t_test = t_test\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = mini_batch_size\n",
    "        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n",
    "\n",
    "        # optimizer\n",
    "        optimizer_class_dict = {'sgd':SGD, 'momentum':Momentum, 'nesterov':Nesterov,\n",
    "                                'adagrad':AdaGrad, 'rmsprop':RMSprop, 'adam':Adam}\n",
    "        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n",
    "        \n",
    "        self.train_size = x_train.shape[0]\n",
    "        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1)\n",
    "        self.max_iter = int(epochs * self.iter_per_epoch)\n",
    "        self.current_iter = 0\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        self.train_loss_list = []\n",
    "        self.train_acc_list = []\n",
    "        self.test_acc_list = []\n",
    "\n",
    "    def train_step(self):\n",
    "        batch_mask = np.random.choice(self.train_size, self.batch_size)\n",
    "        x_batch = self.x_train[batch_mask]\n",
    "        t_batch = self.t_train[batch_mask]\n",
    "        \n",
    "        grads = self.network.gradient(x_batch, t_batch)\n",
    "        self.optimizer.update(self.network.params, grads)\n",
    "        \n",
    "        loss = self.network.loss(x_batch, t_batch)\n",
    "        self.train_loss_list.append(loss)\n",
    "        if self.verbose: print(\"train loss:\" + str(loss))\n",
    "        \n",
    "        if self.current_iter % self.iter_per_epoch == 0:\n",
    "            self.current_epoch += 1\n",
    "            \n",
    "            x_train_sample, t_train_sample = self.x_train, self.t_train\n",
    "            x_test_sample, t_test_sample = self.x_test, self.t_test\n",
    "            if not self.evaluate_sample_num_per_epoch is None:\n",
    "                t = self.evaluate_sample_num_per_epoch\n",
    "                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n",
    "                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n",
    "                \n",
    "            train_acc = self.network.accuracy(x_train_sample, t_train_sample)\n",
    "            test_acc = self.network.accuracy(x_test_sample, t_test_sample)\n",
    "            self.train_acc_list.append(train_acc)\n",
    "            self.test_acc_list.append(test_acc)\n",
    "\n",
    "            if self.verbose: print(\"=== epoch:\" + str(self.current_epoch) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc) + \" ===\")\n",
    "        self.current_iter += 1\n",
    "\n",
    "    def train(self):\n",
    "        for i in range(self.max_iter):\n",
    "            self.train_step()\n",
    "\n",
    "        test_acc = self.network.accuracy(self.x_test, self.t_test)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"=============== Final Test Accuracy ===============\")\n",
    "            print(\"test acc:\" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.297891461868232\n",
      "=== epoch:1, train acc:0.128, test acc:0.12 ===\n",
      "train loss:2.29461747648177\n",
      "train loss:2.294914527784889\n",
      "train loss:2.286092434396578\n",
      "train loss:2.2807524201633047\n",
      "train loss:2.255168084697051\n",
      "train loss:2.244673551759313\n",
      "train loss:2.2462133658768515\n",
      "train loss:2.2141917442037777\n",
      "train loss:2.202938962958139\n",
      "train loss:2.191116546526192\n",
      "train loss:2.128235657955119\n",
      "train loss:2.071529214522457\n",
      "train loss:2.019848247169938\n",
      "train loss:2.0062143687973357\n",
      "train loss:1.9561035604702104\n",
      "train loss:1.8564286061930746\n",
      "train loss:1.8143170611866666\n",
      "train loss:1.7919334083859888\n",
      "train loss:1.6702845251560579\n",
      "train loss:1.6196877291973386\n",
      "train loss:1.459399065117604\n",
      "train loss:1.465706324289978\n",
      "train loss:1.3851367119492535\n",
      "train loss:1.2502492594497054\n",
      "train loss:1.181093233477177\n",
      "train loss:1.219939055005517\n",
      "train loss:1.0942129691269207\n",
      "train loss:0.9973881291508856\n",
      "train loss:0.8991315089442932\n",
      "train loss:0.9179767581254298\n",
      "train loss:0.8290435285269069\n",
      "train loss:0.9153256641315063\n",
      "train loss:0.7943878382142628\n",
      "train loss:0.7864656590342082\n",
      "train loss:0.7001336616304514\n",
      "train loss:0.6635864604325746\n",
      "train loss:0.7253153088224102\n",
      "train loss:0.7805577720513394\n",
      "train loss:0.6810798105301096\n",
      "train loss:0.5388550002204209\n",
      "train loss:0.6391019999929698\n",
      "train loss:0.5915305795776146\n",
      "train loss:0.5800085727236817\n",
      "train loss:0.8715878890369185\n",
      "train loss:0.5226258191452416\n",
      "train loss:0.5730144449831305\n",
      "train loss:0.4693322336909755\n",
      "train loss:0.5524821094307509\n",
      "train loss:0.5680733273809213\n",
      "train loss:0.6049828075696158\n",
      "train loss:0.6678830044287445\n",
      "train loss:0.5871135604128042\n",
      "train loss:0.5186487580499931\n",
      "train loss:0.5975074377294921\n",
      "train loss:0.629438811200108\n",
      "train loss:0.5129911388156527\n",
      "train loss:0.5112808568296118\n",
      "train loss:0.43062550832385904\n",
      "train loss:0.46285407963341363\n",
      "train loss:0.3968339770351417\n",
      "train loss:0.3528364637517329\n",
      "train loss:0.5420637916611891\n",
      "train loss:0.6301828408225312\n",
      "train loss:0.48915860302990366\n",
      "train loss:0.47311272443836555\n",
      "train loss:0.3436473064815837\n",
      "train loss:0.6189704646487871\n",
      "train loss:0.46758579169099623\n",
      "train loss:0.3369796435828995\n",
      "train loss:0.6890142338028327\n",
      "train loss:0.5571676833436208\n",
      "train loss:0.47957856838285046\n",
      "train loss:0.41360888150375097\n",
      "train loss:0.5966105181267569\n",
      "train loss:0.440402276370806\n",
      "train loss:0.36207411537261985\n",
      "train loss:0.43613993555691577\n",
      "train loss:0.3891313576481514\n",
      "train loss:0.3338311949438094\n",
      "train loss:0.2879216491588649\n",
      "train loss:0.36119949863011713\n",
      "train loss:0.4175105890545735\n",
      "train loss:0.5079784905496804\n",
      "train loss:0.3120686754361011\n",
      "train loss:0.43900767922500433\n",
      "train loss:0.3145258028544547\n",
      "train loss:0.38880474548801236\n",
      "train loss:0.3865035376424279\n",
      "train loss:0.3848617369301454\n",
      "train loss:0.4407395724303852\n",
      "train loss:0.5970520789231553\n",
      "train loss:0.4660406863059167\n",
      "train loss:0.5445434089073692\n",
      "train loss:0.3004064518158869\n",
      "train loss:0.3149323555130025\n",
      "train loss:0.352565524139828\n",
      "train loss:0.3626534551436684\n",
      "train loss:0.44304526679203365\n",
      "train loss:0.3193378334644514\n",
      "train loss:0.2762581648117927\n",
      "train loss:0.37639452350919206\n",
      "train loss:0.34476741843746406\n",
      "train loss:0.5078329369713084\n",
      "train loss:0.5272979760584233\n",
      "train loss:0.1919635348878595\n",
      "train loss:0.44872344072697123\n",
      "train loss:0.3427758830009051\n",
      "train loss:0.3031446864652295\n",
      "train loss:0.3103073531018461\n",
      "train loss:0.30164877045119065\n",
      "train loss:0.3924467849310218\n",
      "train loss:0.33733326682348974\n",
      "train loss:0.29730722730981396\n",
      "train loss:0.3337399441114159\n",
      "train loss:0.23901975913276508\n",
      "train loss:0.4059181292969376\n",
      "train loss:0.30957114644588934\n",
      "train loss:0.356921975663848\n",
      "train loss:0.49430182103306985\n",
      "train loss:0.41851434332441456\n",
      "train loss:0.3338521778716567\n",
      "train loss:0.3059158518101479\n",
      "train loss:0.25938993893852486\n",
      "train loss:0.27991413816607563\n",
      "train loss:0.5899569699916247\n",
      "train loss:0.5441368299074879\n",
      "train loss:0.33778341183303484\n",
      "train loss:0.5242325324654938\n",
      "train loss:0.2767605399275624\n",
      "train loss:0.4697182872399333\n",
      "train loss:0.2518775749973883\n",
      "train loss:0.420928882003737\n",
      "train loss:0.42945412680520756\n",
      "train loss:0.45598681635415844\n",
      "train loss:0.2882553112352904\n",
      "train loss:0.4475508975201633\n",
      "train loss:0.34336599850068367\n",
      "train loss:0.4361925330899269\n",
      "train loss:0.34239153187262156\n",
      "train loss:0.3078566527069499\n",
      "train loss:0.35209951608147305\n",
      "train loss:0.2970776993659697\n",
      "train loss:0.3583985712210074\n",
      "train loss:0.398748576180487\n",
      "train loss:0.3176347072365463\n",
      "train loss:0.3003110066262705\n",
      "train loss:0.34193761303291936\n",
      "train loss:0.2682948648492179\n",
      "train loss:0.2347267846670546\n",
      "train loss:0.2508169689966333\n",
      "train loss:0.35792081708642537\n",
      "train loss:0.44946505133914516\n",
      "train loss:0.3367033178405445\n",
      "train loss:0.4751808243544303\n",
      "train loss:0.22095737415928085\n",
      "train loss:0.29396808253628787\n",
      "train loss:0.24144122075038874\n",
      "train loss:0.1798832824013028\n",
      "train loss:0.2981492201588773\n",
      "train loss:0.28900301382079246\n",
      "train loss:0.245241046548047\n",
      "train loss:0.2920581665703505\n",
      "train loss:0.22774117118357742\n",
      "train loss:0.40612591409960624\n",
      "train loss:0.5076073351083296\n",
      "train loss:0.4780794628411114\n",
      "train loss:0.3234281353801224\n",
      "train loss:0.2987936769447133\n",
      "train loss:0.20096242446882578\n",
      "train loss:0.3338719647406232\n",
      "train loss:0.24234161498351667\n",
      "train loss:0.2345757310244404\n",
      "train loss:0.2806790654115295\n",
      "train loss:0.4729866950636683\n",
      "train loss:0.25894529380486886\n",
      "train loss:0.19856597078320018\n",
      "train loss:0.3509852116161056\n",
      "train loss:0.24807446102924005\n",
      "train loss:0.4013847482545485\n",
      "train loss:0.346838630908771\n",
      "train loss:0.2429647302975063\n",
      "train loss:0.2930027628455056\n",
      "train loss:0.27445389736402026\n",
      "train loss:0.4918197930730059\n",
      "train loss:0.25806326409926983\n",
      "train loss:0.3080424743039655\n",
      "train loss:0.2588204975631119\n",
      "train loss:0.20352843394999437\n",
      "train loss:0.13429356326111733\n",
      "train loss:0.31868443447208306\n",
      "train loss:0.2935145974489439\n",
      "train loss:0.3660419486858187\n",
      "train loss:0.23221540667030788\n",
      "train loss:0.3156069923385267\n",
      "train loss:0.13989988164559863\n",
      "train loss:0.16292670906437934\n",
      "train loss:0.17384693749703284\n",
      "train loss:0.46493786204388315\n",
      "train loss:0.3377830467749084\n",
      "train loss:0.39091693109881936\n",
      "train loss:0.3170776815891257\n",
      "train loss:0.42064563507998676\n",
      "train loss:0.21021588798298768\n",
      "train loss:0.22743928943059438\n",
      "train loss:0.25717420485111336\n",
      "train loss:0.26258326405012855\n",
      "train loss:0.274550134061965\n",
      "train loss:0.5020096202082681\n",
      "train loss:0.28709097275465156\n",
      "train loss:0.16248674450487677\n",
      "train loss:0.18703982592976595\n",
      "train loss:0.31821822100292513\n",
      "train loss:0.2765654150591406\n",
      "train loss:0.2872793665761389\n",
      "train loss:0.29416312102980025\n",
      "train loss:0.2777142127874739\n",
      "train loss:0.1507482265234817\n",
      "train loss:0.28834612289954475\n",
      "train loss:0.28086731265634546\n",
      "train loss:0.17646147889636737\n",
      "train loss:0.36254857450049577\n",
      "train loss:0.34190448224537545\n",
      "train loss:0.2855682466113084\n",
      "train loss:0.2671233445756114\n",
      "train loss:0.256334386581466\n",
      "train loss:0.28708103654582695\n",
      "train loss:0.3389067922836944\n",
      "train loss:0.37562525844930583\n",
      "train loss:0.18589284809109763\n",
      "train loss:0.3541869648346392\n",
      "train loss:0.21386239583267957\n",
      "train loss:0.29399912588176086\n",
      "train loss:0.23448938639168077\n",
      "train loss:0.33956287308025496\n",
      "train loss:0.1666038249999093\n",
      "train loss:0.18164308443581437\n",
      "train loss:0.29044412857750024\n",
      "train loss:0.1485997579448466\n",
      "train loss:0.26895506622237664\n",
      "train loss:0.26199038710175143\n",
      "train loss:0.21429978024130417\n",
      "train loss:0.3151786551083446\n",
      "train loss:0.2299651595372846\n",
      "train loss:0.23382442584201193\n",
      "train loss:0.22038145061003062\n",
      "train loss:0.19798290391759285\n",
      "train loss:0.31780052391364505\n",
      "train loss:0.23971758811457933\n",
      "train loss:0.20842965949264755\n",
      "train loss:0.13263221804577216\n",
      "train loss:0.22904225028731356\n",
      "train loss:0.157781137471402\n",
      "train loss:0.2821713325664327\n",
      "train loss:0.16644542457966854\n",
      "train loss:0.38424082891910044\n",
      "train loss:0.16750044597413008\n",
      "train loss:0.27698385253948404\n",
      "train loss:0.2524010610613482\n",
      "train loss:0.15439033770955168\n",
      "train loss:0.24177288160603255\n",
      "train loss:0.22249131867596306\n",
      "train loss:0.22309197811587686\n",
      "train loss:0.20288575359372335\n",
      "train loss:0.3100360792398424\n",
      "train loss:0.3516461236137811\n",
      "train loss:0.24451877376445252\n",
      "train loss:0.1750896417900092\n",
      "train loss:0.1989516152598325\n",
      "train loss:0.20344983553775944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.24832499613976022\n",
      "train loss:0.2307863407832013\n",
      "train loss:0.11132653213181096\n",
      "train loss:0.41177993334360286\n",
      "train loss:0.2047546284159647\n",
      "train loss:0.25511087105558605\n",
      "train loss:0.23138773082143976\n",
      "train loss:0.24490473338499652\n",
      "train loss:0.1468539033489074\n",
      "train loss:0.21545657231664248\n",
      "train loss:0.1669333538883908\n",
      "train loss:0.37341769740771574\n",
      "train loss:0.35414534416079674\n",
      "train loss:0.12913903368767396\n",
      "train loss:0.22197295161818847\n",
      "train loss:0.21630829512286703\n",
      "train loss:0.20237081076166547\n",
      "train loss:0.2545011700099288\n",
      "train loss:0.19462324295728448\n",
      "train loss:0.13747433526338945\n",
      "train loss:0.26746843803597836\n",
      "train loss:0.1934785849363171\n",
      "train loss:0.18884514048870812\n",
      "train loss:0.16197720967696036\n",
      "train loss:0.2028000228217718\n",
      "train loss:0.13533230647227598\n",
      "train loss:0.29958243291076353\n",
      "train loss:0.16503992941634302\n",
      "train loss:0.3850541090919945\n",
      "train loss:0.22916742519518785\n",
      "train loss:0.13460212949751119\n",
      "train loss:0.17064756770722678\n",
      "train loss:0.2723104471468405\n",
      "train loss:0.17676911736559123\n",
      "train loss:0.19444521262654477\n",
      "train loss:0.16402750687531753\n",
      "train loss:0.1940618473786249\n",
      "train loss:0.37414865639332606\n",
      "train loss:0.23942368524020555\n",
      "train loss:0.15730901205434578\n",
      "train loss:0.24236127993091675\n",
      "train loss:0.11439285919630843\n",
      "train loss:0.22372450176172498\n",
      "train loss:0.19867560014978003\n",
      "train loss:0.1686521621939617\n",
      "train loss:0.36395046231213696\n",
      "train loss:0.31376193293840304\n",
      "train loss:0.31518491942606663\n",
      "train loss:0.232012251142553\n",
      "train loss:0.15823565288900948\n",
      "train loss:0.20002304130033466\n",
      "train loss:0.13333826049657987\n",
      "train loss:0.26460881297494715\n",
      "train loss:0.24547795562502098\n",
      "train loss:0.15925927413224783\n",
      "train loss:0.22505183135965182\n",
      "train loss:0.17762899406685403\n",
      "train loss:0.20552627727486758\n",
      "train loss:0.3445215955965136\n",
      "train loss:0.223267551204653\n",
      "train loss:0.2331060369969472\n",
      "train loss:0.19339980969004011\n",
      "train loss:0.1678524045691671\n",
      "train loss:0.22255445778437644\n",
      "train loss:0.3160742160642561\n",
      "train loss:0.21376333902328237\n",
      "train loss:0.12673004904603785\n",
      "train loss:0.2363307685362686\n",
      "train loss:0.2701309129669499\n",
      "train loss:0.21120357575182092\n",
      "train loss:0.15724597605571602\n",
      "train loss:0.21442805461711525\n",
      "train loss:0.1916323687642781\n",
      "train loss:0.1752559426429215\n",
      "train loss:0.2553756105643256\n",
      "train loss:0.16232019929124072\n",
      "train loss:0.18519723170707966\n",
      "train loss:0.2488196886064479\n",
      "train loss:0.13834850257156328\n",
      "train loss:0.22876607055275805\n",
      "train loss:0.15565732609389094\n",
      "train loss:0.11332672406693145\n",
      "train loss:0.21984145978903702\n",
      "train loss:0.274138450982073\n",
      "train loss:0.2103362602702889\n",
      "train loss:0.11676983018028174\n",
      "train loss:0.11244016624763312\n",
      "train loss:0.24883292767642728\n",
      "train loss:0.11499516680651187\n",
      "train loss:0.20756909226708958\n",
      "train loss:0.12876159931165565\n",
      "train loss:0.1662475616354437\n",
      "train loss:0.2196072243117786\n",
      "train loss:0.3631958893810838\n",
      "train loss:0.1571571829256565\n",
      "train loss:0.09903464457194405\n",
      "train loss:0.12118505011687232\n",
      "train loss:0.2516275362050386\n",
      "train loss:0.12070947481629739\n",
      "train loss:0.2036870444810705\n",
      "train loss:0.2307696004568998\n",
      "train loss:0.24960641335387215\n",
      "train loss:0.1731771161992428\n",
      "train loss:0.33712673827246875\n",
      "train loss:0.22149174722259385\n",
      "train loss:0.120914156653409\n",
      "train loss:0.2623984747364502\n",
      "train loss:0.17786881910359348\n",
      "train loss:0.14902549813726204\n",
      "train loss:0.08893565331640041\n",
      "train loss:0.21169848274430828\n",
      "train loss:0.29118643103716574\n",
      "train loss:0.16669741407543415\n",
      "train loss:0.21116777443846696\n",
      "train loss:0.2823966046648123\n",
      "train loss:0.43428181504304647\n",
      "train loss:0.1935964158224893\n",
      "train loss:0.14678212433519158\n",
      "train loss:0.1708896758868793\n",
      "train loss:0.23042014709915723\n",
      "train loss:0.17530557222158205\n",
      "train loss:0.1131933059181069\n",
      "train loss:0.17334597779701102\n",
      "train loss:0.18096941853943954\n",
      "train loss:0.3453869990872534\n",
      "train loss:0.17033349519305957\n",
      "train loss:0.08620510006271066\n",
      "train loss:0.10961968422295586\n",
      "train loss:0.1557295356533966\n",
      "train loss:0.16351689585297208\n",
      "train loss:0.22585539716912084\n",
      "train loss:0.11122933645582492\n",
      "train loss:0.12291443054585581\n",
      "train loss:0.1633203879089417\n",
      "train loss:0.10686946282041541\n",
      "train loss:0.10623932399676198\n",
      "train loss:0.17914990838188172\n",
      "train loss:0.2103666783606754\n",
      "train loss:0.1814314717198037\n",
      "train loss:0.1383355414445799\n",
      "train loss:0.19475576916978554\n",
      "train loss:0.12292725943947895\n",
      "train loss:0.21212454997814084\n",
      "train loss:0.12467208089665963\n",
      "train loss:0.16994171933920071\n",
      "train loss:0.15412651679930905\n",
      "train loss:0.09250121231419356\n",
      "train loss:0.12375466698583576\n",
      "train loss:0.22838500294107283\n",
      "train loss:0.18444344719398476\n",
      "train loss:0.23166844860519664\n",
      "train loss:0.17025645035815487\n",
      "train loss:0.09179350175892342\n",
      "train loss:0.10322446649581757\n",
      "train loss:0.18519394503528708\n",
      "train loss:0.14485944909585055\n",
      "train loss:0.2633853573155137\n",
      "train loss:0.16458909114939485\n",
      "train loss:0.1910419872416402\n",
      "train loss:0.2077694656791766\n",
      "train loss:0.14128054286042585\n",
      "train loss:0.15537070994229424\n",
      "train loss:0.24962483549346248\n",
      "train loss:0.1405914692665984\n",
      "train loss:0.1355473991429874\n",
      "train loss:0.20351289803643635\n",
      "train loss:0.23587293016327593\n",
      "train loss:0.07853886649653635\n",
      "train loss:0.1953439061650467\n",
      "train loss:0.251111306647319\n",
      "train loss:0.1301655399131758\n",
      "train loss:0.14095170193605214\n",
      "train loss:0.07495486402796829\n",
      "train loss:0.15117742920514388\n",
      "train loss:0.13135122232489058\n",
      "train loss:0.2321115629341791\n",
      "train loss:0.26678406135832544\n",
      "train loss:0.09803263518362022\n",
      "train loss:0.08823899800352701\n",
      "train loss:0.20559628195771396\n",
      "train loss:0.1969799372272626\n",
      "train loss:0.20045492490916714\n",
      "train loss:0.11793493518733637\n",
      "train loss:0.29296190801710337\n",
      "train loss:0.15633884033581322\n",
      "train loss:0.19968163651788537\n",
      "train loss:0.1713524586789234\n",
      "train loss:0.14518346718445702\n",
      "train loss:0.09986307557571107\n",
      "train loss:0.15341163808783811\n",
      "train loss:0.13357433734733493\n",
      "train loss:0.14636847409016185\n",
      "train loss:0.07580695039312951\n",
      "train loss:0.1601976998687781\n",
      "train loss:0.259301092028206\n",
      "train loss:0.19489042133120363\n",
      "train loss:0.1398030289425768\n",
      "train loss:0.06589374730834685\n",
      "train loss:0.2559869148056808\n",
      "train loss:0.1707888731345961\n",
      "train loss:0.25399678265913944\n",
      "train loss:0.06694030862135036\n",
      "train loss:0.21587254818473223\n",
      "train loss:0.1301386469698252\n",
      "train loss:0.23841813354945887\n",
      "train loss:0.12362759789646079\n",
      "train loss:0.13479921500348324\n",
      "train loss:0.13623513364092962\n",
      "train loss:0.16191462581920787\n",
      "train loss:0.23141550755707496\n",
      "train loss:0.27711461752811745\n",
      "train loss:0.10836837071605787\n",
      "train loss:0.18828313186553505\n",
      "train loss:0.08214459837747028\n",
      "train loss:0.07827915608780059\n",
      "train loss:0.10237464239654026\n",
      "train loss:0.14153558471773284\n",
      "train loss:0.1260859066228531\n",
      "train loss:0.1596514770536098\n",
      "train loss:0.10867966218956678\n",
      "train loss:0.11891318365611862\n",
      "train loss:0.07494125197266799\n",
      "train loss:0.0936631325685077\n",
      "train loss:0.13125691186269436\n",
      "train loss:0.10846956808677512\n",
      "train loss:0.16199911130105002\n",
      "train loss:0.12439729042185116\n",
      "train loss:0.178075385397099\n",
      "train loss:0.09675152742256095\n",
      "train loss:0.12919985541491857\n",
      "train loss:0.21893351869215788\n",
      "train loss:0.14413800268643337\n",
      "train loss:0.32556496890761716\n",
      "train loss:0.0911369058695018\n",
      "train loss:0.1595380746996424\n",
      "train loss:0.23267723962339243\n",
      "train loss:0.2364983292711133\n",
      "train loss:0.11864864128215089\n",
      "train loss:0.16712738820482723\n",
      "train loss:0.10396822176372986\n",
      "train loss:0.19462656122015642\n",
      "train loss:0.1468155869230644\n",
      "train loss:0.16759324688879293\n",
      "train loss:0.14441960662801503\n",
      "train loss:0.08938289124612105\n",
      "train loss:0.15256251427881534\n",
      "train loss:0.17757702501208722\n",
      "train loss:0.20151494912615145\n",
      "train loss:0.22145726341657826\n",
      "train loss:0.11895388496685572\n",
      "train loss:0.046485710457550684\n",
      "train loss:0.0559159372592165\n",
      "train loss:0.19059771202823722\n",
      "train loss:0.15527018618123992\n",
      "train loss:0.10785991489085112\n",
      "train loss:0.18437343261599942\n",
      "train loss:0.1812960657674515\n",
      "train loss:0.2348698533726121\n",
      "train loss:0.12170466856703968\n",
      "train loss:0.1997400230401421\n",
      "train loss:0.18789769046905577\n",
      "train loss:0.1175995363473818\n",
      "train loss:0.04715467663366284\n",
      "train loss:0.23142188884105333\n",
      "train loss:0.0993507792365864\n",
      "train loss:0.1388614459011115\n",
      "train loss:0.18652724261544942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2227621519642598\n",
      "train loss:0.21621355803077005\n",
      "train loss:0.10406053018468231\n",
      "train loss:0.07537320085272628\n",
      "train loss:0.09790747321191173\n",
      "train loss:0.07871384131370869\n",
      "train loss:0.17988558267540855\n",
      "train loss:0.11031053931807\n",
      "train loss:0.13160041204336254\n",
      "train loss:0.07998254159602931\n",
      "train loss:0.184534535480861\n",
      "train loss:0.11882397677223393\n",
      "train loss:0.16250449600524905\n",
      "train loss:0.0993206446857713\n",
      "train loss:0.10146690109898224\n",
      "train loss:0.09176371826918933\n",
      "train loss:0.13695399944129136\n",
      "train loss:0.14700137712599892\n",
      "train loss:0.1368685696751112\n",
      "train loss:0.07533070409356124\n",
      "train loss:0.17827503230178074\n",
      "train loss:0.0808603093898933\n",
      "train loss:0.06464703891902043\n",
      "train loss:0.20930038483640082\n",
      "train loss:0.12660172268831676\n",
      "train loss:0.18603125106077628\n",
      "train loss:0.20043272650084665\n",
      "train loss:0.13967959782531994\n",
      "train loss:0.1338665787430659\n",
      "train loss:0.10616029446525299\n",
      "train loss:0.15326404240896965\n",
      "train loss:0.15072424050919364\n",
      "train loss:0.09985840631810032\n",
      "train loss:0.056928024658047416\n",
      "train loss:0.0958978434196709\n",
      "train loss:0.23004388712329005\n",
      "train loss:0.08288123581873229\n",
      "train loss:0.11730668498459781\n",
      "train loss:0.10043297565019223\n",
      "train loss:0.13452534168793748\n",
      "train loss:0.10827704163152634\n",
      "train loss:0.1642113089811792\n",
      "train loss:0.2440444258274658\n",
      "train loss:0.15512165870124522\n",
      "train loss:0.14199539590203533\n",
      "train loss:0.21771788522508703\n",
      "train loss:0.09677128734059606\n",
      "train loss:0.12090405224863192\n",
      "train loss:0.12045268017730326\n",
      "train loss:0.11989996406558007\n",
      "train loss:0.08910230112753256\n",
      "train loss:0.20606541485839774\n",
      "train loss:0.18901166706091202\n",
      "train loss:0.061644322524957905\n",
      "train loss:0.1752597683741564\n",
      "train loss:0.10099154044464831\n",
      "train loss:0.12495387776987588\n",
      "train loss:0.23930913797176423\n",
      "train loss:0.2506306043823432\n",
      "train loss:0.08243832206637179\n",
      "train loss:0.07944620624154507\n",
      "train loss:0.06151522666943282\n",
      "train loss:0.2098663940956991\n",
      "train loss:0.14218041626549116\n",
      "=== epoch:2, train acc:0.96, test acc:0.964 ===\n",
      "train loss:0.1251265513349927\n",
      "train loss:0.14368163640614107\n",
      "train loss:0.0787354127786999\n",
      "train loss:0.052961995257845985\n",
      "train loss:0.1362392737740158\n",
      "train loss:0.18759724495779267\n",
      "train loss:0.21552062026461263\n",
      "train loss:0.07513321215909567\n",
      "train loss:0.12516641857862146\n",
      "train loss:0.11272249972587277\n",
      "train loss:0.1470826630783254\n",
      "train loss:0.07816214926094726\n",
      "train loss:0.1748862092098888\n",
      "train loss:0.15080905567700553\n",
      "train loss:0.09253452930870712\n",
      "train loss:0.051647712498224134\n",
      "train loss:0.15922507072750625\n",
      "train loss:0.11867684438878316\n",
      "train loss:0.04135943428899713\n",
      "train loss:0.060292141447949386\n",
      "train loss:0.10677745296871072\n",
      "train loss:0.22632995049244758\n",
      "train loss:0.115256853660643\n",
      "train loss:0.11804130261280539\n",
      "train loss:0.08824806464408148\n",
      "train loss:0.1383188145961745\n",
      "train loss:0.08597919151896649\n",
      "train loss:0.13324297787132916\n",
      "train loss:0.03872774906875151\n",
      "train loss:0.08644869823068092\n",
      "train loss:0.21040901041309884\n",
      "train loss:0.12382406861201296\n",
      "train loss:0.05544240727045498\n",
      "train loss:0.0865629808125142\n",
      "train loss:0.12907436553353535\n",
      "train loss:0.20358516929389023\n",
      "train loss:0.1609252851053716\n",
      "train loss:0.10836330033064248\n",
      "train loss:0.1750079324499479\n",
      "train loss:0.10920777513126939\n",
      "train loss:0.1308518066375357\n",
      "train loss:0.06798330926160291\n",
      "train loss:0.06602200744859835\n",
      "train loss:0.13179598434762574\n",
      "train loss:0.19266405816509813\n",
      "train loss:0.07262540304241762\n",
      "train loss:0.19813225193052833\n",
      "train loss:0.06877778845832058\n",
      "train loss:0.11611993869387063\n",
      "train loss:0.15806485120162256\n",
      "train loss:0.11772416154239013\n",
      "train loss:0.13253949022492786\n",
      "train loss:0.21369794387631885\n",
      "train loss:0.13891244452417303\n",
      "train loss:0.08632955673376597\n",
      "train loss:0.07782845675638646\n",
      "train loss:0.09812870328810132\n",
      "train loss:0.13755485960490552\n",
      "train loss:0.11393976571690115\n",
      "train loss:0.15304287431060964\n",
      "train loss:0.05584176148739997\n",
      "train loss:0.12667270052169252\n",
      "train loss:0.1833884302056653\n",
      "train loss:0.18374112456101852\n",
      "train loss:0.1610961415372743\n",
      "train loss:0.09587682669787302\n",
      "train loss:0.08069994551082486\n",
      "train loss:0.07222921052531263\n",
      "train loss:0.1369323135585799\n",
      "train loss:0.12374108967333644\n",
      "train loss:0.08199749367687158\n",
      "train loss:0.07698980514180186\n",
      "train loss:0.15175926106128582\n",
      "train loss:0.1163166850935564\n",
      "train loss:0.07143103599079637\n",
      "train loss:0.1406417897440954\n",
      "train loss:0.07408953219430087\n",
      "train loss:0.14183321420022227\n",
      "train loss:0.053199836747983446\n",
      "train loss:0.15821354389769648\n",
      "train loss:0.11569304372785691\n",
      "train loss:0.10921081289500681\n",
      "train loss:0.042419885750421965\n",
      "train loss:0.10099260302732439\n",
      "train loss:0.1638260631215098\n",
      "train loss:0.16407759677875933\n",
      "train loss:0.17134203983592092\n",
      "train loss:0.17756683608558033\n",
      "train loss:0.0864570344136786\n",
      "train loss:0.10349295376939993\n",
      "train loss:0.0915528703113559\n",
      "train loss:0.11829718168473423\n",
      "train loss:0.07215036591660275\n",
      "train loss:0.05950790441423452\n",
      "train loss:0.04943123273732047\n",
      "train loss:0.06555205365445191\n",
      "train loss:0.04983720916592726\n",
      "train loss:0.06466446661012847\n",
      "train loss:0.12733180404284725\n",
      "train loss:0.09366345013835145\n",
      "train loss:0.09915101967836033\n",
      "train loss:0.07985649293956057\n",
      "train loss:0.10916735985160449\n",
      "train loss:0.03943695756689204\n",
      "train loss:0.07853384069533673\n",
      "train loss:0.07222546134039316\n",
      "train loss:0.15267512044929032\n",
      "train loss:0.04694043759311667\n",
      "train loss:0.06098608121252719\n",
      "train loss:0.06213297600214252\n",
      "train loss:0.08777999220719603\n",
      "train loss:0.06367446571440652\n",
      "train loss:0.155763866293024\n",
      "train loss:0.053144106165003195\n",
      "train loss:0.08255743367189469\n",
      "train loss:0.04908716130702433\n",
      "train loss:0.16080497128346288\n",
      "train loss:0.05316877731654123\n",
      "train loss:0.034984943188487744\n",
      "train loss:0.06911893022427468\n",
      "train loss:0.22960855679682093\n",
      "train loss:0.10998080081160304\n",
      "train loss:0.095436494799378\n",
      "train loss:0.0979975989122206\n",
      "train loss:0.0627221654424034\n",
      "train loss:0.05794440404749821\n",
      "train loss:0.13658686014368512\n",
      "train loss:0.03847090453103577\n",
      "train loss:0.11195005980093978\n",
      "train loss:0.05062541567986595\n",
      "train loss:0.08543117964109147\n",
      "train loss:0.1027282800778003\n",
      "train loss:0.13229736810841733\n",
      "train loss:0.11540074054042028\n",
      "train loss:0.14603361042085505\n",
      "train loss:0.1610973409067757\n",
      "train loss:0.12857375624079243\n",
      "train loss:0.09632414035466208\n",
      "train loss:0.1523278012691553\n",
      "train loss:0.11118999736804352\n",
      "train loss:0.21276103363275325\n",
      "train loss:0.185240255674963\n",
      "train loss:0.0989547791901113\n",
      "train loss:0.08136188700366559\n",
      "train loss:0.17834756646014302\n",
      "train loss:0.10567708416235372\n",
      "train loss:0.09683292922139387\n",
      "train loss:0.18217448194545366\n",
      "train loss:0.08684130595936937\n",
      "train loss:0.09811188930654285\n",
      "train loss:0.058676828428850365\n",
      "train loss:0.13898756666619\n",
      "train loss:0.055359350424556523\n",
      "train loss:0.13253479751260636\n",
      "train loss:0.09506658548505499\n",
      "train loss:0.13675375831815859\n",
      "train loss:0.14050514399319255\n",
      "train loss:0.059247672698529576\n",
      "train loss:0.07554035362478953\n",
      "train loss:0.12180183020844712\n",
      "train loss:0.12520930459786977\n",
      "train loss:0.057697517843118815\n",
      "train loss:0.057950988100397886\n",
      "train loss:0.1425325950145425\n",
      "train loss:0.11050290619460558\n",
      "train loss:0.06905815420390074\n",
      "train loss:0.136359133260321\n",
      "train loss:0.12179729382685413\n",
      "train loss:0.1434548190165652\n",
      "train loss:0.10639520145996023\n",
      "train loss:0.08598349156395223\n",
      "train loss:0.07599634442489904\n",
      "train loss:0.08143450025319222\n",
      "train loss:0.12501263571637855\n",
      "train loss:0.11894757691947888\n",
      "train loss:0.14363650651432439\n",
      "train loss:0.27437689352935596\n",
      "train loss:0.17146293873716092\n",
      "train loss:0.1799868172245467\n",
      "train loss:0.16038282475386276\n",
      "train loss:0.23441650876486275\n",
      "train loss:0.11766470497470476\n",
      "train loss:0.08308193612332836\n",
      "train loss:0.1229215160174037\n",
      "train loss:0.14346558611044552\n",
      "train loss:0.1288750855726663\n",
      "train loss:0.1712757360203718\n",
      "train loss:0.1182325443407847\n",
      "train loss:0.10471847922783187\n",
      "train loss:0.02797896645617918\n",
      "train loss:0.10536626342805551\n",
      "train loss:0.15709849363266817\n",
      "train loss:0.06407772435038125\n",
      "train loss:0.0673024387998426\n",
      "train loss:0.15249091991527933\n",
      "train loss:0.09220266824336455\n",
      "train loss:0.08440366684391011\n",
      "train loss:0.06549555620155789\n",
      "train loss:0.1546954964108661\n",
      "train loss:0.2038234959880528\n",
      "train loss:0.08052103499614179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.072888828235283\n",
      "train loss:0.10960245590253967\n",
      "train loss:0.14211916252004855\n",
      "train loss:0.1595171914253297\n",
      "train loss:0.09935129280916973\n",
      "train loss:0.10424015231668889\n",
      "train loss:0.04600955152616953\n",
      "train loss:0.11911120937365287\n",
      "train loss:0.15417545623841927\n",
      "train loss:0.06416209151366514\n",
      "train loss:0.08355710178030584\n",
      "train loss:0.09737990453764786\n",
      "train loss:0.13466112941083874\n",
      "train loss:0.14101772458005832\n",
      "train loss:0.09718674598684764\n",
      "train loss:0.07708600606630946\n",
      "train loss:0.09015121065064596\n",
      "train loss:0.07698262241869978\n",
      "train loss:0.1468599031152376\n",
      "train loss:0.05312403721262991\n",
      "train loss:0.18503380160483224\n",
      "train loss:0.07831218094439431\n",
      "train loss:0.0816646050746695\n",
      "train loss:0.09166255814267428\n",
      "train loss:0.037170559318530166\n",
      "train loss:0.07008520843491417\n",
      "train loss:0.03616941258681095\n",
      "train loss:0.11393520788541052\n",
      "train loss:0.14462333984347245\n",
      "train loss:0.1448801064368373\n",
      "train loss:0.19092858920170921\n",
      "train loss:0.09002851729303982\n",
      "train loss:0.08927388564672935\n",
      "train loss:0.08923960363326872\n",
      "train loss:0.1213353239039268\n",
      "train loss:0.18119427049458442\n",
      "train loss:0.0704330912588475\n",
      "train loss:0.08162868342844282\n",
      "train loss:0.13955409561329848\n",
      "train loss:0.043383492295347104\n",
      "train loss:0.13060254281742414\n",
      "train loss:0.21397907805772312\n",
      "train loss:0.03857950984254824\n",
      "train loss:0.08591216966359898\n",
      "train loss:0.11534154279791045\n",
      "train loss:0.12523190588709435\n",
      "train loss:0.1375749629880037\n",
      "train loss:0.10654310656215193\n",
      "train loss:0.18655218394511197\n",
      "train loss:0.09425898078762267\n",
      "train loss:0.07124292073862802\n",
      "train loss:0.09114982920533692\n",
      "train loss:0.06633674534013614\n",
      "train loss:0.06114084214325041\n",
      "train loss:0.13662859131304436\n",
      "train loss:0.15064403483135552\n",
      "train loss:0.03239413793534431\n",
      "train loss:0.06739873345623816\n",
      "train loss:0.1925549857153907\n",
      "train loss:0.10292490019286787\n",
      "train loss:0.1604997115595484\n",
      "train loss:0.038007808599683474\n",
      "train loss:0.14940629492675822\n",
      "train loss:0.12040897173600568\n",
      "train loss:0.1322321542557383\n",
      "train loss:0.15399116586362824\n",
      "train loss:0.05242639476771948\n",
      "train loss:0.07022036190530594\n",
      "train loss:0.09993387578078348\n",
      "train loss:0.0522024262089733\n",
      "train loss:0.05856002587481864\n",
      "train loss:0.15071404490732204\n",
      "train loss:0.04498590595348682\n",
      "train loss:0.043244091742632246\n",
      "train loss:0.04712676640730588\n",
      "train loss:0.1522097991250728\n",
      "train loss:0.10178046372532135\n",
      "train loss:0.15506613918491696\n",
      "train loss:0.053728115913611985\n",
      "train loss:0.10241398045505233\n",
      "train loss:0.09842044297983614\n",
      "train loss:0.060082504878910294\n",
      "train loss:0.17584611677459808\n",
      "train loss:0.037978785497743\n",
      "train loss:0.03697172010267429\n",
      "train loss:0.13675026612412655\n",
      "train loss:0.12399625713299887\n",
      "train loss:0.051452482595635354\n",
      "train loss:0.05435613498351565\n",
      "train loss:0.1071911309269359\n",
      "train loss:0.14727980832005722\n",
      "train loss:0.07119980852332307\n",
      "train loss:0.089722124417458\n",
      "train loss:0.05499375094813\n",
      "train loss:0.08742056950622924\n",
      "train loss:0.08852375646438976\n",
      "train loss:0.0780587671900751\n",
      "train loss:0.10736150250539518\n",
      "train loss:0.1208313139970602\n",
      "train loss:0.06984733077061746\n",
      "train loss:0.13900974323411786\n",
      "train loss:0.1049405985554423\n",
      "train loss:0.09464444061192591\n",
      "train loss:0.05031909809219677\n",
      "train loss:0.07918222035360183\n",
      "train loss:0.06411507141291882\n",
      "train loss:0.17677948050934433\n",
      "train loss:0.09929032234253024\n",
      "train loss:0.07407901139034839\n",
      "train loss:0.029600838096040465\n",
      "train loss:0.06052946116468502\n",
      "train loss:0.04178403815740103\n",
      "train loss:0.03572674146486846\n",
      "train loss:0.04510044591709349\n",
      "train loss:0.14721128959773996\n",
      "train loss:0.0637812755696299\n",
      "train loss:0.030732770511491526\n",
      "train loss:0.1245568787505787\n",
      "train loss:0.16254979674208114\n",
      "train loss:0.04863684150583767\n",
      "train loss:0.09229633574732352\n",
      "train loss:0.08239793728067905\n",
      "train loss:0.08910077045791129\n",
      "train loss:0.122917329629902\n",
      "train loss:0.034904592491903356\n",
      "train loss:0.034590105387994896\n",
      "train loss:0.10525343068699194\n",
      "train loss:0.07054014757932185\n",
      "train loss:0.19477878539686433\n",
      "train loss:0.12655215489084848\n",
      "train loss:0.05027370325166332\n",
      "train loss:0.09634250845699052\n",
      "train loss:0.037955305848835635\n",
      "train loss:0.06468243763061335\n",
      "train loss:0.10009919699718912\n",
      "train loss:0.03453299442592583\n",
      "train loss:0.0790937347103286\n",
      "train loss:0.09552724345356783\n",
      "train loss:0.03124276631397343\n",
      "train loss:0.09737796089878917\n",
      "train loss:0.054345830485082694\n",
      "train loss:0.07997124092304955\n",
      "train loss:0.05822690845798704\n",
      "train loss:0.06436374925962442\n",
      "train loss:0.08937549742836161\n",
      "train loss:0.0747805664483927\n",
      "train loss:0.0807819979686221\n",
      "train loss:0.06241718313626528\n",
      "train loss:0.03962753502842528\n",
      "train loss:0.13555746336387509\n",
      "train loss:0.1039658320711407\n",
      "train loss:0.050087794101523614\n",
      "train loss:0.023614301553626992\n",
      "train loss:0.03478201962811984\n",
      "train loss:0.022771224147275105\n",
      "train loss:0.05366535122480429\n",
      "train loss:0.06003557144476927\n",
      "train loss:0.22098827386301867\n",
      "train loss:0.07487713331586204\n",
      "train loss:0.08381185640764001\n",
      "train loss:0.10885573371065928\n",
      "train loss:0.060107539886640235\n",
      "train loss:0.04867649902444891\n",
      "train loss:0.09129236057773932\n",
      "train loss:0.04414435636386469\n",
      "train loss:0.14256089449540874\n",
      "train loss:0.03466852801225048\n",
      "train loss:0.12391689075202594\n",
      "train loss:0.06547889396945018\n",
      "train loss:0.03208183163798987\n",
      "train loss:0.07176909984547454\n",
      "train loss:0.0724730277687748\n",
      "train loss:0.20025918465591397\n",
      "train loss:0.08680790160133509\n",
      "train loss:0.03678416351909422\n",
      "train loss:0.05859991726614428\n",
      "train loss:0.05798602993712545\n",
      "train loss:0.02872336818576012\n",
      "train loss:0.022517932965200917\n",
      "train loss:0.09533739362412103\n",
      "train loss:0.0477098102246278\n",
      "train loss:0.04699660325121771\n",
      "train loss:0.027542337588764742\n",
      "train loss:0.1008690168373587\n",
      "train loss:0.06845733309221563\n",
      "train loss:0.05858712719948821\n",
      "train loss:0.057243540660185846\n",
      "train loss:0.17935057069864674\n",
      "train loss:0.19560503338256016\n",
      "train loss:0.07015790303008074\n",
      "train loss:0.1082324423820803\n",
      "train loss:0.062342096627159574\n",
      "train loss:0.12301074555593726\n",
      "train loss:0.05544438129843246\n",
      "train loss:0.1109320422044358\n",
      "train loss:0.03596761352197077\n",
      "train loss:0.12939234824097823\n",
      "train loss:0.023986616979964123\n",
      "train loss:0.058014545891332966\n",
      "train loss:0.03927595482333503\n",
      "train loss:0.027395218421909697\n",
      "train loss:0.06983845871518689\n",
      "train loss:0.06645078335799916\n",
      "train loss:0.04331433576835671\n",
      "train loss:0.10225992654154137\n",
      "train loss:0.0877634363959824\n",
      "train loss:0.13699348410096682\n",
      "train loss:0.042835088309103056\n",
      "train loss:0.1266349289602247\n",
      "train loss:0.09628599822765939\n",
      "train loss:0.05393748025987967\n",
      "train loss:0.08004103967032544\n",
      "train loss:0.12171304221619465\n",
      "train loss:0.15012367836907045\n",
      "train loss:0.04119813113686581\n",
      "train loss:0.12147092726634787\n",
      "train loss:0.10967824885258104\n",
      "train loss:0.03741265627664646\n",
      "train loss:0.08838681112978347\n",
      "train loss:0.08471109790733329\n",
      "train loss:0.03795860499140767\n",
      "train loss:0.04977550298441214\n",
      "train loss:0.04960941640366984\n",
      "train loss:0.16367618618306523\n",
      "train loss:0.07345305569446914\n",
      "train loss:0.03300768917162108\n",
      "train loss:0.05584233976250423\n",
      "train loss:0.09371246083519309\n",
      "train loss:0.08184891367783387\n",
      "train loss:0.06871663476049704\n",
      "train loss:0.0486316027368267\n",
      "train loss:0.13772922601353044\n",
      "train loss:0.07724713931118989\n",
      "train loss:0.07602467867968478\n",
      "train loss:0.04227835095206246\n",
      "train loss:0.11113197302684692\n",
      "train loss:0.08530866851489793\n",
      "train loss:0.05227939807798018\n",
      "train loss:0.08645884970151217\n",
      "train loss:0.03530799495255634\n",
      "train loss:0.03285135822186022\n",
      "train loss:0.03834535621523729\n",
      "train loss:0.08227910024123641\n",
      "train loss:0.09394665493669759\n",
      "train loss:0.08890157164001852\n",
      "train loss:0.08659083959676105\n",
      "train loss:0.058281790255257385\n",
      "train loss:0.08572570646602298\n",
      "train loss:0.2256536156751508\n",
      "train loss:0.04391462920601738\n",
      "train loss:0.10343982270135176\n",
      "train loss:0.11244229639744338\n",
      "train loss:0.06796562259432644\n",
      "train loss:0.14379390900824737\n",
      "train loss:0.12561940232638436\n",
      "train loss:0.042658938765126386\n",
      "train loss:0.12946054833613377\n",
      "train loss:0.11121843289207468\n",
      "train loss:0.08719673603111382\n",
      "train loss:0.07202020885113637\n",
      "train loss:0.10269477231709562\n",
      "train loss:0.06226821908466557\n",
      "train loss:0.11269989471039206\n",
      "train loss:0.07205742285520135\n",
      "train loss:0.03417887529142131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05037749481932803\n",
      "train loss:0.05541851722259521\n",
      "train loss:0.025915194378912907\n",
      "train loss:0.05604994883231823\n",
      "train loss:0.052556709958726654\n",
      "train loss:0.05887928627503794\n",
      "train loss:0.04595464120967461\n",
      "train loss:0.09062176944673396\n",
      "train loss:0.07411592957986472\n",
      "train loss:0.022560725505257277\n",
      "train loss:0.08045780715139678\n",
      "train loss:0.03535990370931494\n",
      "train loss:0.072210092344997\n",
      "train loss:0.13123971266902132\n",
      "train loss:0.03727113370843435\n",
      "train loss:0.029147751059367292\n",
      "train loss:0.027138971384053398\n",
      "train loss:0.11177807846931984\n",
      "train loss:0.03711039332761783\n",
      "train loss:0.09642670351079731\n",
      "train loss:0.030725462706770748\n",
      "train loss:0.028384724979289927\n",
      "train loss:0.07768625047287832\n",
      "train loss:0.05886796125623334\n",
      "train loss:0.1672091745026104\n",
      "train loss:0.10699166893085475\n",
      "train loss:0.04918960226451704\n",
      "train loss:0.04914474738113814\n",
      "train loss:0.06004415616135108\n",
      "train loss:0.026930998256710782\n",
      "train loss:0.02177122447696801\n",
      "train loss:0.0936459320438138\n",
      "train loss:0.043496170157063876\n",
      "train loss:0.07227170019728911\n",
      "train loss:0.08046762234563981\n",
      "train loss:0.09250159927991493\n",
      "train loss:0.11060563888544687\n",
      "train loss:0.07893702628841955\n",
      "train loss:0.06407896285690093\n",
      "train loss:0.057460350116836645\n",
      "train loss:0.0342190993677292\n",
      "train loss:0.0360450543312203\n",
      "train loss:0.08238444186647913\n",
      "train loss:0.025143884247446444\n",
      "train loss:0.10534011259133111\n",
      "train loss:0.06698232169572353\n",
      "train loss:0.16790268011931495\n",
      "train loss:0.09738838825549917\n",
      "train loss:0.04855905858612525\n",
      "train loss:0.030043964359137355\n",
      "train loss:0.10257942785690072\n",
      "train loss:0.031173067802462665\n",
      "train loss:0.09971379092721168\n",
      "train loss:0.21777256529719596\n",
      "train loss:0.0480518140546921\n",
      "train loss:0.038179336871670494\n",
      "train loss:0.07037606598827993\n",
      "train loss:0.07382236849137287\n",
      "train loss:0.13718643323118837\n",
      "train loss:0.2049440337410936\n",
      "train loss:0.07503065341375431\n",
      "train loss:0.03778765354184876\n",
      "train loss:0.05910112245546695\n",
      "train loss:0.03726699919320767\n",
      "train loss:0.032710847081339194\n",
      "train loss:0.11862142816033902\n",
      "train loss:0.05546558566667145\n",
      "train loss:0.056996050628581284\n",
      "train loss:0.028255640222791215\n",
      "train loss:0.01905224126149339\n",
      "train loss:0.11944047160177915\n",
      "train loss:0.08101776539151255\n",
      "train loss:0.09916158909584424\n",
      "train loss:0.07227752584602237\n",
      "train loss:0.09695522444587362\n",
      "train loss:0.05709964839846855\n",
      "train loss:0.08572605998410689\n",
      "train loss:0.10091438428575622\n",
      "train loss:0.13731406466980817\n",
      "train loss:0.018467230295810294\n",
      "train loss:0.0646938813625702\n",
      "train loss:0.07592132790965728\n",
      "train loss:0.12979783082938226\n",
      "train loss:0.04979915045993897\n",
      "train loss:0.04351970003354468\n",
      "train loss:0.10589977484713643\n",
      "train loss:0.0906284510158539\n",
      "train loss:0.06512277631871738\n",
      "train loss:0.07528936540070084\n",
      "train loss:0.09078425917077868\n",
      "train loss:0.1345790214499637\n",
      "train loss:0.09524924566563361\n",
      "train loss:0.056178622488845795\n",
      "train loss:0.10494031011893883\n",
      "train loss:0.06296280926433004\n",
      "train loss:0.11055347048826157\n",
      "train loss:0.1202137177338725\n",
      "train loss:0.09440293329693977\n",
      "train loss:0.07550760232224948\n",
      "train loss:0.06134139079786403\n",
      "train loss:0.08365294309206696\n",
      "train loss:0.02669525126528049\n",
      "train loss:0.08603827846621451\n",
      "train loss:0.04347098577585888\n",
      "train loss:0.06939168815458213\n",
      "train loss:0.03340877522773087\n",
      "train loss:0.04797524389695378\n",
      "train loss:0.027458731209867526\n",
      "train loss:0.1682994293788709\n",
      "train loss:0.07130582862048924\n",
      "train loss:0.03909358224354609\n",
      "train loss:0.062107936503883604\n",
      "train loss:0.06988675887451584\n",
      "train loss:0.031597736334850135\n",
      "train loss:0.12063223239110873\n",
      "train loss:0.13322269710594203\n",
      "train loss:0.050430539082045\n",
      "train loss:0.09460101583906269\n",
      "train loss:0.08688582235009334\n",
      "train loss:0.10846845856592786\n",
      "train loss:0.060345225650839635\n",
      "train loss:0.09125181564185979\n",
      "train loss:0.10040694737502756\n",
      "train loss:0.030033918923164177\n",
      "train loss:0.04855457255502405\n",
      "train loss:0.07419685214291116\n",
      "train loss:0.03616654857412188\n",
      "train loss:0.047982273797907586\n",
      "train loss:0.08389106196227378\n",
      "train loss:0.03211134051556102\n",
      "train loss:0.03203142053972765\n",
      "train loss:0.02743652999408787\n",
      "train loss:0.016759073822980225\n",
      "train loss:0.0413145435709173\n",
      "=== epoch:3, train acc:0.978, test acc:0.974 ===\n",
      "train loss:0.05995955045521903\n",
      "train loss:0.040668881751252134\n",
      "train loss:0.08605034016224321\n",
      "train loss:0.02316822483140191\n",
      "train loss:0.08363708678298512\n",
      "train loss:0.09049535363497938\n",
      "train loss:0.09096225345634243\n",
      "train loss:0.04589039939971766\n",
      "train loss:0.02755665655701516\n",
      "train loss:0.06379290421336511\n",
      "train loss:0.040645714353929926\n",
      "train loss:0.0727880169337513\n",
      "train loss:0.0719130100265625\n",
      "train loss:0.09556730599299579\n",
      "train loss:0.05097317045243294\n",
      "train loss:0.047657493753553236\n",
      "train loss:0.04646990555339072\n",
      "train loss:0.14974392920728877\n",
      "train loss:0.06519209305531434\n",
      "train loss:0.02841828387722827\n",
      "train loss:0.06245364242746082\n",
      "train loss:0.043505459545431176\n",
      "train loss:0.033146697811081496\n",
      "train loss:0.08193116072931231\n",
      "train loss:0.044229931891140765\n",
      "train loss:0.05184251241417983\n",
      "train loss:0.024946456196173212\n",
      "train loss:0.03878218232969175\n",
      "train loss:0.054246074856456356\n",
      "train loss:0.08999904949690654\n",
      "train loss:0.023676867940925175\n",
      "train loss:0.07085141059194969\n",
      "train loss:0.10588727851312128\n",
      "train loss:0.049486399054094195\n",
      "train loss:0.0558560610193994\n",
      "train loss:0.05737530233537787\n",
      "train loss:0.07285104004142597\n",
      "train loss:0.07783401692400103\n",
      "train loss:0.07611368170782078\n",
      "train loss:0.03662528769649842\n",
      "train loss:0.024590402616492427\n",
      "train loss:0.025517662622621944\n",
      "train loss:0.07688578995701707\n",
      "train loss:0.052978730604135854\n",
      "train loss:0.060287643681606\n",
      "train loss:0.09422712318970725\n",
      "train loss:0.1293693720732029\n",
      "train loss:0.04036671935835497\n",
      "train loss:0.09736688788108369\n",
      "train loss:0.059952541742559304\n",
      "train loss:0.1218282477793335\n",
      "train loss:0.043345215419885536\n",
      "train loss:0.03420205868239525\n",
      "train loss:0.022839213143907397\n",
      "train loss:0.057603540188472906\n",
      "train loss:0.04124999793519206\n",
      "train loss:0.11968063774116491\n",
      "train loss:0.05344260265405031\n",
      "train loss:0.026395209604145306\n",
      "train loss:0.11738581570174908\n",
      "train loss:0.04499908019955253\n",
      "train loss:0.043759646912799516\n",
      "train loss:0.05308536989527526\n",
      "train loss:0.01941911184190386\n",
      "train loss:0.08751272038490149\n",
      "train loss:0.05354071506148382\n",
      "train loss:0.056323042714494224\n",
      "train loss:0.05910353760621459\n",
      "train loss:0.03145187469603968\n",
      "train loss:0.08183742382807813\n",
      "train loss:0.1091706948904053\n",
      "train loss:0.08105518160006892\n",
      "train loss:0.10251122843982179\n",
      "train loss:0.039348828482876734\n",
      "train loss:0.08650344344795526\n",
      "train loss:0.03358030420508331\n",
      "train loss:0.06641978070680239\n",
      "train loss:0.030640843190295194\n",
      "train loss:0.012646626275160793\n",
      "train loss:0.07299873394087812\n",
      "train loss:0.09314945502576048\n",
      "train loss:0.09469023917226453\n",
      "train loss:0.05508243579023758\n",
      "train loss:0.03167435494309598\n",
      "train loss:0.10811797247928354\n",
      "train loss:0.11074131883581355\n",
      "train loss:0.07525420328771276\n",
      "train loss:0.03359660470165164\n",
      "train loss:0.018438937512389966\n",
      "train loss:0.04664814435847646\n",
      "train loss:0.1092970080542067\n",
      "train loss:0.08937128227371544\n",
      "train loss:0.024749365008857608\n",
      "train loss:0.046735484123760856\n",
      "train loss:0.07784813126104945\n",
      "train loss:0.1214608018315997\n",
      "train loss:0.03465040501305574\n",
      "train loss:0.04546033785798304\n",
      "train loss:0.03737988427477859\n",
      "train loss:0.026662190655239323\n",
      "train loss:0.06504740937383283\n",
      "train loss:0.03461059386462919\n",
      "train loss:0.04591924001208873\n",
      "train loss:0.01075805961478195\n",
      "train loss:0.08514594997615647\n",
      "train loss:0.04051807614235441\n",
      "train loss:0.05708676457281467\n",
      "train loss:0.11297727093650002\n",
      "train loss:0.04378760414059297\n",
      "train loss:0.07751834267863016\n",
      "train loss:0.05920718169836188\n",
      "train loss:0.060564008444446725\n",
      "train loss:0.07613949019241315\n",
      "train loss:0.027284696600113758\n",
      "train loss:0.09506349955652953\n",
      "train loss:0.09958940495118894\n",
      "train loss:0.05137230757141835\n",
      "train loss:0.021669685698709137\n",
      "train loss:0.03185631537229202\n",
      "train loss:0.10855485502776235\n",
      "train loss:0.05092368303932375\n",
      "train loss:0.10150054088132421\n",
      "train loss:0.03170671824576519\n",
      "train loss:0.08278053882148197\n",
      "train loss:0.025742783789957223\n",
      "train loss:0.055988779874657\n",
      "train loss:0.1059321292130381\n",
      "train loss:0.03331124944704231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10827348874299066\n",
      "train loss:0.04670736898155254\n",
      "train loss:0.13458603674758549\n",
      "train loss:0.10644872734769613\n",
      "train loss:0.03545535259171832\n",
      "train loss:0.09237162013343418\n",
      "train loss:0.021133745779101498\n",
      "train loss:0.026079000982266214\n",
      "train loss:0.12285879715161659\n",
      "train loss:0.03495022573868687\n",
      "train loss:0.12639188136905424\n",
      "train loss:0.05093483686566505\n",
      "train loss:0.11253272512110518\n",
      "train loss:0.038579321847963505\n",
      "train loss:0.054799834028098876\n",
      "train loss:0.15049528145127047\n",
      "train loss:0.03807123442731187\n",
      "train loss:0.06500377076796159\n",
      "train loss:0.08831417420085842\n",
      "train loss:0.09238381765673516\n",
      "train loss:0.0460322407429297\n",
      "train loss:0.020169273812568823\n",
      "train loss:0.03939194904183351\n",
      "train loss:0.017250583123644546\n",
      "train loss:0.1513223551240995\n",
      "train loss:0.0790686490918561\n",
      "train loss:0.06818129465706355\n",
      "train loss:0.09798562165496706\n",
      "train loss:0.050998848605027486\n",
      "train loss:0.028661248407677493\n",
      "train loss:0.1438771374868986\n",
      "train loss:0.04692944033097643\n",
      "train loss:0.021155300352890653\n",
      "train loss:0.05081155290894169\n",
      "train loss:0.05827305938358766\n",
      "train loss:0.028578190714061407\n",
      "train loss:0.032274163089489855\n",
      "train loss:0.05080698295333209\n",
      "train loss:0.09140296486961244\n",
      "train loss:0.07216305054839771\n",
      "train loss:0.02179576985131961\n",
      "train loss:0.052863638842947175\n",
      "train loss:0.12474574703504954\n",
      "train loss:0.06180170920832136\n",
      "train loss:0.030929547707542436\n",
      "train loss:0.06525998351440637\n",
      "train loss:0.06674155689140092\n",
      "train loss:0.018852540663415417\n",
      "train loss:0.08209525970173594\n",
      "train loss:0.037125865127213456\n",
      "train loss:0.027528069257926738\n",
      "train loss:0.07359024377481603\n",
      "train loss:0.0769384506818669\n",
      "train loss:0.04482652006902566\n",
      "train loss:0.05230623906884874\n",
      "train loss:0.043818014224608924\n",
      "train loss:0.026512086931910542\n",
      "train loss:0.030842155942489055\n",
      "train loss:0.03629255393581467\n",
      "train loss:0.10754910216206685\n",
      "train loss:0.06679465776743834\n",
      "train loss:0.08861533344751615\n",
      "train loss:0.07269035382139136\n",
      "train loss:0.06691452352855794\n",
      "train loss:0.04565354263247299\n",
      "train loss:0.060970079251867954\n",
      "train loss:0.040441163958412435\n",
      "train loss:0.0967273026684914\n",
      "train loss:0.07313013599121276\n",
      "train loss:0.11031894790534638\n",
      "train loss:0.14263909314998957\n",
      "train loss:0.032564832998186626\n",
      "train loss:0.08503328824246865\n",
      "train loss:0.10159202961126088\n",
      "train loss:0.09841158200588801\n",
      "train loss:0.05390561510534035\n",
      "train loss:0.037068839323594775\n",
      "train loss:0.030867009608350652\n",
      "train loss:0.04150835708954883\n",
      "train loss:0.08312061772711427\n",
      "train loss:0.1402671387087496\n",
      "train loss:0.08491240426842316\n",
      "train loss:0.07279043654577773\n",
      "train loss:0.026150528370289507\n",
      "train loss:0.033277476899130895\n",
      "train loss:0.07072573728743593\n",
      "train loss:0.04465857174142452\n",
      "train loss:0.047639912789219155\n",
      "train loss:0.05749781065105028\n",
      "train loss:0.026911205049996147\n",
      "train loss:0.038583757795276855\n",
      "train loss:0.12756506043804244\n",
      "train loss:0.03861315565456763\n",
      "train loss:0.12356638556187743\n",
      "train loss:0.04741836069508731\n",
      "train loss:0.04447725000896205\n",
      "train loss:0.1443180236143536\n",
      "train loss:0.03240817930895553\n",
      "train loss:0.034608660101091364\n",
      "train loss:0.04949134628730654\n",
      "train loss:0.06714279966533586\n",
      "train loss:0.022077210705586773\n",
      "train loss:0.047307233986965895\n",
      "train loss:0.06761396665169415\n",
      "train loss:0.12112572315615645\n",
      "train loss:0.08261580174933765\n",
      "train loss:0.06278244937807781\n",
      "train loss:0.1486157920642716\n",
      "train loss:0.09258409380376842\n",
      "train loss:0.03517511574173207\n",
      "train loss:0.041355416294728775\n",
      "train loss:0.04145475019344192\n",
      "train loss:0.028519196422037194\n",
      "train loss:0.1224293317074734\n",
      "train loss:0.031128418814698976\n",
      "train loss:0.037480141978026495\n",
      "train loss:0.05323041854313138\n",
      "train loss:0.012244357720836844\n",
      "train loss:0.0630080609117021\n",
      "train loss:0.05837197293756852\n",
      "train loss:0.03224466220356947\n",
      "train loss:0.07744801870703215\n",
      "train loss:0.05261298413070116\n",
      "train loss:0.10632943111258591\n",
      "train loss:0.05551906947707067\n",
      "train loss:0.029228464419834236\n",
      "train loss:0.1302335650036782\n",
      "train loss:0.1027527314726085\n",
      "train loss:0.047043632064905784\n",
      "train loss:0.10367751121129296\n",
      "train loss:0.05118757566457267\n",
      "train loss:0.030664671025893212\n",
      "train loss:0.052803273559449956\n",
      "train loss:0.028021312806820617\n",
      "train loss:0.07543141576282474\n",
      "train loss:0.04906153926474818\n",
      "train loss:0.05336107757588613\n",
      "train loss:0.0902189258038705\n",
      "train loss:0.0373031046145049\n",
      "train loss:0.07659841488254897\n",
      "train loss:0.13319089988093305\n",
      "train loss:0.029979054755427753\n",
      "train loss:0.056565534637321\n",
      "train loss:0.03215743308050324\n",
      "train loss:0.038096220181932636\n",
      "train loss:0.13640324743491833\n",
      "train loss:0.08331656672939725\n",
      "train loss:0.05859474556590456\n",
      "train loss:0.14246801959930852\n",
      "train loss:0.029890304007563394\n",
      "train loss:0.07839680934275758\n",
      "train loss:0.09256194603199899\n",
      "train loss:0.03163176061260356\n",
      "train loss:0.044146868093272375\n",
      "train loss:0.024924778840315315\n",
      "train loss:0.022505043215646364\n",
      "train loss:0.046307266559749094\n",
      "train loss:0.03920324022667116\n",
      "train loss:0.04001586292712664\n",
      "train loss:0.03509056510634118\n",
      "train loss:0.07283924281432745\n",
      "train loss:0.06277287730182732\n",
      "train loss:0.04828176157761879\n",
      "train loss:0.04518319341745318\n",
      "train loss:0.0772204180146169\n",
      "train loss:0.07245090231611051\n",
      "train loss:0.06782013688944923\n",
      "train loss:0.02467109406893085\n",
      "train loss:0.0717555250547171\n",
      "train loss:0.03723691391208863\n",
      "train loss:0.0612799901540642\n",
      "train loss:0.027484420438661145\n",
      "train loss:0.04790695650955541\n",
      "train loss:0.04192647247611394\n",
      "train loss:0.036918654660063666\n",
      "train loss:0.06063071592450173\n",
      "train loss:0.07188628248323826\n",
      "train loss:0.02462619752062228\n",
      "train loss:0.06075098311643917\n",
      "train loss:0.05087666885072721\n",
      "train loss:0.056011648907537105\n",
      "train loss:0.16129657540149683\n",
      "train loss:0.13205450327774965\n",
      "train loss:0.07849246167346494\n",
      "train loss:0.03736208792461039\n",
      "train loss:0.08839385511674705\n",
      "train loss:0.03359952126395918\n",
      "train loss:0.03299773580464684\n",
      "train loss:0.039841634808113535\n",
      "train loss:0.10263553516297665\n",
      "train loss:0.11156936086917323\n",
      "train loss:0.09497070371449796\n",
      "train loss:0.008686971048223673\n",
      "train loss:0.029793384296567697\n",
      "train loss:0.09082113313464699\n",
      "train loss:0.04613647172732875\n",
      "train loss:0.09566252677423044\n",
      "train loss:0.05658385052880397\n",
      "train loss:0.048496100177158975\n",
      "train loss:0.10681179460427616\n",
      "train loss:0.025673297871215292\n",
      "train loss:0.035618729730768434\n",
      "train loss:0.029032500381512262\n",
      "train loss:0.11720693488988317\n",
      "train loss:0.047752887815288386\n",
      "train loss:0.016172094357958685\n",
      "train loss:0.031615348663871015\n",
      "train loss:0.05569887359535025\n",
      "train loss:0.07447898171406755\n",
      "train loss:0.011708713053097423\n",
      "train loss:0.022951858882662983\n",
      "train loss:0.044887394551261055\n",
      "train loss:0.05186876307558375\n",
      "train loss:0.013345549917033525\n",
      "train loss:0.03810383828800435\n",
      "train loss:0.08324628214649916\n",
      "train loss:0.09667486073005901\n",
      "train loss:0.048318530906284615\n",
      "train loss:0.118624475256218\n",
      "train loss:0.021420170853523598\n",
      "train loss:0.030025221447989955\n",
      "train loss:0.07878354351813519\n",
      "train loss:0.07280228125524928\n",
      "train loss:0.0662206637134946\n",
      "train loss:0.01931099377647448\n",
      "train loss:0.034029263627748205\n",
      "train loss:0.04144923677850496\n",
      "train loss:0.16918473714895177\n",
      "train loss:0.07146322917027718\n",
      "train loss:0.05066658742999735\n",
      "train loss:0.021036445261702324\n",
      "train loss:0.05291885080956705\n",
      "train loss:0.04155371347797823\n",
      "train loss:0.1534296913264427\n",
      "train loss:0.01682359604323079\n",
      "train loss:0.05127514468431578\n",
      "train loss:0.09857138282495499\n",
      "train loss:0.02438859819018286\n",
      "train loss:0.03624366674156029\n",
      "train loss:0.09122266595802932\n",
      "train loss:0.06138966365963757\n",
      "train loss:0.035652466091988244\n",
      "train loss:0.010579737966664988\n",
      "train loss:0.028801871493920533\n",
      "train loss:0.020621095963670965\n",
      "train loss:0.022760274045514214\n",
      "train loss:0.08189251039643501\n",
      "train loss:0.07786880025027824\n",
      "train loss:0.01855040747897994\n",
      "train loss:0.05187970586584169\n",
      "train loss:0.01358337560357143\n",
      "train loss:0.07939620169790787\n",
      "train loss:0.0518743504285474\n",
      "train loss:0.08179718936279984\n",
      "train loss:0.09310325676729177\n",
      "train loss:0.01987406365543702\n",
      "train loss:0.029402588828794582\n",
      "train loss:0.10208721665336729\n",
      "train loss:0.04096064982753957\n",
      "train loss:0.06153420252785815\n",
      "train loss:0.08026381724109705\n",
      "train loss:0.040292407088501896\n",
      "train loss:0.038025062846697225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1168862009299474\n",
      "train loss:0.06737033946898002\n",
      "train loss:0.04708635429506856\n",
      "train loss:0.12264712889946905\n",
      "train loss:0.05185552127955557\n",
      "train loss:0.08375383300235979\n",
      "train loss:0.0118971925935834\n",
      "train loss:0.07699745112109467\n",
      "train loss:0.0497693819952075\n",
      "train loss:0.0322078199244653\n",
      "train loss:0.023928791903668766\n",
      "train loss:0.03488706469381101\n",
      "train loss:0.01801570890753671\n",
      "train loss:0.030386052350687316\n",
      "train loss:0.05588067723678757\n",
      "train loss:0.03447924668703914\n",
      "train loss:0.02533619445536664\n",
      "train loss:0.020853585321061404\n",
      "train loss:0.0687988796408985\n",
      "train loss:0.12917402345417675\n",
      "train loss:0.01842901175419603\n",
      "train loss:0.0469361194920139\n",
      "train loss:0.03676385008179374\n",
      "train loss:0.06897658220952922\n",
      "train loss:0.07090857958647508\n",
      "train loss:0.06371222603938759\n",
      "train loss:0.029042759190007587\n",
      "train loss:0.022037398397885644\n",
      "train loss:0.03863771028744503\n",
      "train loss:0.05487883979402098\n",
      "train loss:0.09783671719143928\n",
      "train loss:0.042211130683825634\n",
      "train loss:0.023400663663648263\n",
      "train loss:0.03104003765626253\n",
      "train loss:0.03261069735071178\n",
      "train loss:0.09177558838392877\n",
      "train loss:0.05318583724677637\n",
      "train loss:0.05123456191424714\n",
      "train loss:0.03803899522441845\n",
      "train loss:0.03760225883250886\n",
      "train loss:0.018711476009982683\n",
      "train loss:0.027468832281336775\n",
      "train loss:0.03943755442525334\n",
      "train loss:0.07070134659298336\n",
      "train loss:0.03301750269146284\n",
      "train loss:0.07215139579108175\n",
      "train loss:0.04221648989745992\n",
      "train loss:0.026368306085156844\n",
      "train loss:0.01130763102782984\n",
      "train loss:0.10201258982417864\n",
      "train loss:0.007966075200867704\n",
      "train loss:0.03818184988857009\n",
      "train loss:0.14575987195159515\n",
      "train loss:0.04508735002211019\n",
      "train loss:0.0501717744925421\n",
      "train loss:0.02076273487288214\n",
      "train loss:0.03762964559023541\n",
      "train loss:0.03784051388150789\n",
      "train loss:0.022526612384823865\n",
      "train loss:0.04228412023535318\n",
      "train loss:0.04208090436696534\n",
      "train loss:0.09580997288412486\n",
      "train loss:0.06313132385307699\n",
      "train loss:0.0429961586324975\n",
      "train loss:0.08050813531032537\n",
      "train loss:0.04281020226845821\n",
      "train loss:0.07174722195098934\n",
      "train loss:0.05959133736303673\n",
      "train loss:0.032181963974964665\n",
      "train loss:0.048564442671770125\n",
      "train loss:0.0544644391993292\n",
      "train loss:0.024074163440157944\n",
      "train loss:0.017376718755802326\n",
      "train loss:0.07249663982993955\n",
      "train loss:0.03961079350301393\n",
      "train loss:0.052017477230232506\n",
      "train loss:0.014970936489306703\n",
      "train loss:0.02895688227851491\n",
      "train loss:0.019118572914077744\n",
      "train loss:0.01787319063861763\n",
      "train loss:0.02250843291358381\n",
      "train loss:0.03223808611781697\n",
      "train loss:0.03666242831966644\n",
      "train loss:0.015523689449492319\n",
      "train loss:0.02829387417424649\n",
      "train loss:0.05285080406186157\n",
      "train loss:0.007168678737693156\n",
      "train loss:0.1119001175228016\n",
      "train loss:0.047626769184533735\n",
      "train loss:0.00930018536723694\n",
      "train loss:0.01862222653768744\n",
      "train loss:0.026896653455561602\n",
      "train loss:0.05044559435585047\n",
      "train loss:0.018027822627838343\n",
      "train loss:0.032682777363252064\n",
      "train loss:0.05192121640518744\n",
      "train loss:0.0819685913436631\n",
      "train loss:0.026453712240314068\n",
      "train loss:0.034030526458379826\n",
      "train loss:0.016592927579521438\n",
      "train loss:0.014219369586962363\n",
      "train loss:0.02075354906269016\n",
      "train loss:0.0423749437037303\n",
      "train loss:0.03068852196013172\n",
      "train loss:0.09169875298955621\n",
      "train loss:0.08819541833846183\n",
      "train loss:0.021014011873354853\n",
      "train loss:0.09220845918472684\n",
      "train loss:0.056668543605666616\n",
      "train loss:0.02227764117098455\n",
      "train loss:0.028031257166914313\n",
      "train loss:0.03260536921950064\n",
      "train loss:0.031216156677294195\n",
      "train loss:0.05766041905218119\n",
      "train loss:0.03552793530368299\n",
      "train loss:0.04428603458701362\n",
      "train loss:0.03713936429349461\n",
      "train loss:0.06656370044743641\n",
      "train loss:0.09379972541910378\n",
      "train loss:0.03506037732101601\n",
      "train loss:0.011440388273492506\n",
      "train loss:0.06821011451351308\n",
      "train loss:0.1506238895272011\n",
      "train loss:0.028398677600822934\n",
      "train loss:0.04998036285087089\n",
      "train loss:0.07729938788817292\n",
      "train loss:0.09885638918428134\n",
      "train loss:0.050460623694511264\n",
      "train loss:0.067184984547593\n",
      "train loss:0.03151972259276838\n",
      "train loss:0.0688865680801531\n",
      "train loss:0.06360984510171298\n",
      "train loss:0.03564124044953164\n",
      "train loss:0.06222937387092962\n",
      "train loss:0.019539266082677875\n",
      "train loss:0.036322013733243896\n",
      "train loss:0.07915444315654081\n",
      "train loss:0.031003843503359357\n",
      "train loss:0.020129629623786175\n",
      "train loss:0.09620354582071476\n",
      "train loss:0.01775417191808311\n",
      "train loss:0.03772029190865386\n",
      "train loss:0.029171708671117066\n",
      "train loss:0.06558263935676306\n",
      "train loss:0.07895880386116044\n",
      "train loss:0.015164548433862229\n",
      "train loss:0.0638153949975756\n",
      "train loss:0.0446300746857621\n",
      "train loss:0.08650686461346863\n",
      "train loss:0.03264396947326449\n",
      "train loss:0.09886345957529696\n",
      "train loss:0.06379398723846061\n",
      "train loss:0.022153678860477748\n",
      "train loss:0.012604366425533973\n",
      "train loss:0.04588736612985975\n",
      "train loss:0.01709756987415052\n",
      "train loss:0.05520880131205393\n",
      "train loss:0.029027515610947515\n",
      "train loss:0.08835646449466507\n",
      "train loss:0.05573421338383668\n",
      "train loss:0.027086320101770932\n",
      "train loss:0.029518576075340554\n",
      "train loss:0.04441232107827519\n",
      "train loss:0.031040411997772126\n",
      "train loss:0.04200140934704131\n",
      "train loss:0.03155659283090746\n",
      "train loss:0.027447194997193024\n",
      "train loss:0.034480914553817216\n",
      "train loss:0.0735385034931129\n",
      "train loss:0.03667904634143137\n",
      "train loss:0.07297961204683062\n",
      "train loss:0.06082690926217229\n",
      "train loss:0.1366307920269412\n",
      "train loss:0.07031867342162833\n",
      "train loss:0.06198234384831423\n",
      "train loss:0.028079382482503745\n",
      "train loss:0.06411145298320392\n",
      "train loss:0.0800913346723781\n",
      "train loss:0.06121007264821273\n",
      "train loss:0.014279767202401521\n",
      "train loss:0.042143551910088\n",
      "train loss:0.05051026489857836\n",
      "train loss:0.14045353825884427\n",
      "train loss:0.0944928594653922\n",
      "train loss:0.06487175928162289\n",
      "train loss:0.03568137951135827\n",
      "train loss:0.0917990914923649\n",
      "train loss:0.026752560715426373\n",
      "train loss:0.028201238364665166\n",
      "train loss:0.01980743655414202\n",
      "train loss:0.03151587152925775\n",
      "train loss:0.01844424853999839\n",
      "train loss:0.06822013399197178\n",
      "train loss:0.010174949373557845\n",
      "train loss:0.011826313338040547\n",
      "train loss:0.057969789487490535\n",
      "train loss:0.02524079836263515\n",
      "train loss:0.025283973181587257\n",
      "train loss:0.019670031972865896\n",
      "train loss:0.032747786963172716\n",
      "train loss:0.09694725809195603\n",
      "train loss:0.10271346128239989\n",
      "train loss:0.02764599676291568\n",
      "train loss:0.0563152603958163\n",
      "train loss:0.02772594670106459\n",
      "train loss:0.014377578561680116\n",
      "train loss:0.039913089809998435\n",
      "train loss:0.15486190025674762\n",
      "train loss:0.01635440878517888\n",
      "=== epoch:4, train acc:0.982, test acc:0.985 ===\n",
      "train loss:0.04258621943166846\n",
      "train loss:0.021686840373250985\n",
      "train loss:0.04409930589892623\n",
      "train loss:0.02670560071025124\n",
      "train loss:0.08835740655458448\n",
      "train loss:0.02104944204368382\n",
      "train loss:0.0461846893602128\n",
      "train loss:0.02960994909023448\n",
      "train loss:0.023227347135583408\n",
      "train loss:0.03134865784705248\n",
      "train loss:0.024346172505062342\n",
      "train loss:0.020667145360090896\n",
      "train loss:0.05283640182351938\n",
      "train loss:0.03133954122700782\n",
      "train loss:0.17391737316735212\n",
      "train loss:0.019973373962736712\n",
      "train loss:0.030218225744447092\n",
      "train loss:0.031274614785990765\n",
      "train loss:0.05586770199850459\n",
      "train loss:0.02244692552202668\n",
      "train loss:0.036630111533428905\n",
      "train loss:0.03963367890329927\n",
      "train loss:0.04320962821331289\n",
      "train loss:0.0821305799721397\n",
      "train loss:0.039004748049819286\n",
      "train loss:0.046473858783178314\n",
      "train loss:0.0065097298394767075\n",
      "train loss:0.012857523802240402\n",
      "train loss:0.035300815673055694\n",
      "train loss:0.010993342101848628\n",
      "train loss:0.039864758881854416\n",
      "train loss:0.033035088192818314\n",
      "train loss:0.05900685784843123\n",
      "train loss:0.03344428389344575\n",
      "train loss:0.1310737274736925\n",
      "train loss:0.06232696561917081\n",
      "train loss:0.029918764339045438\n",
      "train loss:0.020580131460952136\n",
      "train loss:0.026630072667636114\n",
      "train loss:0.013866923939905938\n",
      "train loss:0.10903423074398921\n",
      "train loss:0.027657827711127757\n",
      "train loss:0.012546340135055489\n",
      "train loss:0.03819887000417008\n",
      "train loss:0.01118736673687506\n",
      "train loss:0.018521516857678687\n",
      "train loss:0.07797871634124803\n",
      "train loss:0.12026131371201496\n",
      "train loss:0.0382518766990416\n",
      "train loss:0.07360287540878603\n",
      "train loss:0.023737152919633218\n",
      "train loss:0.010803785303105702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12775789600217433\n",
      "train loss:0.019434208461922006\n",
      "train loss:0.03866340324380111\n",
      "train loss:0.02482212180104038\n",
      "train loss:0.0603373222663817\n",
      "train loss:0.009380669504223588\n",
      "train loss:0.12344972592006362\n",
      "train loss:0.0291087312022732\n",
      "train loss:0.06812954975340191\n",
      "train loss:0.0729021000304964\n",
      "train loss:0.01669077702651055\n",
      "train loss:0.08022802833523328\n",
      "train loss:0.02112600886269617\n",
      "train loss:0.01932364289236508\n",
      "train loss:0.013395281380480318\n",
      "train loss:0.06815145165291488\n",
      "train loss:0.03543800619894513\n",
      "train loss:0.02358648843120763\n",
      "train loss:0.11264148680161283\n",
      "train loss:0.02654181507653537\n",
      "train loss:0.09241702749752685\n",
      "train loss:0.04466429757443745\n",
      "train loss:0.033801572679582795\n",
      "train loss:0.02890765567196076\n",
      "train loss:0.10712103498423264\n",
      "train loss:0.08229518051422625\n",
      "train loss:0.030145423178923547\n",
      "train loss:0.02498859846183293\n",
      "train loss:0.05946162998654698\n",
      "train loss:0.04400778936914012\n",
      "train loss:0.11538123818536804\n",
      "train loss:0.06483445236545077\n",
      "train loss:0.021771415104380857\n",
      "train loss:0.045097612808633614\n",
      "train loss:0.03967338041013336\n",
      "train loss:0.03830577307807937\n",
      "train loss:0.06676691711329587\n",
      "train loss:0.05046276956610504\n",
      "train loss:0.06178663821161183\n",
      "train loss:0.08654329423669647\n",
      "train loss:0.06072723030157641\n",
      "train loss:0.03705869445223347\n",
      "train loss:0.0299401015073722\n",
      "train loss:0.00976055929229653\n",
      "train loss:0.01590463959748688\n",
      "train loss:0.10913668713583632\n",
      "train loss:0.023946378983575326\n",
      "train loss:0.042561908368480054\n",
      "train loss:0.037157744833179636\n",
      "train loss:0.08928668844740273\n",
      "train loss:0.024156673951673487\n",
      "train loss:0.06653583446355758\n",
      "train loss:0.040087561494268106\n",
      "train loss:0.04372116802123868\n",
      "train loss:0.0368598476540335\n",
      "train loss:0.09391143454217014\n",
      "train loss:0.051897328598125465\n",
      "train loss:0.02073146082601539\n",
      "train loss:0.015433305883882453\n",
      "train loss:0.0711400624659418\n",
      "train loss:0.027798454556889916\n",
      "train loss:0.055699032730987606\n",
      "train loss:0.023008804536540906\n",
      "train loss:0.05167437669428164\n",
      "train loss:0.06135277045679053\n",
      "train loss:0.019143610258234703\n",
      "train loss:0.10095906065693837\n",
      "train loss:0.027079528425482512\n",
      "train loss:0.01684106748651527\n",
      "train loss:0.08822635322136753\n",
      "train loss:0.10826216512803916\n",
      "train loss:0.03740328180052454\n",
      "train loss:0.09238971158224075\n",
      "train loss:0.0486512570293794\n",
      "train loss:0.05045289429134026\n",
      "train loss:0.029440885863550294\n",
      "train loss:0.032226020886539426\n",
      "train loss:0.07605745784389727\n",
      "train loss:0.012608443800216442\n",
      "train loss:0.18447622955549264\n",
      "train loss:0.05061493334717139\n",
      "train loss:0.1256987863986895\n",
      "train loss:0.05397807850893428\n",
      "train loss:0.08212176485703125\n",
      "train loss:0.07524150449963707\n",
      "train loss:0.021840431693645385\n",
      "train loss:0.014469161649327133\n",
      "train loss:0.0162097278695147\n",
      "train loss:0.02818014959782992\n",
      "train loss:0.11844619788007707\n",
      "train loss:0.10850721145087924\n",
      "train loss:0.042946857931910214\n",
      "train loss:0.01809159507082318\n",
      "train loss:0.0685382933631817\n",
      "train loss:0.0258251270613408\n",
      "train loss:0.050500972404537825\n",
      "train loss:0.10262417393966049\n",
      "train loss:0.052476677782741066\n",
      "train loss:0.09222285410679433\n",
      "train loss:0.02892981979328235\n",
      "train loss:0.04697024681167677\n",
      "train loss:0.03686974311694123\n",
      "train loss:0.07243889728328497\n",
      "train loss:0.03499773278436996\n",
      "train loss:0.020424145642327512\n",
      "train loss:0.07188803067877882\n",
      "train loss:0.06555373130027593\n",
      "train loss:0.020647460807071943\n",
      "train loss:0.09909142849916876\n",
      "train loss:0.01442507337943841\n",
      "train loss:0.03867588973525534\n",
      "train loss:0.011841337520494205\n",
      "train loss:0.04047978856830934\n",
      "train loss:0.06396499625496949\n",
      "train loss:0.027326132955013373\n",
      "train loss:0.026085688263763895\n",
      "train loss:0.053334281131347\n",
      "train loss:0.06876889797969096\n",
      "train loss:0.047675358046416025\n",
      "train loss:0.018254017445586364\n",
      "train loss:0.037481792659619824\n",
      "train loss:0.03732688028060152\n",
      "train loss:0.03679823494941631\n",
      "train loss:0.020496467084041757\n",
      "train loss:0.01810436018500249\n",
      "train loss:0.019647664508821275\n",
      "train loss:0.023987472947940756\n",
      "train loss:0.03808799119431731\n",
      "train loss:0.018382746333719634\n",
      "train loss:0.03709699791325859\n",
      "train loss:0.007653566135576603\n",
      "train loss:0.02062458277042383\n",
      "train loss:0.009407564068025221\n",
      "train loss:0.07900792746674061\n",
      "train loss:0.008964411394506435\n",
      "train loss:0.05778373043022485\n",
      "train loss:0.05324496911652478\n",
      "train loss:0.08738360002595737\n",
      "train loss:0.033357540011288274\n",
      "train loss:0.044937094475422136\n",
      "train loss:0.0626984368946884\n",
      "train loss:0.03224950425360956\n",
      "train loss:0.08662418402283308\n",
      "train loss:0.033547513686796135\n",
      "train loss:0.021928239755903814\n",
      "train loss:0.07170756416747683\n",
      "train loss:0.05150874343482252\n",
      "train loss:0.024285476806478225\n",
      "train loss:0.044914696975089\n",
      "train loss:0.06859197092486398\n",
      "train loss:0.018996890996548554\n",
      "train loss:0.038768294911568364\n",
      "train loss:0.01587942908288952\n",
      "train loss:0.01082296438433562\n",
      "train loss:0.043494239900809716\n",
      "train loss:0.034780200023155905\n",
      "train loss:0.027000486479223658\n",
      "train loss:0.008732098503081388\n",
      "train loss:0.03671112653200585\n",
      "train loss:0.07577650737095235\n",
      "train loss:0.08803759392463237\n",
      "train loss:0.1092256154621315\n",
      "train loss:0.047231293147106806\n",
      "train loss:0.038735948739681676\n",
      "train loss:0.0561788126223581\n",
      "train loss:0.049999316665945655\n",
      "train loss:0.007459624640288732\n",
      "train loss:0.04960826581219882\n",
      "train loss:0.05950329714236739\n",
      "train loss:0.02480635690430875\n",
      "train loss:0.07821658977570366\n",
      "train loss:0.011297372572644553\n",
      "train loss:0.041620755670213665\n",
      "train loss:0.12068423339803071\n",
      "train loss:0.08689265217089526\n",
      "train loss:0.017575917977232097\n",
      "train loss:0.05854908344324332\n",
      "train loss:0.039840837151559706\n",
      "train loss:0.015502377272470452\n",
      "train loss:0.01747440770518581\n",
      "train loss:0.017490065834951146\n",
      "train loss:0.03366548952818516\n",
      "train loss:0.013797802880133556\n",
      "train loss:0.0585049032969892\n",
      "train loss:0.02457647081455381\n",
      "train loss:0.009840072736130284\n",
      "train loss:0.03517750842780757\n",
      "train loss:0.051324007642914914\n",
      "train loss:0.03902772951423861\n",
      "train loss:0.018264282260843617\n",
      "train loss:0.051482770883001405\n",
      "train loss:0.011056034099036731\n",
      "train loss:0.04689876387070584\n",
      "train loss:0.022680586428757556\n",
      "train loss:0.008502208876185816\n",
      "train loss:0.05918555640219014\n",
      "train loss:0.0346428508691091\n",
      "train loss:0.006938402493181568\n",
      "train loss:0.04108241368213033\n",
      "train loss:0.015355383937154793\n",
      "train loss:0.03313511169645431\n",
      "train loss:0.07226255485887882\n",
      "train loss:0.04379899438313045\n",
      "train loss:0.018008896179009623\n",
      "train loss:0.02108690869455142\n",
      "train loss:0.045118064700272714\n",
      "train loss:0.05572517927833099\n",
      "train loss:0.04897689684838363\n",
      "train loss:0.03486457749195059\n",
      "train loss:0.08342011564180384\n",
      "train loss:0.07754951783194403\n",
      "train loss:0.04145056873143675\n",
      "train loss:0.04765308126364109\n",
      "train loss:0.01808015464465346\n",
      "train loss:0.047962780914589394\n",
      "train loss:0.06844828466466325\n",
      "train loss:0.03159496048118457\n",
      "train loss:0.027687072827148364\n",
      "train loss:0.030695598553282723\n",
      "train loss:0.05091876512236536\n",
      "train loss:0.01467814413515577\n",
      "train loss:0.13894997982817553\n",
      "train loss:0.01504343999051256\n",
      "train loss:0.033350786503753865\n",
      "train loss:0.03532178769959205\n",
      "train loss:0.046067900430013395\n",
      "train loss:0.014424319756954837\n",
      "train loss:0.023969187361644134\n",
      "train loss:0.03719327268529258\n",
      "train loss:0.018081605242442483\n",
      "train loss:0.031181323670827484\n",
      "train loss:0.04030917368478039\n",
      "train loss:0.08623337638337494\n",
      "train loss:0.106825294900037\n",
      "train loss:0.03470120548144174\n",
      "train loss:0.017274070508691154\n",
      "train loss:0.018734220903131663\n",
      "train loss:0.02298394868535443\n",
      "train loss:0.039205333736969855\n",
      "train loss:0.02839327085280784\n",
      "train loss:0.09998017673964853\n",
      "train loss:0.14286253740405144\n",
      "train loss:0.054995048800950096\n",
      "train loss:0.01934147508226007\n",
      "train loss:0.043963447768125725\n",
      "train loss:0.015831705688245913\n",
      "train loss:0.022932679597426456\n",
      "train loss:0.035873346709236476\n",
      "train loss:0.05676679488410144\n",
      "train loss:0.009005870881922338\n",
      "train loss:0.04063671849966141\n",
      "train loss:0.007263434288669894\n",
      "train loss:0.018124091503457295\n",
      "train loss:0.03549717986847143\n",
      "train loss:0.009008535551855908\n",
      "train loss:0.034651555257321186\n",
      "train loss:0.03441925450534312\n",
      "train loss:0.10610272139019297\n",
      "train loss:0.02671562123844895\n",
      "train loss:0.014858574698985565\n",
      "train loss:0.01493794533875649\n",
      "train loss:0.02347905006540485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.027486723833608825\n",
      "train loss:0.04515229318256773\n",
      "train loss:0.02494083695727173\n",
      "train loss:0.007405961509974279\n",
      "train loss:0.009330942751372745\n",
      "train loss:0.034069625237126255\n",
      "train loss:0.020899415575167248\n",
      "train loss:0.021129456831134225\n",
      "train loss:0.0128596479514352\n",
      "train loss:0.0520120757307907\n",
      "train loss:0.024195114343784768\n",
      "train loss:0.013493661224287651\n",
      "train loss:0.015857948536089073\n",
      "train loss:0.028124534018878423\n",
      "train loss:0.013593392604487702\n",
      "train loss:0.03971047052823363\n",
      "train loss:0.041749950990167664\n",
      "train loss:0.013282364729456849\n",
      "train loss:0.017065264449418832\n",
      "train loss:0.03729058084266451\n",
      "train loss:0.036342418410214836\n",
      "train loss:0.06810990620812624\n",
      "train loss:0.016840253618407887\n",
      "train loss:0.006782398580868277\n",
      "train loss:0.018317419398802513\n",
      "train loss:0.027780066031645574\n",
      "train loss:0.03181711257151516\n",
      "train loss:0.02027631661108126\n",
      "train loss:0.006627377536255614\n",
      "train loss:0.020982893545239457\n",
      "train loss:0.010016001212615843\n",
      "train loss:0.03020113039102352\n",
      "train loss:0.010694716202698922\n",
      "train loss:0.07210051700093847\n",
      "train loss:0.04378825282849867\n",
      "train loss:0.11828088354732542\n",
      "train loss:0.010746193818194949\n",
      "train loss:0.03278689006437034\n",
      "train loss:0.08531174110173\n",
      "train loss:0.02959088469699767\n",
      "train loss:0.016060443014886117\n",
      "train loss:0.018182307879308045\n",
      "train loss:0.03103971949683071\n",
      "train loss:0.03183728850158464\n",
      "train loss:0.04206148622930943\n",
      "train loss:0.007742326391020713\n",
      "train loss:0.06685597009698553\n",
      "train loss:0.013834147578969273\n",
      "train loss:0.01962204600984755\n",
      "train loss:0.018974668919051748\n",
      "train loss:0.03322192553720735\n",
      "train loss:0.031105985818681337\n",
      "train loss:0.010931181103014307\n",
      "train loss:0.040884679511805536\n",
      "train loss:0.04060670961312527\n",
      "train loss:0.04509967414263461\n",
      "train loss:0.006556356343493901\n",
      "train loss:0.046852425461539754\n",
      "train loss:0.018233604677426404\n",
      "train loss:0.01915406128071981\n",
      "train loss:0.021279814181950244\n",
      "train loss:0.020564644312807977\n",
      "train loss:0.04711449844449537\n",
      "train loss:0.04215031607886197\n",
      "train loss:0.12332089658139007\n",
      "train loss:0.08295874294979112\n",
      "train loss:0.05224095845694541\n",
      "train loss:0.033695962991185296\n",
      "train loss:0.0354066067392813\n",
      "train loss:0.03967313909176677\n",
      "train loss:0.020075940281788985\n",
      "train loss:0.02632004611689481\n",
      "train loss:0.05564869662467481\n",
      "train loss:0.0318602444056745\n",
      "train loss:0.03573103104341935\n",
      "train loss:0.061644768980587426\n",
      "train loss:0.0335230121079107\n",
      "train loss:0.08566545468658457\n",
      "train loss:0.021725300592774565\n",
      "train loss:0.04804966930793857\n",
      "train loss:0.0419782097645981\n",
      "train loss:0.00870080555223714\n",
      "train loss:0.06412564462755344\n",
      "train loss:0.01827537503354485\n",
      "train loss:0.007749077523172697\n",
      "train loss:0.010054302623579146\n",
      "train loss:0.035151708348192374\n",
      "train loss:0.09376542780352365\n",
      "train loss:0.024211107334403216\n",
      "train loss:0.030424116155072546\n",
      "train loss:0.03568932283642326\n",
      "train loss:0.01956727346282699\n",
      "train loss:0.038321592520281535\n",
      "train loss:0.07917217826286625\n",
      "train loss:0.08049400853285514\n",
      "train loss:0.060278970013734195\n",
      "train loss:0.021462864387824784\n",
      "train loss:0.020198973100568472\n",
      "train loss:0.030414290678301256\n",
      "train loss:0.06789606985888677\n",
      "train loss:0.03571104513820123\n",
      "train loss:0.15052381911147777\n",
      "train loss:0.025689696051824643\n",
      "train loss:0.011061272624310831\n",
      "train loss:0.09816096791561905\n",
      "train loss:0.025059372668476545\n",
      "train loss:0.03603144496177041\n",
      "train loss:0.022153302575945628\n",
      "train loss:0.040279907233196785\n",
      "train loss:0.029246574973724907\n",
      "train loss:0.05003247369054156\n",
      "train loss:0.014844378319922493\n",
      "train loss:0.03145375396417287\n",
      "train loss:0.03915277569833389\n",
      "train loss:0.062319546404356524\n",
      "train loss:0.05062698944280391\n",
      "train loss:0.07035085456971053\n",
      "train loss:0.07893379783244392\n",
      "train loss:0.043848633075356656\n",
      "train loss:0.02794827865205805\n",
      "train loss:0.019267653132457506\n",
      "train loss:0.025573255465847832\n",
      "train loss:0.036300673540067295\n",
      "train loss:0.019992460409015648\n",
      "train loss:0.02635299437655099\n",
      "train loss:0.019292275233366286\n",
      "train loss:0.03554333229121903\n",
      "train loss:0.055064982130763704\n",
      "train loss:0.1512683711647509\n",
      "train loss:0.05125774384105696\n",
      "train loss:0.025767770811429547\n",
      "train loss:0.09893710802322486\n",
      "train loss:0.013297362655512623\n",
      "train loss:0.02899613203838717\n",
      "train loss:0.04466470180290336\n",
      "train loss:0.018967298465056123\n",
      "train loss:0.04123049775664378\n",
      "train loss:0.030049425617301295\n",
      "train loss:0.028485971350005173\n",
      "train loss:0.059328220970840874\n",
      "train loss:0.03311704657020769\n",
      "train loss:0.033593063420760176\n",
      "train loss:0.03429032683037558\n",
      "train loss:0.0451199123494545\n",
      "train loss:0.033488417473723685\n",
      "train loss:0.04090405739726\n",
      "train loss:0.030720058661328414\n",
      "train loss:0.05039299527880124\n",
      "train loss:0.035989566903653784\n",
      "train loss:0.00867966630048115\n",
      "train loss:0.03948150894401468\n",
      "train loss:0.06739040550281204\n",
      "train loss:0.07599915050814372\n",
      "train loss:0.009077943807100608\n",
      "train loss:0.0169772239397558\n",
      "train loss:0.00960368832212661\n",
      "train loss:0.041300775893542196\n",
      "train loss:0.042220875280392055\n",
      "train loss:0.06130812087066999\n",
      "train loss:0.027309395734485674\n",
      "train loss:0.03190538912316825\n",
      "train loss:0.007676693938849026\n",
      "train loss:0.03907683979919427\n",
      "train loss:0.019323838234806955\n",
      "train loss:0.032927002480191994\n",
      "train loss:0.03468118974316827\n",
      "train loss:0.033012184043295034\n",
      "train loss:0.026819099668569595\n",
      "train loss:0.052229359603293564\n",
      "train loss:0.013023521646867188\n",
      "train loss:0.04853573195060568\n",
      "train loss:0.023157305035098708\n",
      "train loss:0.05055104032169223\n",
      "train loss:0.07488758024333879\n",
      "train loss:0.03687744878817334\n",
      "train loss:0.011752487231542064\n",
      "train loss:0.014264077181585096\n",
      "train loss:0.016202209664360236\n",
      "train loss:0.020476991070589548\n",
      "train loss:0.05518470479668862\n",
      "train loss:0.0419654405293444\n",
      "train loss:0.08248398233835134\n",
      "train loss:0.030423407289434802\n",
      "train loss:0.013524505385337575\n",
      "train loss:0.02023080319368491\n",
      "train loss:0.04007166862582979\n",
      "train loss:0.019990734235424724\n",
      "train loss:0.04662819672745318\n",
      "train loss:0.041081375868369206\n",
      "train loss:0.06204740457109215\n",
      "train loss:0.017842854822389786\n",
      "train loss:0.08726139239040558\n",
      "train loss:0.04630291922269681\n",
      "train loss:0.11849323962673212\n",
      "train loss:0.0354106673538819\n",
      "train loss:0.017724108668310982\n",
      "train loss:0.07820001285354504\n",
      "train loss:0.08128245786138326\n",
      "train loss:0.0169514797732105\n",
      "train loss:0.032732694730192156\n",
      "train loss:0.039684315592493635\n",
      "train loss:0.05188168173525774\n",
      "train loss:0.007507826641557305\n",
      "train loss:0.011459649540021962\n",
      "train loss:0.008408336974604991\n",
      "train loss:0.0676872283343754\n",
      "train loss:0.04632547246573766\n",
      "train loss:0.007188194932213174\n",
      "train loss:0.00734263331214966\n",
      "train loss:0.028317332870496953\n",
      "train loss:0.03612114499084765\n",
      "train loss:0.013359163224846198\n",
      "train loss:0.03468990522572581\n",
      "train loss:0.006888450656772338\n",
      "train loss:0.056586948205726816\n",
      "train loss:0.06204993651240894\n",
      "train loss:0.01512231246786154\n",
      "train loss:0.014015056102028942\n",
      "train loss:0.03844475480754854\n",
      "train loss:0.013878077983444015\n",
      "train loss:0.03575082479851674\n",
      "train loss:0.023142873628448614\n",
      "train loss:0.08119583881421347\n",
      "train loss:0.029300930940200528\n",
      "train loss:0.01068100504844681\n",
      "train loss:0.044605266250001836\n",
      "train loss:0.003532876251417304\n",
      "train loss:0.02791671295357233\n",
      "train loss:0.0075262461406946915\n",
      "train loss:0.05476674777310062\n",
      "train loss:0.034625619982115566\n",
      "train loss:0.020649114095465115\n",
      "train loss:0.03237651207706196\n",
      "train loss:0.028224996829807017\n",
      "train loss:0.03368610057072793\n",
      "train loss:0.06175899480460484\n",
      "train loss:0.02280838137004542\n",
      "train loss:0.04752423833546028\n",
      "train loss:0.029090675083804397\n",
      "train loss:0.02718461641387674\n",
      "train loss:0.008758879719301622\n",
      "train loss:0.009937316493698363\n",
      "train loss:0.025266581238342994\n",
      "train loss:0.01510370154645146\n",
      "train loss:0.0053837235856569\n",
      "train loss:0.08271028987177909\n",
      "train loss:0.03387124405860392\n",
      "train loss:0.011286768392280535\n",
      "train loss:0.018928965709089498\n",
      "train loss:0.03759971726730051\n",
      "train loss:0.028355561065653033\n",
      "train loss:0.08698046156751608\n",
      "train loss:0.04458138336980801\n",
      "train loss:0.03880363575108458\n",
      "train loss:0.012500421935409291\n",
      "train loss:0.0185183612231949\n",
      "train loss:0.009845656721405664\n",
      "train loss:0.016507773649175984\n",
      "train loss:0.018254481678581184\n",
      "train loss:0.07429184505389527\n",
      "train loss:0.010953438764671872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016612516499046402\n",
      "train loss:0.01795603989572841\n",
      "train loss:0.03601712462701721\n",
      "train loss:0.057131520779553885\n",
      "train loss:0.03860905478104457\n",
      "train loss:0.09094740935700106\n",
      "train loss:0.0035882290182107724\n",
      "train loss:0.03249999208717249\n",
      "train loss:0.016677421802729738\n",
      "train loss:0.016395982313856118\n",
      "train loss:0.031038116048459123\n",
      "train loss:0.014363988629126863\n",
      "train loss:0.028080331261549425\n",
      "train loss:0.008414645431048327\n",
      "train loss:0.013123452923095896\n",
      "train loss:0.03581618241190517\n",
      "train loss:0.06690080987687808\n",
      "train loss:0.028803144949060288\n",
      "train loss:0.00568454062300378\n",
      "train loss:0.03450751637768428\n",
      "train loss:0.06519177501570106\n",
      "train loss:0.05446343736926914\n",
      "train loss:0.032875449758004285\n",
      "train loss:0.017762727456266406\n",
      "train loss:0.027186688692243097\n",
      "=== epoch:5, train acc:0.985, test acc:0.981 ===\n",
      "train loss:0.017962275944008458\n",
      "train loss:0.03491851104446586\n",
      "train loss:0.03971773898803183\n",
      "train loss:0.01444561306244306\n",
      "train loss:0.03250718335184251\n",
      "train loss:0.0075684976872511436\n",
      "train loss:0.028477247904157062\n",
      "train loss:0.024390126268833703\n",
      "train loss:0.1053128078160457\n",
      "train loss:0.030806372567584783\n",
      "train loss:0.011482318964457349\n",
      "train loss:0.04925677371025536\n",
      "train loss:0.014345622310829536\n",
      "train loss:0.015719215597591464\n",
      "train loss:0.038764465607056875\n",
      "train loss:0.029537796785329546\n",
      "train loss:0.018106926039601214\n",
      "train loss:0.033088121455030386\n",
      "train loss:0.01341809538637948\n",
      "train loss:0.027183456261805797\n",
      "train loss:0.037692870612886516\n",
      "train loss:0.022728904813314563\n",
      "train loss:0.03361288048902019\n",
      "train loss:0.017396732116928413\n",
      "train loss:0.009592555081906479\n",
      "train loss:0.024167107202139028\n",
      "train loss:0.018137167510861862\n",
      "train loss:0.03492531553106584\n",
      "train loss:0.0665449641972637\n",
      "train loss:0.008624536836322794\n",
      "train loss:0.005757400438870011\n",
      "train loss:0.028970982243687472\n",
      "train loss:0.025558226667523748\n",
      "train loss:0.022953369293053957\n",
      "train loss:0.06556208833262889\n",
      "train loss:0.01633176352931832\n",
      "train loss:0.03789972877167821\n",
      "train loss:0.019949478481703985\n",
      "train loss:0.020023928186852936\n",
      "train loss:0.014043552460743252\n",
      "train loss:0.023761499308458705\n",
      "train loss:0.04101150890940805\n",
      "train loss:0.018894895202795792\n",
      "train loss:0.015736202055401608\n",
      "train loss:0.012104634052475803\n",
      "train loss:0.013348325127668542\n",
      "train loss:0.0254275160867505\n",
      "train loss:0.02792819363963198\n",
      "train loss:0.03936205196215404\n",
      "train loss:0.01644879999545648\n",
      "train loss:0.05795007563228758\n",
      "train loss:0.006679157816986265\n",
      "train loss:0.008303836807158689\n",
      "train loss:0.013606705143970449\n",
      "train loss:0.028104625310794874\n",
      "train loss:0.019965538468193163\n",
      "train loss:0.0055360333774564065\n",
      "train loss:0.012847500324623416\n",
      "train loss:0.01032778834915851\n",
      "train loss:0.061281161326312894\n",
      "train loss:0.006505098119606133\n",
      "train loss:0.004073153094390378\n",
      "train loss:0.01464675050737084\n",
      "train loss:0.030965896406234858\n",
      "train loss:0.01775654092459568\n",
      "train loss:0.016759594445878778\n",
      "train loss:0.07531782845849296\n",
      "train loss:0.04305659253593283\n",
      "train loss:0.04586844326288424\n",
      "train loss:0.008158363956024673\n",
      "train loss:0.014694282193424713\n",
      "train loss:0.047229826422944085\n",
      "train loss:0.022224513955079933\n",
      "train loss:0.006507125671626992\n",
      "train loss:0.022470477651815205\n",
      "train loss:0.025628776126277498\n",
      "train loss:0.019617609278360582\n",
      "train loss:0.014009346345401328\n",
      "train loss:0.027117614876328286\n",
      "train loss:0.013999183242058654\n",
      "train loss:0.041439968891294275\n",
      "train loss:0.031053962744276357\n",
      "train loss:0.007047687122734066\n",
      "train loss:0.0038115988349293668\n",
      "train loss:0.023441165643622065\n",
      "train loss:0.024898555133431182\n",
      "train loss:0.01368869434012586\n",
      "train loss:0.04492895810300631\n",
      "train loss:0.016039380762934305\n",
      "train loss:0.0041294536387506235\n",
      "train loss:0.025195790727702946\n",
      "train loss:0.0188410092812723\n",
      "train loss:0.051848480113929646\n",
      "train loss:0.0258536937809858\n",
      "train loss:0.012674226231148914\n",
      "train loss:0.019285121275888994\n",
      "train loss:0.02935033402587114\n",
      "train loss:0.04739274262176493\n",
      "train loss:0.006459088193106814\n",
      "train loss:0.04961722680528405\n",
      "train loss:0.017312616888743308\n",
      "train loss:0.005578177783565874\n",
      "train loss:0.03187519122586409\n",
      "train loss:0.11917497020443278\n",
      "train loss:0.1237286962182948\n",
      "train loss:0.007445805168122842\n",
      "train loss:0.019166474023764164\n",
      "train loss:0.0040451725342103\n",
      "train loss:0.019858210019920875\n",
      "train loss:0.040813999942317644\n",
      "train loss:0.02004942928472555\n",
      "train loss:0.06168003811678959\n",
      "train loss:0.013383364594098461\n",
      "train loss:0.031469537115173994\n",
      "train loss:0.0052796120261408295\n",
      "train loss:0.04957389059113416\n",
      "train loss:0.018058965921115902\n",
      "train loss:0.023315573874292343\n",
      "train loss:0.007036778480095314\n",
      "train loss:0.02009973823227905\n",
      "train loss:0.007181964220581713\n",
      "train loss:0.01340678802873539\n",
      "train loss:0.0015292209226896092\n",
      "train loss:0.014712591004004332\n",
      "train loss:0.017615195454390258\n",
      "train loss:0.04358285453027558\n",
      "train loss:0.02080494001011116\n",
      "train loss:0.0361946524099136\n",
      "train loss:0.009275632603483304\n",
      "train loss:0.005882340602353868\n",
      "train loss:0.04945885789319099\n",
      "train loss:0.015064729142510926\n",
      "train loss:0.029202587237026803\n",
      "train loss:0.019350395235403578\n",
      "train loss:0.09830369526647799\n",
      "train loss:0.010580776649875577\n",
      "train loss:0.04098193377508854\n",
      "train loss:0.02472756786736361\n",
      "train loss:0.0260239509943218\n",
      "train loss:0.005676475784372168\n",
      "train loss:0.03551189461613392\n",
      "train loss:0.04184887527785275\n",
      "train loss:0.05445751557189566\n",
      "train loss:0.0368646452240233\n",
      "train loss:0.00841139613883195\n",
      "train loss:0.027398500062684236\n",
      "train loss:0.04720518196063557\n",
      "train loss:0.016094082190338102\n",
      "train loss:0.04558887732082256\n",
      "train loss:0.049780737106166144\n",
      "train loss:0.05464113669558662\n",
      "train loss:0.014965132962214207\n",
      "train loss:0.008945873099121964\n",
      "train loss:0.03132579178555838\n",
      "train loss:0.06714808523669374\n",
      "train loss:0.014968484713209284\n",
      "train loss:0.004384321821000483\n",
      "train loss:0.033396158130010734\n",
      "train loss:0.05568296088865985\n",
      "train loss:0.04317620745293093\n",
      "train loss:0.01985051542141086\n",
      "train loss:0.020597008216182235\n",
      "train loss:0.04040354580237605\n",
      "train loss:0.021064134604391254\n",
      "train loss:0.03548263485857305\n",
      "train loss:0.02612660977492927\n",
      "train loss:0.021202674745667997\n",
      "train loss:0.02720003022790629\n",
      "train loss:0.0372195296341589\n",
      "train loss:0.023710891618648647\n",
      "train loss:0.06322772703390515\n",
      "train loss:0.01735855562014725\n",
      "train loss:0.011912762239054004\n",
      "train loss:0.009677878725236334\n",
      "train loss:0.01750606122023121\n",
      "train loss:0.011438132800577407\n",
      "train loss:0.03266142906753465\n",
      "train loss:0.021637757760333217\n",
      "train loss:0.04131546002567367\n",
      "train loss:0.01992176094549783\n",
      "train loss:0.019832937741346996\n",
      "train loss:0.01828730141232817\n",
      "train loss:0.04523887744808947\n",
      "train loss:0.07027004766043732\n",
      "train loss:0.05344493979649389\n",
      "train loss:0.019620624727344504\n",
      "train loss:0.016450529714959247\n",
      "train loss:0.0347512617877062\n",
      "train loss:0.013134771468092436\n",
      "train loss:0.018409958552265775\n",
      "train loss:0.03431604874148526\n",
      "train loss:0.006507483705022449\n",
      "train loss:0.0711142338174185\n",
      "train loss:0.010020828887930515\n",
      "train loss:0.09324021437932123\n",
      "train loss:0.012025066150090795\n",
      "train loss:0.030694262774728042\n",
      "train loss:0.032384716531571836\n",
      "train loss:0.03813693548979305\n",
      "train loss:0.03487403996985112\n",
      "train loss:0.016642379877365446\n",
      "train loss:0.006372779447206512\n",
      "train loss:0.035657094039574976\n",
      "train loss:0.03551581239152697\n",
      "train loss:0.04826513922466685\n",
      "train loss:0.03758799553257795\n",
      "train loss:0.06496870792580216\n",
      "train loss:0.04460451725762577\n",
      "train loss:0.01117333573650881\n",
      "train loss:0.01481002421581174\n",
      "train loss:0.009286577578498352\n",
      "train loss:0.01308052210166689\n",
      "train loss:0.05986981305973518\n",
      "train loss:0.026105300070109097\n",
      "train loss:0.059023223725161084\n",
      "train loss:0.02181727572118237\n",
      "train loss:0.026775861095888528\n",
      "train loss:0.03052967546226958\n",
      "train loss:0.020151547531794774\n",
      "train loss:0.0026154319316851276\n",
      "train loss:0.025237944900205495\n",
      "train loss:0.01536447752011655\n",
      "train loss:0.03697614441254467\n",
      "train loss:0.013841351173162209\n",
      "train loss:0.01210514610926085\n",
      "train loss:0.020544700221290273\n",
      "train loss:0.03727945053789169\n",
      "train loss:0.03348894170279725\n",
      "train loss:0.0045505031184709\n",
      "train loss:0.05985106558270016\n",
      "train loss:0.032579255675035904\n",
      "train loss:0.003034026993840441\n",
      "train loss:0.038109766266981406\n",
      "train loss:0.01712208144113593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07319174510928876\n",
      "train loss:0.044752246499844626\n",
      "train loss:0.022746922677626714\n",
      "train loss:0.013719934971898473\n",
      "train loss:0.014920503889535135\n",
      "train loss:0.01735188032777396\n",
      "train loss:0.07732519503038092\n",
      "train loss:0.051880757285039936\n",
      "train loss:0.00585849736442557\n",
      "train loss:0.006707077218621382\n",
      "train loss:0.13339720411945832\n",
      "train loss:0.028147663244358027\n",
      "train loss:0.023772815979099863\n",
      "train loss:0.029953113380514686\n",
      "train loss:0.026363512302831897\n",
      "train loss:0.02750549171312571\n",
      "train loss:0.06657012719030092\n",
      "train loss:0.029992537727184083\n",
      "train loss:0.04403124007069116\n",
      "train loss:0.06826579190350418\n",
      "train loss:0.021631376899194095\n",
      "train loss:0.010681213869769052\n",
      "train loss:0.025408599797103477\n",
      "train loss:0.05278809000538056\n",
      "train loss:0.012614425748011424\n",
      "train loss:0.023453576513812142\n",
      "train loss:0.05379514419291784\n",
      "train loss:0.03314404480750628\n",
      "train loss:0.12657565369179768\n",
      "train loss:0.016896206165327495\n",
      "train loss:0.006944559760536584\n",
      "train loss:0.03139847380859401\n",
      "train loss:0.06874421807127583\n",
      "train loss:0.004927198061076291\n",
      "train loss:0.07738878128140274\n",
      "train loss:0.05463953222994701\n",
      "train loss:0.01246130613533617\n",
      "train loss:0.02904058454009771\n",
      "train loss:0.0400479936964476\n",
      "train loss:0.021723897182574028\n",
      "train loss:0.0278261779118374\n",
      "train loss:0.03976211865993759\n",
      "train loss:0.01761749735504991\n",
      "train loss:0.18838509666279435\n",
      "train loss:0.0259038149188044\n",
      "train loss:0.02420886714822408\n",
      "train loss:0.009162064912769375\n",
      "train loss:0.05650991040465717\n",
      "train loss:0.0477611927164186\n",
      "train loss:0.030856929601445256\n",
      "train loss:0.06702060227905499\n",
      "train loss:0.012189655857899178\n",
      "train loss:0.06050070686282336\n",
      "train loss:0.015034258578153614\n",
      "train loss:0.006646334086833773\n",
      "train loss:0.08641797209977269\n",
      "train loss:0.011274496577156042\n",
      "train loss:0.019640687408742398\n",
      "train loss:0.05560584224422066\n",
      "train loss:0.004697742852621259\n",
      "train loss:0.027688764490852048\n",
      "train loss:0.01429077063955193\n",
      "train loss:0.021414968527850034\n",
      "train loss:0.014532111227443563\n",
      "train loss:0.05264299947836307\n",
      "train loss:0.023334322803222677\n",
      "train loss:0.009136210599148327\n",
      "train loss:0.0525956393309469\n",
      "train loss:0.009915790591699988\n",
      "train loss:0.03397128156103612\n",
      "train loss:0.04540859408568651\n",
      "train loss:0.025508779421439233\n",
      "train loss:0.030817254300108822\n",
      "train loss:0.007062804335839243\n",
      "train loss:0.030530333922627627\n",
      "train loss:0.015449693554800227\n",
      "train loss:0.010166536961062783\n",
      "train loss:0.04421701594877844\n",
      "train loss:0.014168370443637602\n",
      "train loss:0.0278520914606826\n",
      "train loss:0.012742840667613173\n",
      "train loss:0.013397894904421203\n",
      "train loss:0.020556067913792334\n",
      "train loss:0.01663212843527371\n",
      "train loss:0.00848990829304594\n",
      "train loss:0.02462032187443992\n",
      "train loss:0.049624661064404496\n",
      "train loss:0.0070454661683295935\n",
      "train loss:0.037807942678643555\n",
      "train loss:0.014928487367041492\n",
      "train loss:0.00791323339838828\n",
      "train loss:0.01028338462459295\n",
      "train loss:0.0498744494889092\n",
      "train loss:0.02911766578510865\n",
      "train loss:0.011348406398281491\n",
      "train loss:0.018415754956552642\n",
      "train loss:0.029468557556295304\n",
      "train loss:0.02267555972372045\n",
      "train loss:0.10148117735722371\n",
      "train loss:0.05451800980338905\n",
      "train loss:0.030241795016403113\n",
      "train loss:0.003264126367107242\n",
      "train loss:0.006349789349327168\n",
      "train loss:0.0062528526691871976\n",
      "train loss:0.010942595660141451\n",
      "train loss:0.03965097785659532\n",
      "train loss:0.004140687364834956\n",
      "train loss:0.018239581929127904\n",
      "train loss:0.006578541500196775\n",
      "train loss:0.04074603133309974\n",
      "train loss:0.0054626586536782986\n",
      "train loss:0.003568459160403246\n",
      "train loss:0.015013469255576672\n",
      "train loss:0.028746657874238624\n",
      "train loss:0.07417504531477057\n",
      "train loss:0.02871308521241483\n",
      "train loss:0.034025063172079296\n",
      "train loss:0.013145717059551585\n",
      "train loss:0.017719409886576568\n",
      "train loss:0.021238479166185615\n",
      "train loss:0.009935872219650208\n",
      "train loss:0.01169216305219841\n",
      "train loss:0.04208849293479654\n",
      "train loss:0.027003263641193445\n",
      "train loss:0.014663409653450364\n",
      "train loss:0.017454580343588714\n",
      "train loss:0.014753588009697479\n",
      "train loss:0.015578004909100641\n",
      "train loss:0.015089580231625368\n",
      "train loss:0.010894240535972457\n",
      "train loss:0.0199743817007931\n",
      "train loss:0.011592558290285097\n",
      "train loss:0.014073181433015667\n",
      "train loss:0.010010898304553794\n",
      "train loss:0.08097617040257621\n",
      "train loss:0.012872019821013842\n",
      "train loss:0.013980003049373335\n",
      "train loss:0.03399929537936723\n",
      "train loss:0.030968273860465398\n",
      "train loss:0.016728413910068123\n",
      "train loss:0.01801387735396418\n",
      "train loss:0.013402962013826385\n",
      "train loss:0.07707588186090492\n",
      "train loss:0.012048610204519234\n",
      "train loss:0.008224334362855199\n",
      "train loss:0.039449906399106685\n",
      "train loss:0.01190050420004389\n",
      "train loss:0.008935405350583698\n",
      "train loss:0.032933897877740766\n",
      "train loss:0.06647576976617103\n",
      "train loss:0.04596186362855013\n",
      "train loss:0.007366637642954732\n",
      "train loss:0.019215877883407683\n",
      "train loss:0.031180691876515655\n",
      "train loss:0.008501644882361983\n",
      "train loss:0.02308821710856894\n",
      "train loss:0.035796860750621384\n",
      "train loss:0.007232011308205134\n",
      "train loss:0.07726124809229154\n",
      "train loss:0.031096485205548644\n",
      "train loss:0.030708360606865093\n",
      "train loss:0.007324580012453391\n",
      "train loss:0.01367617944215246\n",
      "train loss:0.1563947153031393\n",
      "train loss:0.05742527511312906\n",
      "train loss:0.007193416849954812\n",
      "train loss:0.016483262959985753\n",
      "train loss:0.09703253107459782\n",
      "train loss:0.012197970390561594\n",
      "train loss:0.011674851300257819\n",
      "train loss:0.03442878074902117\n",
      "train loss:0.010489146156103555\n",
      "train loss:0.04073932806548296\n",
      "train loss:0.046789895228214445\n",
      "train loss:0.009430361205156354\n",
      "train loss:0.013002418186074071\n",
      "train loss:0.011745879325075754\n",
      "train loss:0.05530972784233728\n",
      "train loss:0.008668480814755235\n",
      "train loss:0.039959735828378445\n",
      "train loss:0.0245745536732439\n",
      "train loss:0.057110780254464054\n",
      "train loss:0.01047032396691476\n",
      "train loss:0.06452282890923397\n",
      "train loss:0.08597759567334567\n",
      "train loss:0.008462650348865747\n",
      "train loss:0.041993632458577144\n",
      "train loss:0.014468674100853694\n",
      "train loss:0.011321991942482328\n",
      "train loss:0.016322004498288488\n",
      "train loss:0.029508543673538813\n",
      "train loss:0.008217586893343549\n",
      "train loss:0.07525595130357213\n",
      "train loss:0.011674030566720702\n",
      "train loss:0.06242392997941129\n",
      "train loss:0.003143482956609533\n",
      "train loss:0.012862460197452576\n",
      "train loss:0.007500540976175961\n",
      "train loss:0.005113481880868568\n",
      "train loss:0.016721846536950132\n",
      "train loss:0.011582750902196494\n",
      "train loss:0.017555199130770752\n",
      "train loss:0.00698010015270631\n",
      "train loss:0.020513032870154935\n",
      "train loss:0.015484923936309711\n",
      "train loss:0.033084967300243594\n",
      "train loss:0.012340844629511976\n",
      "train loss:0.03668115227765498\n",
      "train loss:0.015072264409797942\n",
      "train loss:0.00669035880981163\n",
      "train loss:0.07606703178124269\n",
      "train loss:0.00523522946838548\n",
      "train loss:0.06874146376405599\n",
      "train loss:0.0138640933507229\n",
      "train loss:0.005235829304549645\n",
      "train loss:0.016601303748538708\n",
      "train loss:0.014040055114552497\n",
      "train loss:0.028162955654350324\n",
      "train loss:0.036402183134726755\n",
      "train loss:0.04069798891032159\n",
      "train loss:0.050371027421107384\n",
      "train loss:0.015845346795219786\n",
      "train loss:0.018299065500716773\n",
      "train loss:0.01650421924677563\n",
      "train loss:0.0032520466907811673\n",
      "train loss:0.040202642950088754\n",
      "train loss:0.06400626408774417\n",
      "train loss:0.012292357830995743\n",
      "train loss:0.0031744989237280858\n",
      "train loss:0.010733892519066845\n",
      "train loss:0.010145175565578009\n",
      "train loss:0.027402351365180405\n",
      "train loss:0.011652306741926457\n",
      "train loss:0.011799330799875695\n",
      "train loss:0.03570114645310825\n",
      "train loss:0.032848160636315765\n",
      "train loss:0.009992228520218143\n",
      "train loss:0.04574402867068816\n",
      "train loss:0.046354403454461825\n",
      "train loss:0.01749223619744787\n",
      "train loss:0.034877444336407104\n",
      "train loss:0.015149826054024975\n",
      "train loss:0.005366580170688501\n",
      "train loss:0.013862623543976852\n",
      "train loss:0.026036297021048496\n",
      "train loss:0.018829443079162088\n",
      "train loss:0.017710536701893966\n",
      "train loss:0.03198558048789321\n",
      "train loss:0.03843157473622235\n",
      "train loss:0.06426051336469012\n",
      "train loss:0.006623377235761531\n",
      "train loss:0.04935429282430258\n",
      "train loss:0.017296275455272368\n",
      "train loss:0.0286220363969625\n",
      "train loss:0.052138665296025684\n",
      "train loss:0.015490269303016238\n",
      "train loss:0.044626762756444414\n",
      "train loss:0.07267859876760188\n",
      "train loss:0.08838053192565574\n",
      "train loss:0.0030583730235940625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06420184508637203\n",
      "train loss:0.025341933721414023\n",
      "train loss:0.01806470624819216\n",
      "train loss:0.18215480212490262\n",
      "train loss:0.06162825902140282\n",
      "train loss:0.01443620935508712\n",
      "train loss:0.01500006695832923\n",
      "train loss:0.03743187286182524\n",
      "train loss:0.06637214210447424\n",
      "train loss:0.03686750766129181\n",
      "train loss:0.0689599775425822\n",
      "train loss:0.056821827611147846\n",
      "train loss:0.08566698494048626\n",
      "train loss:0.02980147726103842\n",
      "train loss:0.013519136481314378\n",
      "train loss:0.003629703190318645\n",
      "train loss:0.015981610306343277\n",
      "train loss:0.07985207615642712\n",
      "train loss:0.02700418570390978\n",
      "train loss:0.02239662514780383\n",
      "train loss:0.0228986537993433\n",
      "train loss:0.022391042800439756\n",
      "train loss:0.022165632815300956\n",
      "train loss:0.005868927541929655\n",
      "train loss:0.03850227326128954\n",
      "train loss:0.04857308024345125\n",
      "train loss:0.009907982668716765\n",
      "train loss:0.01506428602836276\n",
      "train loss:0.016559915114010223\n",
      "train loss:0.017693506797679413\n",
      "train loss:0.18104652209736144\n",
      "train loss:0.01437161996997653\n",
      "train loss:0.00769539731123997\n",
      "train loss:0.006591573305673841\n",
      "train loss:0.036765356096327334\n",
      "train loss:0.025402259381953875\n",
      "train loss:0.02623085825978842\n",
      "train loss:0.030417114523470047\n",
      "train loss:0.029440691329186877\n",
      "train loss:0.039652714178733464\n",
      "train loss:0.010128943586397212\n",
      "train loss:0.060633812243123975\n",
      "train loss:0.035035778456363645\n",
      "train loss:0.029637544834966563\n",
      "train loss:0.04440253967334961\n",
      "train loss:0.022625654128911807\n",
      "train loss:0.03379274275360224\n",
      "train loss:0.06939004567015664\n",
      "train loss:0.02533879009071887\n",
      "train loss:0.011555777055035896\n",
      "train loss:0.008879341566097881\n",
      "train loss:0.05996447182490042\n",
      "train loss:0.01803903672262213\n",
      "train loss:0.010314045022142084\n",
      "train loss:0.06462853506912773\n",
      "train loss:0.023715303520730792\n",
      "train loss:0.011432184158186578\n",
      "train loss:0.018860748892515863\n",
      "train loss:0.007803416664971735\n",
      "train loss:0.037827966342802714\n",
      "train loss:0.05308208774998548\n",
      "train loss:0.05982645089010338\n",
      "train loss:0.05633759264218467\n",
      "train loss:0.002029160733177535\n",
      "train loss:0.047801818041945845\n",
      "train loss:0.006616281433368292\n",
      "train loss:0.003990728542868399\n",
      "train loss:0.01056981227497502\n",
      "train loss:0.005835965991546713\n",
      "train loss:0.014075862018514644\n",
      "train loss:0.007185110619863935\n",
      "train loss:0.023458705569581725\n",
      "train loss:0.021223604353835607\n",
      "train loss:0.008958613172913724\n",
      "train loss:0.02756580391316714\n",
      "train loss:0.019734099685247225\n",
      "train loss:0.0290047951171875\n",
      "train loss:0.0176111723405449\n",
      "train loss:0.009740925282843168\n",
      "train loss:0.03957209411677236\n",
      "train loss:0.058126220421275424\n",
      "train loss:0.01602825720364653\n",
      "train loss:0.04315711472918383\n",
      "train loss:0.008738441031116062\n",
      "train loss:0.012725611041571\n",
      "train loss:0.011854929749679576\n",
      "train loss:0.011166834747529015\n",
      "train loss:0.07871672687510305\n",
      "train loss:0.015108512943316808\n",
      "train loss:0.019502931382996528\n",
      "train loss:0.0075454973906984414\n",
      "train loss:0.08431391642704575\n",
      "train loss:0.015001293660369437\n",
      "train loss:0.018956395692408045\n",
      "train loss:0.01781075451332593\n",
      "train loss:0.012352296875041606\n",
      "train loss:0.07444303242684541\n",
      "train loss:0.05224279969565695\n",
      "train loss:0.048598808126834286\n",
      "train loss:0.005721838731317647\n",
      "train loss:0.016092601689639344\n",
      "train loss:0.022513266216620288\n",
      "train loss:0.05526234135439098\n",
      "train loss:0.020042796310512\n",
      "train loss:0.011448364829389013\n",
      "train loss:0.0372476649689656\n",
      "=== epoch:6, train acc:0.989, test acc:0.982 ===\n",
      "train loss:0.01539431973196463\n",
      "train loss:0.006118396180963069\n",
      "train loss:0.011334084082713296\n",
      "train loss:0.00968247886741263\n",
      "train loss:0.022497726442318688\n",
      "train loss:0.014667795981017317\n",
      "train loss:0.016895028176987986\n",
      "train loss:0.02071666095637859\n",
      "train loss:0.008504034236817934\n",
      "train loss:0.013897442408223886\n",
      "train loss:0.01894573145658767\n",
      "train loss:0.009214920417476732\n",
      "train loss:0.02220119766887653\n",
      "train loss:0.02904805974393585\n",
      "train loss:0.010326147345467327\n",
      "train loss:0.011370968748777919\n",
      "train loss:0.052984897617929724\n",
      "train loss:0.006464596276519203\n",
      "train loss:0.013529779280557399\n",
      "train loss:0.011412994197618759\n",
      "train loss:0.05576311092385776\n",
      "train loss:0.009224324571421583\n",
      "train loss:0.16715328791099116\n",
      "train loss:0.0404679591875525\n",
      "train loss:0.005830387519118218\n",
      "train loss:0.06508298521050786\n",
      "train loss:0.01606242143013643\n",
      "train loss:0.005643139328822866\n",
      "train loss:0.12964287984197553\n",
      "train loss:0.023816002939024857\n",
      "train loss:0.005741128320083274\n",
      "train loss:0.036863240951923754\n",
      "train loss:0.015373536831087971\n",
      "train loss:0.01492222953867394\n",
      "train loss:0.035674789176084465\n",
      "train loss:0.019748787405404894\n",
      "train loss:0.026383025733964185\n",
      "train loss:0.007900634423865757\n",
      "train loss:0.021423478270615085\n",
      "train loss:0.009953701935261497\n",
      "train loss:0.01624483282729796\n",
      "train loss:0.0111269142359457\n",
      "train loss:0.01285330118881877\n",
      "train loss:0.0517480868724498\n",
      "train loss:0.0063523208086657835\n",
      "train loss:0.01763957895729058\n",
      "train loss:0.03236700065467219\n",
      "train loss:0.06684246770534974\n",
      "train loss:0.06213126201862715\n",
      "train loss:0.09839633450875127\n",
      "train loss:0.011177646107181026\n",
      "train loss:0.05202966409749961\n",
      "train loss:0.024025609289987346\n",
      "train loss:0.014523494776182888\n",
      "train loss:0.02952024152721899\n",
      "train loss:0.02947094865534315\n",
      "train loss:0.014598150423733325\n",
      "train loss:0.03019182255052552\n",
      "train loss:0.004747517398544216\n",
      "train loss:0.019250206734140417\n",
      "train loss:0.021259859977629594\n",
      "train loss:0.01869204018011676\n",
      "train loss:0.018228561740332848\n",
      "train loss:0.0208741493382979\n",
      "train loss:0.06032606051139572\n",
      "train loss:0.026795808387957813\n",
      "train loss:0.006467451624898738\n",
      "train loss:0.016580125906612002\n",
      "train loss:0.02850807100741811\n",
      "train loss:0.010719260422479473\n",
      "train loss:0.09583270673396269\n",
      "train loss:0.0043758029637198815\n",
      "train loss:0.0020295616440347162\n",
      "train loss:0.03681149478033381\n",
      "train loss:0.02111324321882954\n",
      "train loss:0.007555872819811975\n",
      "train loss:0.14879512304702783\n",
      "train loss:0.012103540607641\n",
      "train loss:0.009500315552248761\n",
      "train loss:0.00782320779037836\n",
      "train loss:0.09803756865529889\n",
      "train loss:0.04393993077109503\n",
      "train loss:0.028445529949215242\n",
      "train loss:0.022717406032181295\n",
      "train loss:0.010395932820287841\n",
      "train loss:0.03035123458875216\n",
      "train loss:0.039463400337020095\n",
      "train loss:0.003671973575353796\n",
      "train loss:0.034190870300621026\n",
      "train loss:0.013259122728797416\n",
      "train loss:0.011076205365330681\n",
      "train loss:0.008845043677707247\n",
      "train loss:0.010741662031147063\n",
      "train loss:0.011552019437209834\n",
      "train loss:0.034536668727342346\n",
      "train loss:0.004944642154749099\n",
      "train loss:0.04016076486011272\n",
      "train loss:0.004385846465726909\n",
      "train loss:0.03426449295038649\n",
      "train loss:0.03745869583998117\n",
      "train loss:0.015873217296381918\n",
      "train loss:0.015678623085275144\n",
      "train loss:0.015341768267632817\n",
      "train loss:0.009164806620532914\n",
      "train loss:0.0751863545381108\n",
      "train loss:0.0073334978032321505\n",
      "train loss:0.03606375258099757\n",
      "train loss:0.06227251119492265\n",
      "train loss:0.011674424588976197\n",
      "train loss:0.024272861291803647\n",
      "train loss:0.03948098023455692\n",
      "train loss:0.03718505639454376\n",
      "train loss:0.0404166662191312\n",
      "train loss:0.008873385945804895\n",
      "train loss:0.012124820217870485\n",
      "train loss:0.004349895892492712\n",
      "train loss:0.010698804112569632\n",
      "train loss:0.010007891543894445\n",
      "train loss:0.018969191861857276\n",
      "train loss:0.04019984917406422\n",
      "train loss:0.01183342683958955\n",
      "train loss:0.003072808684213847\n",
      "train loss:0.006340518499199411\n",
      "train loss:0.04743426296611797\n",
      "train loss:0.04487756014177249\n",
      "train loss:0.0372229446304727\n",
      "train loss:0.016144632296752892\n",
      "train loss:0.006721431043140546\n",
      "train loss:0.008264179881431613\n",
      "train loss:0.04529743136546254\n",
      "train loss:0.008408999297803633\n",
      "train loss:0.03453123690266636\n",
      "train loss:0.010199460224299052\n",
      "train loss:0.02569051640644314\n",
      "train loss:0.06552445678983357\n",
      "train loss:0.05706380488614141\n",
      "train loss:0.002793995041405642\n",
      "train loss:0.020874535709172484\n",
      "train loss:0.03064193348004099\n",
      "train loss:0.00843449021335912\n",
      "train loss:0.00407478610038666\n",
      "train loss:0.010613287799791524\n",
      "train loss:0.027179929820688144\n",
      "train loss:0.01850260432640167\n",
      "train loss:0.004187975968806434\n",
      "train loss:0.026002946541270014\n",
      "train loss:0.022798901910840785\n",
      "train loss:0.03766787144183007\n",
      "train loss:0.011866938144436442\n",
      "train loss:0.012416939340511707\n",
      "train loss:0.010328524128103074\n",
      "train loss:0.035560093863093105\n",
      "train loss:0.013769528698461472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04114946218555415\n",
      "train loss:0.015313431066692897\n",
      "train loss:0.017835513088853176\n",
      "train loss:0.004922706879523458\n",
      "train loss:0.07274207206279772\n",
      "train loss:0.07366084479644813\n",
      "train loss:0.04007809470060236\n",
      "train loss:0.008459721584741403\n",
      "train loss:0.0997460647815131\n",
      "train loss:0.027152112003167927\n",
      "train loss:0.019552907193295447\n",
      "train loss:0.0108001226801795\n",
      "train loss:0.031480198634813356\n",
      "train loss:0.02149759647992465\n",
      "train loss:0.014072793781915173\n",
      "train loss:0.01738712530738373\n",
      "train loss:0.035633751466289734\n",
      "train loss:0.010521157125374207\n",
      "train loss:0.027606818461758102\n",
      "train loss:0.005348953576758909\n",
      "train loss:0.009937878454688189\n",
      "train loss:0.007850182723367535\n",
      "train loss:0.03589972316103951\n",
      "train loss:0.042517816657483935\n",
      "train loss:0.05063512319548255\n",
      "train loss:0.011086035930442852\n",
      "train loss:0.0435582487100835\n",
      "train loss:0.007004530816517351\n",
      "train loss:0.06563391277044822\n",
      "train loss:0.09430565786661864\n",
      "train loss:0.03826067159274332\n",
      "train loss:0.017173338115537666\n",
      "train loss:0.007276604721776213\n",
      "train loss:0.016004489835347302\n",
      "train loss:0.10418404276511554\n",
      "train loss:0.0037483279564002325\n",
      "train loss:0.011967516568617878\n",
      "train loss:0.043260253008509865\n",
      "train loss:0.0874659162641508\n",
      "train loss:0.0174734545993172\n",
      "train loss:0.04075561329258024\n",
      "train loss:0.02214193869057631\n",
      "train loss:0.010055937126846916\n",
      "train loss:0.06065190945270648\n",
      "train loss:0.014837497323679338\n",
      "train loss:0.008256548541565559\n",
      "train loss:0.012259900763926966\n",
      "train loss:0.016164209028849706\n",
      "train loss:0.013528451086726949\n",
      "train loss:0.04764903628664739\n",
      "train loss:0.005101476461964012\n",
      "train loss:0.018418840300236678\n",
      "train loss:0.011147741346439075\n",
      "train loss:0.010296361657402942\n",
      "train loss:0.04554315256872072\n",
      "train loss:0.058660437170458074\n",
      "train loss:0.06962164064834671\n",
      "train loss:0.011909680269022602\n",
      "train loss:0.009722756038134188\n",
      "train loss:0.004512702478830112\n",
      "train loss:0.05255666303681032\n",
      "train loss:0.04183772683478835\n",
      "train loss:0.09857112572477357\n",
      "train loss:0.005068427311847597\n",
      "train loss:0.01378851021325632\n",
      "train loss:0.026999391942222544\n",
      "train loss:0.0071411366899071325\n",
      "train loss:0.008826806730393042\n",
      "train loss:0.01519450300377389\n",
      "train loss:0.006142454670925029\n",
      "train loss:0.011372358072328788\n",
      "train loss:0.0035736798205820417\n",
      "train loss:0.06965236485709837\n",
      "train loss:0.055369556215234816\n",
      "train loss:0.024439199358408336\n",
      "train loss:0.003707233468039318\n",
      "train loss:0.011216079715335035\n",
      "train loss:0.008567339010353966\n",
      "train loss:0.010951048508618624\n",
      "train loss:0.02064548847096914\n",
      "train loss:0.04252824181727578\n",
      "train loss:0.010526139528254848\n",
      "train loss:0.011299231557571848\n",
      "train loss:0.013074121104666367\n",
      "train loss:0.030396713486952484\n",
      "train loss:0.019474091041965763\n",
      "train loss:0.036383760461715306\n",
      "train loss:0.011453082028069106\n",
      "train loss:0.012293708554595892\n",
      "train loss:0.01753760745568326\n",
      "train loss:0.0083720988067652\n",
      "train loss:0.04668233997401984\n",
      "train loss:0.043054289972316535\n",
      "train loss:0.01837498193196059\n",
      "train loss:0.00870316304763473\n",
      "train loss:0.00748272691698588\n",
      "train loss:0.021273084977885673\n",
      "train loss:0.0226613266274573\n",
      "train loss:0.01810664290115328\n",
      "train loss:0.011176588633805646\n",
      "train loss:0.009499020747169096\n",
      "train loss:0.0726177373283556\n",
      "train loss:0.0037141757071863396\n",
      "train loss:0.005495606058837029\n",
      "train loss:0.020619040748650105\n",
      "train loss:0.023772590518003477\n",
      "train loss:0.022015332093927486\n",
      "train loss:0.036410381708111846\n",
      "train loss:0.0178057403455351\n",
      "train loss:0.011766995329081846\n",
      "train loss:0.017771259581859516\n",
      "train loss:0.010127992497345258\n",
      "train loss:0.029068891457402168\n",
      "train loss:0.028817834630401096\n",
      "train loss:0.03315051266676845\n",
      "train loss:0.031855841633005144\n",
      "train loss:0.035163785518399555\n",
      "train loss:0.023492857828001586\n",
      "train loss:0.008597978494125138\n",
      "train loss:0.011373086331669795\n",
      "train loss:0.020893294565611474\n",
      "train loss:0.022948255370207855\n",
      "train loss:0.00699588543184279\n",
      "train loss:0.04405116251836894\n",
      "train loss:0.02072751532969328\n",
      "train loss:0.009456990997624655\n",
      "train loss:0.018312274666010354\n",
      "train loss:0.01770606382136907\n",
      "train loss:0.04194845771595105\n",
      "train loss:0.005169653989516272\n",
      "train loss:0.05108461705762484\n",
      "train loss:0.005476084467809257\n",
      "train loss:0.015166001585353138\n",
      "train loss:0.03183068303622802\n",
      "train loss:0.0571352438868189\n",
      "train loss:0.004490002073097516\n",
      "train loss:0.08043264602605213\n",
      "train loss:0.03149237196272954\n",
      "train loss:0.0051387723718244425\n",
      "train loss:0.029996715814773922\n",
      "train loss:0.014258420157722926\n",
      "train loss:0.033313885926670644\n",
      "train loss:0.0061732925221935275\n",
      "train loss:0.024081579776344494\n",
      "train loss:0.020739786763667584\n",
      "train loss:0.008694482347425187\n",
      "train loss:0.009066880576255525\n",
      "train loss:0.006271931082894263\n",
      "train loss:0.007642343434111859\n",
      "train loss:0.008752803795300135\n",
      "train loss:0.014669743312639837\n",
      "train loss:0.004717686970742265\n",
      "train loss:0.0023175984967143304\n",
      "train loss:0.02871986192320449\n",
      "train loss:0.0030706225285488825\n",
      "train loss:0.014522943657277456\n",
      "train loss:0.14651088932113746\n",
      "train loss:0.013776775446226701\n",
      "train loss:0.03785103234955219\n",
      "train loss:0.0161674457532377\n",
      "train loss:0.01148066390357464\n",
      "train loss:0.06516459789133658\n",
      "train loss:0.019607199072463145\n",
      "train loss:0.014897351784934076\n",
      "train loss:0.01380590452851892\n",
      "train loss:0.01006346668135048\n",
      "train loss:0.022720023057724657\n",
      "train loss:0.017291199424874712\n",
      "train loss:0.044288218235132924\n",
      "train loss:0.00342264655075711\n",
      "train loss:0.01953322196811883\n",
      "train loss:0.012834572335712755\n",
      "train loss:0.03503392450027708\n",
      "train loss:0.007239750606126221\n",
      "train loss:0.009116470897416348\n",
      "train loss:0.004081665823013193\n",
      "train loss:0.007048875673379143\n",
      "train loss:0.0474286038426207\n",
      "train loss:0.018515143545332985\n",
      "train loss:0.01569840890378138\n",
      "train loss:0.02381435463724859\n",
      "train loss:0.03533894956799801\n",
      "train loss:0.014752955869407326\n",
      "train loss:0.022843316532653844\n",
      "train loss:0.011922644650599971\n",
      "train loss:0.011591976510080043\n",
      "train loss:0.013224532863385716\n",
      "train loss:0.03326368789987802\n",
      "train loss:0.014894490796673366\n",
      "train loss:0.01413941223811683\n",
      "train loss:0.0051002709279197615\n",
      "train loss:0.015325430339803912\n",
      "train loss:0.027028341605568246\n",
      "train loss:0.0777797925757604\n",
      "train loss:0.028807309560339545\n",
      "train loss:0.03963653749034586\n",
      "train loss:0.015236816854615502\n",
      "train loss:0.0042985953548964366\n",
      "train loss:0.00759176211461179\n",
      "train loss:0.04206551833815135\n",
      "train loss:0.04738544096501427\n",
      "train loss:0.015403038011081812\n",
      "train loss:0.032760766448714514\n",
      "train loss:0.008136125858070154\n",
      "train loss:0.032753554742623606\n",
      "train loss:0.0059431304119506485\n",
      "train loss:0.030392909848852817\n",
      "train loss:0.009135973930204466\n",
      "train loss:0.02969551339328811\n",
      "train loss:0.06350038574909413\n",
      "train loss:0.01903059174671123\n",
      "train loss:0.01399286938055484\n",
      "train loss:0.0062185639251529255\n",
      "train loss:0.04221146255621882\n",
      "train loss:0.026733809797801645\n",
      "train loss:0.0078475544586643\n",
      "train loss:0.005367688202480128\n",
      "train loss:0.004628212769323791\n",
      "train loss:0.05881021616053554\n",
      "train loss:0.007142666123059137\n",
      "train loss:0.0022146570905471844\n",
      "train loss:0.019292459251635197\n",
      "train loss:0.0073756738160692045\n",
      "train loss:0.010896780810693247\n",
      "train loss:0.06412527325906453\n",
      "train loss:0.0812142090405435\n",
      "train loss:0.045639927945729394\n",
      "train loss:0.00848532386682007\n",
      "train loss:0.011168554898078371\n",
      "train loss:0.07037785669027313\n",
      "train loss:0.009694805878592077\n",
      "train loss:0.005348243430806977\n",
      "train loss:0.04672080603581839\n",
      "train loss:0.005698748309006807\n",
      "train loss:0.005299589202557816\n",
      "train loss:0.023088271171305092\n",
      "train loss:0.0030859463110703383\n",
      "train loss:0.020297103120609287\n",
      "train loss:0.016535940513665238\n",
      "train loss:0.008185293201028997\n",
      "train loss:0.02430054479959203\n",
      "train loss:0.02521668344640418\n",
      "train loss:0.0070006769346639365\n",
      "train loss:0.07702855014183571\n",
      "train loss:0.004601200159475511\n",
      "train loss:0.03576729006994973\n",
      "train loss:0.01981735874838097\n",
      "train loss:0.008108836658282981\n",
      "train loss:0.017514348674609503\n",
      "train loss:0.013225460415864438\n",
      "train loss:0.018021994559954964\n",
      "train loss:0.017376441212817693\n",
      "train loss:0.01603366782184337\n",
      "train loss:0.0034562375866269827\n",
      "train loss:0.011464314693768542\n",
      "train loss:0.0023560547571395483\n",
      "train loss:0.012803188567833537\n",
      "train loss:0.07113773560315748\n",
      "train loss:0.014433740140784255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026731449203344814\n",
      "train loss:0.018864217831980626\n",
      "train loss:0.0170928396865585\n",
      "train loss:0.04679756375942594\n",
      "train loss:0.003880057935992728\n",
      "train loss:0.006246605288353346\n",
      "train loss:0.006537068454550863\n",
      "train loss:0.016457814888590997\n",
      "train loss:0.012745468501566048\n",
      "train loss:0.013662634443798151\n",
      "train loss:0.013191056907213821\n",
      "train loss:0.010708796924734166\n",
      "train loss:0.006299329252827266\n",
      "train loss:0.02542436745096873\n",
      "train loss:0.002425053999654003\n",
      "train loss:0.005961230000295937\n",
      "train loss:0.04017541470238721\n",
      "train loss:0.012401002947260162\n",
      "train loss:0.015178421736443497\n",
      "train loss:0.007823398254140938\n",
      "train loss:0.010715985396465675\n",
      "train loss:0.02307685492616971\n",
      "train loss:0.01586098037850951\n",
      "train loss:0.00936051795125327\n",
      "train loss:0.03965948931137164\n",
      "train loss:0.006652852691939805\n",
      "train loss:0.004090412552614672\n",
      "train loss:0.0019268576260043754\n",
      "train loss:0.01632687722273192\n",
      "train loss:0.013295874912262284\n",
      "train loss:0.0038181586368427668\n",
      "train loss:0.02823862265133009\n",
      "train loss:0.006140071141022009\n",
      "train loss:0.013938237823516749\n",
      "train loss:0.039571347282248\n",
      "train loss:0.013265334389346966\n",
      "train loss:0.020671406671132007\n",
      "train loss:0.029015453374216654\n",
      "train loss:0.03975268921810845\n",
      "train loss:0.007924119801489393\n",
      "train loss:0.023501029595758283\n",
      "train loss:0.01551978618102079\n",
      "train loss:0.0038096773685153983\n",
      "train loss:0.0018302934589619346\n",
      "train loss:0.006365301619938483\n",
      "train loss:0.008540047843858357\n",
      "train loss:0.014977011367019788\n",
      "train loss:0.015833343382854928\n",
      "train loss:0.008429358347836332\n",
      "train loss:0.03047915677705653\n",
      "train loss:0.01751726414999387\n",
      "train loss:0.030512694871090956\n",
      "train loss:0.0035313147142645423\n",
      "train loss:0.0477389367123148\n",
      "train loss:0.04242852614130497\n",
      "train loss:0.00566240774609371\n",
      "train loss:0.0025497254265168696\n",
      "train loss:0.009599984933275962\n",
      "train loss:0.026367713025157405\n",
      "train loss:0.014559836095384802\n",
      "train loss:0.011205229939594394\n",
      "train loss:0.008599052447016758\n",
      "train loss:0.030217657666402355\n",
      "train loss:0.013654594508595037\n",
      "train loss:0.011901792469816803\n",
      "train loss:0.012662342894245898\n",
      "train loss:0.047472168727426364\n",
      "train loss:0.009145769722630826\n",
      "train loss:0.022303407802636635\n",
      "train loss:0.012497704716918872\n",
      "train loss:0.018208717289913183\n",
      "train loss:0.02222692690986364\n",
      "train loss:0.007997424080328639\n",
      "train loss:0.008620828988588562\n",
      "train loss:0.07473121983600997\n",
      "train loss:0.027628625672763495\n",
      "train loss:0.01220613645334577\n",
      "train loss:0.04689695944803014\n",
      "train loss:0.004159252119918636\n",
      "train loss:0.009605756289102102\n",
      "train loss:0.1311744561817151\n",
      "train loss:0.017973572761176223\n",
      "train loss:0.005912169368493972\n",
      "train loss:0.0027015936549601677\n",
      "train loss:0.022693550836847987\n",
      "train loss:0.010721716128524421\n",
      "train loss:0.07048139524498832\n",
      "train loss:0.013135399359365378\n",
      "train loss:0.005141878152473356\n",
      "train loss:0.025467126461867613\n",
      "train loss:0.006875062081332578\n",
      "train loss:0.006809872289275403\n",
      "train loss:0.0391224768585188\n",
      "train loss:0.037189741026617006\n",
      "train loss:0.01623629057988241\n",
      "train loss:0.006119688987903944\n",
      "train loss:0.005696305423234869\n",
      "train loss:0.010244407137570546\n",
      "train loss:0.01644442548264514\n",
      "train loss:0.00680353524452251\n",
      "train loss:0.0019990932270503724\n",
      "train loss:0.011000826037451172\n",
      "train loss:0.01032888736478231\n",
      "train loss:0.014329304049812107\n",
      "train loss:0.015438670474360032\n",
      "train loss:0.04749850272847886\n",
      "train loss:0.010258910621319492\n",
      "train loss:0.007079579506095124\n",
      "train loss:0.008371820400240516\n",
      "train loss:0.021249171548614863\n",
      "train loss:0.006695422993178345\n",
      "train loss:0.003276333795935633\n",
      "train loss:0.008233252024028474\n",
      "train loss:0.005702320440479542\n",
      "train loss:0.0046108998287402335\n",
      "train loss:0.008692917510201124\n",
      "train loss:0.02444340658522367\n",
      "train loss:0.0015697739284850592\n",
      "train loss:0.013854563993677542\n",
      "train loss:0.008849850164949003\n",
      "train loss:0.0017486978626397064\n",
      "train loss:0.01798847838692712\n",
      "train loss:0.018193426138984545\n",
      "train loss:0.036845479639975344\n",
      "train loss:0.025405380414852567\n",
      "train loss:0.0028535455481726968\n",
      "train loss:0.013374106208933582\n",
      "train loss:0.015460141220901386\n",
      "train loss:0.1267353793606271\n",
      "train loss:0.00503140587778734\n",
      "train loss:0.022874051003906767\n",
      "train loss:0.00253756254539508\n",
      "train loss:0.011586570762506843\n",
      "train loss:0.009589762374801974\n",
      "train loss:0.06392555371240681\n",
      "train loss:0.01340514080526248\n",
      "train loss:0.0052871287160862175\n",
      "train loss:0.0031056085864801675\n",
      "train loss:0.07443219860545536\n",
      "train loss:0.03654661303736381\n",
      "train loss:0.0053247717169491995\n",
      "train loss:0.012344933567024543\n",
      "train loss:0.022117081628307087\n",
      "train loss:0.03833500238885613\n",
      "train loss:0.059187953391553194\n",
      "train loss:0.004136044328398903\n",
      "train loss:0.005544333961688609\n",
      "train loss:0.06234509183435872\n",
      "train loss:0.03911126464330127\n",
      "train loss:0.027879484964432138\n",
      "train loss:0.012917662990307145\n",
      "train loss:0.006444951418833521\n",
      "train loss:0.01370509934949657\n",
      "train loss:0.01099942117142754\n",
      "train loss:0.013290591977812889\n",
      "train loss:0.014490264196429212\n",
      "train loss:0.004824799751281553\n",
      "train loss:0.0031259296529965197\n",
      "train loss:0.005964226127226408\n",
      "train loss:0.010064883307693576\n",
      "train loss:0.022068012322214055\n",
      "train loss:0.0033155628103859708\n",
      "train loss:0.00645434020485247\n",
      "train loss:0.010137189915369584\n",
      "train loss:0.11605700238516274\n",
      "train loss:0.008160454956504465\n",
      "train loss:0.007877452328702989\n",
      "train loss:0.0017281296876286898\n",
      "train loss:0.012246550014025642\n",
      "train loss:0.01799268588939252\n",
      "train loss:0.012729429831636108\n",
      "train loss:0.006046280487896763\n",
      "train loss:0.003508125175933541\n",
      "train loss:0.006467202214986372\n",
      "train loss:0.005328752161378281\n",
      "train loss:0.015834613140760713\n",
      "train loss:0.004509178204910104\n",
      "train loss:0.024038012033904946\n",
      "train loss:0.009721636844737492\n",
      "train loss:0.011517240924334409\n",
      "train loss:0.0033773832882197825\n",
      "train loss:0.020151421118461185\n",
      "train loss:0.004010342886880078\n",
      "train loss:0.005007959106864082\n",
      "train loss:0.004582201147773257\n",
      "train loss:0.01662082041710497\n",
      "train loss:0.006285661601789699\n",
      "train loss:0.011100833379213084\n",
      "=== epoch:7, train acc:0.988, test acc:0.988 ===\n",
      "train loss:0.019388829115251985\n",
      "train loss:0.002885014159484883\n",
      "train loss:0.006480939530086243\n",
      "train loss:0.008284772188106642\n",
      "train loss:0.0016516861429995036\n",
      "train loss:0.022474679502653933\n",
      "train loss:0.006666310663856605\n",
      "train loss:0.0026765818618750153\n",
      "train loss:0.02302826091789577\n",
      "train loss:0.005344554019629055\n",
      "train loss:0.05997251065421927\n",
      "train loss:0.01642147773098587\n",
      "train loss:0.008780192735519473\n",
      "train loss:0.033838615285901194\n",
      "train loss:0.04206082928668682\n",
      "train loss:0.08199835083173504\n",
      "train loss:0.0685255701342172\n",
      "train loss:0.008883863426848907\n",
      "train loss:0.010196057817290964\n",
      "train loss:0.010493386877895559\n",
      "train loss:0.048833864404598\n",
      "train loss:0.011016475669990523\n",
      "train loss:0.008459110029352887\n",
      "train loss:0.015313890246740814\n",
      "train loss:0.014568011170062874\n",
      "train loss:0.001338474661484311\n",
      "train loss:0.021937590177621365\n",
      "train loss:0.001862504519484502\n",
      "train loss:0.025403986216920686\n",
      "train loss:0.00687709034655849\n",
      "train loss:0.008337543842400394\n",
      "train loss:0.0270569363312531\n",
      "train loss:0.01637654544626176\n",
      "train loss:0.017980347131140797\n",
      "train loss:0.002615172775710336\n",
      "train loss:0.006391936456317776\n",
      "train loss:0.002212100760584092\n",
      "train loss:0.04418348496362932\n",
      "train loss:0.0007816810872687642\n",
      "train loss:0.02839170473005859\n",
      "train loss:0.05027752046039514\n",
      "train loss:0.005238937949080135\n",
      "train loss:0.016319505307919865\n",
      "train loss:0.011524496006264548\n",
      "train loss:0.027839322523029186\n",
      "train loss:0.012360740069536\n",
      "train loss:0.008991194575336314\n",
      "train loss:0.0064421652026054425\n",
      "train loss:0.05803559741529915\n",
      "train loss:0.015154422433069279\n",
      "train loss:0.011191609057191283\n",
      "train loss:0.016066866405918864\n",
      "train loss:0.011070944516346938\n",
      "train loss:0.005214846367706063\n",
      "train loss:0.0025885557851526094\n",
      "train loss:0.06735506926828522\n",
      "train loss:0.023513727376805744\n",
      "train loss:0.043818449226577724\n",
      "train loss:0.011785232872038255\n",
      "train loss:0.004455915197528695\n",
      "train loss:0.0033306791582027816\n",
      "train loss:0.01076658128941372\n",
      "train loss:0.010699542470456878\n",
      "train loss:0.003870439899341035\n",
      "train loss:0.01663293514432875\n",
      "train loss:0.00417461437344558\n",
      "train loss:0.01240276506163778\n",
      "train loss:0.007058834394321287\n",
      "train loss:0.009454883595592623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00407546585930713\n",
      "train loss:0.02618150171347421\n",
      "train loss:0.007038450941402728\n",
      "train loss:0.012000270137156946\n",
      "train loss:0.03570585599468984\n",
      "train loss:0.007249341586283615\n",
      "train loss:0.025523993532183153\n",
      "train loss:0.04174371519497923\n",
      "train loss:0.0036904718109293305\n",
      "train loss:0.002710160332519248\n",
      "train loss:0.007786109636029142\n",
      "train loss:0.007895913724708228\n",
      "train loss:0.036953103719248453\n",
      "train loss:0.0069817429133503\n",
      "train loss:0.005186951688471702\n",
      "train loss:0.007882203713697104\n",
      "train loss:0.030632809045592443\n",
      "train loss:0.003422484858324288\n",
      "train loss:0.08952160924206572\n",
      "train loss:0.03076985137967106\n",
      "train loss:0.013110125320942334\n",
      "train loss:0.018195397009718523\n",
      "train loss:0.04493598479927008\n",
      "train loss:0.01327545148460232\n",
      "train loss:0.012937733688528283\n",
      "train loss:0.03248508733504344\n",
      "train loss:0.02000929308953014\n",
      "train loss:0.018213782393580312\n",
      "train loss:0.12082488277132959\n",
      "train loss:0.017521752194459853\n",
      "train loss:0.014120770740043758\n",
      "train loss:0.07928469828117653\n",
      "train loss:0.0466631796553122\n",
      "train loss:0.007018011411083324\n",
      "train loss:0.006610417236645778\n",
      "train loss:0.01143981087774062\n",
      "train loss:0.049872793619594985\n",
      "train loss:0.010834787345535063\n",
      "train loss:0.027137874853413253\n",
      "train loss:0.011811092150268616\n",
      "train loss:0.01374008205324274\n",
      "train loss:0.036160773962427915\n",
      "train loss:0.05164933276787051\n",
      "train loss:0.009188398937625249\n",
      "train loss:0.08918320862752777\n",
      "train loss:0.02911551929707135\n",
      "train loss:0.04906529229150513\n",
      "train loss:0.006032997947492703\n",
      "train loss:0.005714779394025622\n",
      "train loss:0.02071738550128589\n",
      "train loss:0.05680229238067518\n",
      "train loss:0.0989182976868965\n",
      "train loss:0.10257139933624128\n",
      "train loss:0.01380975753386232\n",
      "train loss:0.009225275294921073\n",
      "train loss:0.004577398386552331\n",
      "train loss:0.018026981201542093\n",
      "train loss:0.012617554749352625\n",
      "train loss:0.02302046429138234\n",
      "train loss:0.023566058154653232\n",
      "train loss:0.002973557953619392\n",
      "train loss:0.010220836151272611\n",
      "train loss:0.02319090953495053\n",
      "train loss:0.022403827581954444\n",
      "train loss:0.01810207429478807\n",
      "train loss:0.019408831050717067\n",
      "train loss:0.02385082561492955\n",
      "train loss:0.02739082171250069\n",
      "train loss:0.01908010370782665\n",
      "train loss:0.005465210317311318\n",
      "train loss:0.015222185409124091\n",
      "train loss:0.02235585714752266\n",
      "train loss:0.04136141579583038\n",
      "train loss:0.0022197268168355957\n",
      "train loss:0.007126107746529958\n",
      "train loss:0.04695224429710707\n",
      "train loss:0.002087394426294911\n",
      "train loss:0.07936114521892151\n",
      "train loss:0.01291318795649773\n",
      "train loss:0.03073767833376593\n",
      "train loss:0.0033026623658020436\n",
      "train loss:0.058874163341458265\n",
      "train loss:0.053457257189175725\n",
      "train loss:0.0063260553747177565\n",
      "train loss:0.007169194610816981\n",
      "train loss:0.00806174228173288\n",
      "train loss:0.012104053105917733\n",
      "train loss:0.009770093618082292\n",
      "train loss:0.003772121554842718\n",
      "train loss:0.021008914202362585\n",
      "train loss:0.026507921237250553\n",
      "train loss:0.011455521664031722\n",
      "train loss:0.03153069930647025\n",
      "train loss:0.004543947809818648\n",
      "train loss:0.028718332411898074\n",
      "train loss:0.019452414924783595\n",
      "train loss:0.012376558143810015\n",
      "train loss:0.009552121905225077\n",
      "train loss:0.050850560464277265\n",
      "train loss:0.016258302813377968\n",
      "train loss:0.0020169543843182123\n",
      "train loss:0.05822561077042484\n",
      "train loss:0.029481640128134416\n",
      "train loss:0.006301434903658531\n",
      "train loss:0.08569220948394285\n",
      "train loss:0.05784625319203058\n",
      "train loss:0.012821030706031184\n",
      "train loss:0.0033572623594706665\n",
      "train loss:0.0040551215730890286\n",
      "train loss:0.012830301922066481\n",
      "train loss:0.037228665634326925\n",
      "train loss:0.019849392184027495\n",
      "train loss:0.005175576586662048\n",
      "train loss:0.036490557905396785\n",
      "train loss:0.0358237352361265\n",
      "train loss:0.021400817845215192\n",
      "train loss:0.014118466013568014\n",
      "train loss:0.009711338380086127\n",
      "train loss:0.019542493418597227\n",
      "train loss:0.022120181535144903\n",
      "train loss:0.012344857541123713\n",
      "train loss:0.04159518733599308\n",
      "train loss:0.009602808258049003\n",
      "train loss:0.003171516869622815\n",
      "train loss:0.01504634524721367\n",
      "train loss:0.0087136847621177\n",
      "train loss:0.006383090376968572\n",
      "train loss:0.026580096568956275\n",
      "train loss:0.01912788665434739\n",
      "train loss:0.007198511857477522\n",
      "train loss:0.02313440798542453\n",
      "train loss:0.009696652830991477\n",
      "train loss:0.025042603134214674\n",
      "train loss:0.004593991161091384\n",
      "train loss:0.008005273944256961\n",
      "train loss:0.022362496316201397\n",
      "train loss:0.006285965114351469\n",
      "train loss:0.006476528454892014\n",
      "train loss:0.013917798779333303\n",
      "train loss:0.014192042928800143\n",
      "train loss:0.0068054114189505825\n",
      "train loss:0.005987864079751559\n",
      "train loss:0.02069440651071473\n",
      "train loss:0.007118777865226974\n",
      "train loss:0.0668473970221715\n",
      "train loss:0.004989841087267179\n",
      "train loss:0.006501462975031339\n",
      "train loss:0.013045924901189327\n",
      "train loss:0.023698110710931926\n",
      "train loss:0.026245070591821542\n",
      "train loss:0.0055418330158294015\n",
      "train loss:0.0154303988225423\n",
      "train loss:0.0314620788699974\n",
      "train loss:0.015423339421082441\n",
      "train loss:0.013192900097600165\n",
      "train loss:0.005380307286618374\n",
      "train loss:0.00585888732334452\n",
      "train loss:0.005652942017469364\n",
      "train loss:0.002750355477250821\n",
      "train loss:0.02349332937415551\n",
      "train loss:0.005656723306171908\n",
      "train loss:0.12190295640459789\n",
      "train loss:0.009285769979026534\n",
      "train loss:0.02069090737032039\n",
      "train loss:0.009031921455997412\n",
      "train loss:0.02735472443519105\n",
      "train loss:0.007926099614566497\n",
      "train loss:0.0026589402235240984\n",
      "train loss:0.013386506406092043\n",
      "train loss:0.017258040036516428\n",
      "train loss:0.08165267463159756\n",
      "train loss:0.018743467631873564\n",
      "train loss:0.006758483563342005\n",
      "train loss:0.00897584423029633\n",
      "train loss:0.008805573678138246\n",
      "train loss:0.009742168734708598\n",
      "train loss:0.025957006937095694\n",
      "train loss:0.030554106557033882\n",
      "train loss:0.003918423237410709\n",
      "train loss:0.013463627816703617\n",
      "train loss:0.01183467690911339\n",
      "train loss:0.02558718966848355\n",
      "train loss:0.039657181938232075\n",
      "train loss:0.003914179061294144\n",
      "train loss:0.004469401245332711\n",
      "train loss:0.0179650385633302\n",
      "train loss:0.011636910243928609\n",
      "train loss:0.0054503622999124346\n",
      "train loss:0.026781988044345874\n",
      "train loss:0.004051760860495074\n",
      "train loss:0.05549913644098146\n",
      "train loss:0.01929143447573129\n",
      "train loss:0.01791844724381073\n",
      "train loss:0.009349764932607793\n",
      "train loss:0.008039210382664202\n",
      "train loss:0.009803635979311616\n",
      "train loss:0.012516001830366665\n",
      "train loss:0.021142633901249867\n",
      "train loss:0.008800125639905341\n",
      "train loss:0.04471452942549356\n",
      "train loss:0.009988196346141363\n",
      "train loss:0.00555874719718215\n",
      "train loss:0.03260632857899646\n",
      "train loss:0.01116358809993641\n",
      "train loss:0.00474028254136884\n",
      "train loss:0.007337864543236424\n",
      "train loss:0.014748149724496073\n",
      "train loss:0.009564098538048734\n",
      "train loss:0.008565644322851116\n",
      "train loss:0.03432242996808523\n",
      "train loss:0.004039362146975774\n",
      "train loss:0.00574680200842147\n",
      "train loss:0.024441158326379945\n",
      "train loss:0.058699004787887865\n",
      "train loss:0.0025294631574191654\n",
      "train loss:0.02708044637688917\n",
      "train loss:0.014025303237931308\n",
      "train loss:0.010133407571761026\n",
      "train loss:0.008923958390824946\n",
      "train loss:0.0037606806568326358\n",
      "train loss:0.029291249619360662\n",
      "train loss:0.004904873536193716\n",
      "train loss:0.030586819520348606\n",
      "train loss:0.023898174417073578\n",
      "train loss:0.035995630111039414\n",
      "train loss:0.01552018255448516\n",
      "train loss:0.0024541081923688548\n",
      "train loss:0.010003880534656562\n",
      "train loss:0.01233624125385415\n",
      "train loss:0.029212059541554675\n",
      "train loss:0.014077259345556805\n",
      "train loss:0.011826306164314303\n",
      "train loss:0.029930495849510984\n",
      "train loss:0.034932995868261374\n",
      "train loss:0.04330136411769234\n",
      "train loss:0.02306852680528023\n",
      "train loss:0.014436985147785417\n",
      "train loss:0.0014509374749006687\n",
      "train loss:0.0032189791980297543\n",
      "train loss:0.015501741688413168\n",
      "train loss:0.004473952330869877\n",
      "train loss:0.015801916933076345\n",
      "train loss:0.002193544193017416\n",
      "train loss:0.006812239448388218\n",
      "train loss:0.004768383691051814\n",
      "train loss:0.011350845453083003\n",
      "train loss:0.01879835754445945\n",
      "train loss:0.07073551999771091\n",
      "train loss:0.007234172156828394\n",
      "train loss:0.04572151237381061\n",
      "train loss:0.02772125844695348\n",
      "train loss:0.018007884921758376\n",
      "train loss:0.0042703677452627575\n",
      "train loss:0.002907880240213736\n",
      "train loss:0.00694724079194693\n",
      "train loss:0.005093746414831188\n",
      "train loss:0.006720449227710622\n",
      "train loss:0.03696005460733787\n",
      "train loss:0.01047708112368238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01683428234435712\n",
      "train loss:0.03442648352335042\n",
      "train loss:0.007768538790847443\n",
      "train loss:0.001808818319312125\n",
      "train loss:0.007589111112545549\n",
      "train loss:0.022739198683911055\n",
      "train loss:0.0071558017056428365\n",
      "train loss:0.014309061975558833\n",
      "train loss:0.015499707519656594\n",
      "train loss:0.035870351209083294\n",
      "train loss:0.01196799296933176\n",
      "train loss:0.029406480681015514\n",
      "train loss:0.010269974357804103\n",
      "train loss:0.005608551065531363\n",
      "train loss:0.021098758854263065\n",
      "train loss:0.025786627431517876\n",
      "train loss:0.010835433143203033\n",
      "train loss:0.004395912649446637\n",
      "train loss:0.012405321963399739\n",
      "train loss:0.010599762347212575\n",
      "train loss:0.005548477302487362\n",
      "train loss:0.018360032712790787\n",
      "train loss:0.007170671446375572\n",
      "train loss:0.028465418551083456\n",
      "train loss:0.012946308113380451\n",
      "train loss:0.007881111973258432\n",
      "train loss:0.016859343007946632\n",
      "train loss:0.016564631001351287\n",
      "train loss:0.004498423915225582\n",
      "train loss:0.011370390923374323\n",
      "train loss:0.006582588575986636\n",
      "train loss:0.08184761988501542\n",
      "train loss:0.001902761828838994\n",
      "train loss:0.008658315992681078\n",
      "train loss:0.006336720918641872\n",
      "train loss:0.001816480577252156\n",
      "train loss:0.002296771583638644\n",
      "train loss:0.014229605891835332\n",
      "train loss:0.005080456568501824\n",
      "train loss:0.02338794320484692\n",
      "train loss:0.003175377190793347\n",
      "train loss:0.008995098132952906\n",
      "train loss:0.013485267661460297\n",
      "train loss:0.02185483542737232\n",
      "train loss:0.012177973355939392\n",
      "train loss:0.03654009037509673\n",
      "train loss:0.014150002978914803\n",
      "train loss:0.004600637315914934\n",
      "train loss:0.008705545061977958\n",
      "train loss:0.007474547335366249\n",
      "train loss:0.0055416521193833845\n",
      "train loss:0.004236393721288011\n",
      "train loss:0.005379047389245165\n",
      "train loss:0.03462951763210654\n",
      "train loss:0.010855307099123723\n",
      "train loss:0.005332959293614118\n",
      "train loss:0.02512862754338441\n",
      "train loss:0.008184323844528812\n",
      "train loss:0.021964388649200327\n",
      "train loss:0.007746823781934911\n",
      "train loss:0.002576638076320602\n",
      "train loss:0.004190264454132067\n",
      "train loss:0.004970381911344809\n",
      "train loss:0.006496804964899532\n",
      "train loss:0.01146382467495149\n",
      "train loss:0.047955397880154946\n",
      "train loss:0.026792286195907757\n",
      "train loss:0.037328101663792516\n",
      "train loss:0.007340676819938226\n",
      "train loss:0.001748161244019851\n",
      "train loss:0.003390204118274938\n",
      "train loss:0.019485979207547587\n",
      "train loss:0.012254087721195643\n",
      "train loss:0.007169891201510097\n",
      "train loss:0.004430148905333361\n",
      "train loss:0.003805672794719605\n",
      "train loss:0.012154696315355895\n",
      "train loss:0.011810478261527105\n",
      "train loss:0.004420998765791191\n",
      "train loss:0.004759102938525304\n",
      "train loss:0.03074652002669447\n",
      "train loss:0.02319194448071509\n",
      "train loss:0.00589190532694912\n",
      "train loss:0.02413845213561915\n",
      "train loss:0.03880767849840114\n",
      "train loss:0.006746910373071231\n",
      "train loss:0.0451759062986997\n",
      "train loss:0.035338682730826736\n",
      "train loss:0.01996514590188067\n",
      "train loss:0.02904519191721309\n",
      "train loss:0.007773861709604014\n",
      "train loss:0.008326549324424098\n",
      "train loss:0.0067738546077951885\n",
      "train loss:0.05679783199788133\n",
      "train loss:0.013309022409206377\n",
      "train loss:0.0070355303884127056\n",
      "train loss:0.013957844724087369\n",
      "train loss:0.0151541137392851\n",
      "train loss:0.02363945990711146\n",
      "train loss:0.05449433549128905\n",
      "train loss:0.03332475486662436\n",
      "train loss:0.024845466590422537\n",
      "train loss:0.023918915131869473\n",
      "train loss:0.022490351271778057\n",
      "train loss:0.06527814207760144\n",
      "train loss:0.020291148915611155\n",
      "train loss:0.004467632566256901\n",
      "train loss:0.06298600067997148\n",
      "train loss:0.04486671000200095\n",
      "train loss:0.00976592483525583\n",
      "train loss:0.00788885845922594\n",
      "train loss:0.019375975156732495\n",
      "train loss:0.011469385806468647\n",
      "train loss:0.010417614838231838\n",
      "train loss:0.013053234079932158\n",
      "train loss:0.013652337560023247\n",
      "train loss:0.010989644820056953\n",
      "train loss:0.03110418526857192\n",
      "train loss:0.00727814279535609\n",
      "train loss:0.0275680030097885\n",
      "train loss:0.01046376524021072\n",
      "train loss:0.029243393861168348\n",
      "train loss:0.017019126361254234\n",
      "train loss:0.018437031744911323\n",
      "train loss:0.010295390155552378\n",
      "train loss:0.016150538558565287\n",
      "train loss:0.005409351648402639\n",
      "train loss:0.022178199748126223\n",
      "train loss:0.013747530662506679\n",
      "train loss:0.076084808834477\n",
      "train loss:0.01735550628334169\n",
      "train loss:0.02983406661086947\n",
      "train loss:0.0032819542440357063\n",
      "train loss:0.021910340301232418\n",
      "train loss:0.02880525962716098\n",
      "train loss:0.038624926505639263\n",
      "train loss:0.012452525959878984\n",
      "train loss:0.0036304536510088077\n",
      "train loss:0.015005779690689818\n",
      "train loss:0.06536619677294167\n",
      "train loss:0.007354611413102776\n",
      "train loss:0.017161546887065372\n",
      "train loss:0.006496118596664948\n",
      "train loss:0.01320043557521066\n",
      "train loss:0.031286331525813386\n",
      "train loss:0.004035944382437574\n",
      "train loss:0.009400708153908557\n",
      "train loss:0.01246603954784413\n",
      "train loss:0.05670874222164495\n",
      "train loss:0.0061319007824523954\n",
      "train loss:0.004804544072977893\n",
      "train loss:0.007402129753679609\n",
      "train loss:0.05930052506265022\n",
      "train loss:0.013955144821162134\n",
      "train loss:0.02013558442162065\n",
      "train loss:0.004694935513249509\n",
      "train loss:0.008959419663976266\n",
      "train loss:0.005172818167688702\n",
      "train loss:0.005833912896835086\n",
      "train loss:0.002931711377916075\n",
      "train loss:0.01585431430248983\n",
      "train loss:0.005295301524956737\n",
      "train loss:0.0040905772689350355\n",
      "train loss:0.00695825313307826\n",
      "train loss:0.007722913913993934\n",
      "train loss:0.00321519377293439\n",
      "train loss:0.013433035670646451\n",
      "train loss:0.006340633041720853\n",
      "train loss:0.00451540918255342\n",
      "train loss:0.018708496175518168\n",
      "train loss:0.013578328690736172\n",
      "train loss:0.020449942262750435\n",
      "train loss:0.006148680400942823\n",
      "train loss:0.016177823074523826\n",
      "train loss:0.018786170110441782\n",
      "train loss:0.0066525152409078496\n",
      "train loss:0.010976471690810634\n",
      "train loss:0.009224326427478583\n",
      "train loss:0.008972779010587467\n",
      "train loss:0.005341364801986719\n",
      "train loss:0.01847722821632101\n",
      "train loss:0.027086305304337404\n",
      "train loss:0.002041747959384152\n",
      "train loss:0.0070506096896230195\n",
      "train loss:0.05573659010077726\n",
      "train loss:0.015396002291522302\n",
      "train loss:0.030581207823286594\n",
      "train loss:0.012150621192218476\n",
      "train loss:0.008889574894065186\n",
      "train loss:0.0044745445037192464\n",
      "train loss:0.015217603058454064\n",
      "train loss:0.006728270373442907\n",
      "train loss:0.009866773602980992\n",
      "train loss:0.032695051489884594\n",
      "train loss:0.004580940414753257\n",
      "train loss:0.004446901713097718\n",
      "train loss:0.10905940690318645\n",
      "train loss:0.06334124826232512\n",
      "train loss:0.003862103099220772\n",
      "train loss:0.04618508494142915\n",
      "train loss:0.01070684945443786\n",
      "train loss:0.013097557417504298\n",
      "train loss:0.006922222105023671\n",
      "train loss:0.007121957121003809\n",
      "train loss:0.022227242238708655\n",
      "train loss:0.02407984857438129\n",
      "train loss:0.02039490107630884\n",
      "train loss:0.011689474954703865\n",
      "train loss:0.01583095082304447\n",
      "train loss:0.01570681115719957\n",
      "train loss:0.019724654896077373\n",
      "train loss:0.007494550986183672\n",
      "train loss:0.006458206746209891\n",
      "train loss:0.012083524841679287\n",
      "train loss:0.011589369173965058\n",
      "train loss:0.013447446444745648\n",
      "train loss:0.009685097437632097\n",
      "train loss:0.009680089450868247\n",
      "train loss:0.006661148340877113\n",
      "train loss:0.12332671676246752\n",
      "train loss:0.014579398375603734\n",
      "train loss:0.019231119115507744\n",
      "train loss:0.03365651927917483\n",
      "train loss:0.0021987809289979693\n",
      "train loss:0.0052728621762842594\n",
      "train loss:0.011592829823979167\n",
      "train loss:0.0026170859609299774\n",
      "train loss:0.003960774330583722\n",
      "train loss:0.02701861390971931\n",
      "train loss:0.06525377382408487\n",
      "train loss:0.008275935370643453\n",
      "train loss:0.014743081446072073\n",
      "train loss:0.013842125593073589\n",
      "train loss:0.0065306876564945795\n",
      "train loss:0.012499803652648245\n",
      "train loss:0.005216311908754199\n",
      "train loss:0.037681025855983964\n",
      "train loss:0.004535208332755226\n",
      "train loss:0.012870299335716949\n",
      "train loss:0.006832265236261542\n",
      "train loss:0.0077248482648059605\n",
      "train loss:0.01591435961898071\n",
      "train loss:0.00841422024061778\n",
      "train loss:0.04132429222213868\n",
      "train loss:0.018320650593003328\n",
      "train loss:0.008353293923959493\n",
      "train loss:0.022788120199238152\n",
      "train loss:0.008716678718242835\n",
      "train loss:0.017672930449871855\n",
      "train loss:0.013226359077877179\n",
      "train loss:0.007220510445472889\n",
      "train loss:0.03973234519255091\n",
      "train loss:0.006261086162385306\n",
      "train loss:0.00807098712912033\n",
      "train loss:0.0021047047078621172\n",
      "train loss:0.01682341196910556\n",
      "train loss:0.005832737503520658\n",
      "train loss:0.009405942411932862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005868835396422268\n",
      "train loss:0.00388967037890526\n",
      "train loss:0.0023302847608097383\n",
      "train loss:0.008812920310139874\n",
      "train loss:0.010479548858629445\n",
      "train loss:0.08913533895753253\n",
      "train loss:0.0025902941191248228\n",
      "train loss:0.013903846982973748\n",
      "train loss:0.001008824822982659\n",
      "train loss:0.017004444935071698\n",
      "train loss:0.001297605317697697\n",
      "train loss:0.028224529225470762\n",
      "train loss:0.003032089150985284\n",
      "train loss:0.004019168947291657\n",
      "=== epoch:8, train acc:0.995, test acc:0.991 ===\n",
      "train loss:0.006636246043580274\n",
      "train loss:0.001659557519785231\n",
      "train loss:0.01972878235163962\n",
      "train loss:0.01315591895400262\n",
      "train loss:0.004751751538083585\n",
      "train loss:0.006957760318273593\n",
      "train loss:0.0025601534935887297\n",
      "train loss:0.03529952840238154\n",
      "train loss:0.006368986614138135\n",
      "train loss:0.007244506646263678\n",
      "train loss:0.04027998559451584\n",
      "train loss:0.003097620414309567\n",
      "train loss:0.08423022697289023\n",
      "train loss:0.024224356306942592\n",
      "train loss:0.005055740968268562\n",
      "train loss:0.002887326174854489\n",
      "train loss:0.03508798464268367\n",
      "train loss:0.016578226345342683\n",
      "train loss:0.007711845110763592\n",
      "train loss:0.009855961050257142\n",
      "train loss:0.004184764097974841\n",
      "train loss:0.015387193433344578\n",
      "train loss:0.06642850212534905\n",
      "train loss:0.012515425884452489\n",
      "train loss:0.016269350321730963\n",
      "train loss:0.005854643951697979\n",
      "train loss:0.005078715350886811\n",
      "train loss:0.015592205114196204\n",
      "train loss:0.011967885353410004\n",
      "train loss:0.008730422951150327\n",
      "train loss:0.0028534366321442944\n",
      "train loss:0.0010794471546056658\n",
      "train loss:0.010280034445673129\n",
      "train loss:0.004552084048577373\n",
      "train loss:0.002351262079848152\n",
      "train loss:0.004862520546638495\n",
      "train loss:0.006587704964996353\n",
      "train loss:0.009296619060473512\n",
      "train loss:0.045359829044338225\n",
      "train loss:0.012617540720751146\n",
      "train loss:0.015617204785406718\n",
      "train loss:0.007589469584832551\n",
      "train loss:0.0022794308034002754\n",
      "train loss:0.02256460412978106\n",
      "train loss:0.038221763033621244\n",
      "train loss:0.010320738665266062\n",
      "train loss:0.020055416248932735\n",
      "train loss:0.011932170974193492\n",
      "train loss:0.015583679679860579\n",
      "train loss:0.012133023845166102\n",
      "train loss:0.0036106584542841937\n",
      "train loss:0.05592171901065065\n",
      "train loss:0.008195431449094374\n",
      "train loss:0.06318802696901532\n",
      "train loss:0.008117073632230055\n",
      "train loss:0.03017719853905352\n",
      "train loss:0.006920592712031127\n",
      "train loss:0.0028623582679553413\n",
      "train loss:0.015975097772195298\n",
      "train loss:0.028436639578202114\n",
      "train loss:0.014721916998610179\n",
      "train loss:0.0042457403982966635\n",
      "train loss:0.004377990000539034\n",
      "train loss:0.011851671584689605\n",
      "train loss:0.0033664879108198926\n",
      "train loss:0.009405617701239306\n",
      "train loss:0.004567672309296041\n",
      "train loss:0.010717566471176021\n",
      "train loss:0.0027151770804442464\n",
      "train loss:0.05324276548567539\n",
      "train loss:0.020706203453385176\n",
      "train loss:0.0010170462637385496\n",
      "train loss:0.018003296821356665\n",
      "train loss:0.002139264693403454\n",
      "train loss:0.05392742930169824\n",
      "train loss:0.02311136519789725\n",
      "train loss:0.010042176849618443\n",
      "train loss:0.025581371278922904\n",
      "train loss:0.006325239122245584\n",
      "train loss:0.03134626733163934\n",
      "train loss:0.00569223717835093\n",
      "train loss:0.0058221202457913335\n",
      "train loss:0.019098474794585773\n",
      "train loss:0.025241970091125273\n",
      "train loss:0.010985702337795335\n",
      "train loss:0.031159486928185286\n",
      "train loss:0.03181783132909243\n",
      "train loss:0.035558990589686215\n",
      "train loss:0.005138548387285027\n",
      "train loss:0.020822206445776762\n",
      "train loss:0.0031540226787588666\n",
      "train loss:0.0034038584679549244\n",
      "train loss:0.046896728854431205\n",
      "train loss:0.01995198197651668\n",
      "train loss:0.010594222478538563\n",
      "train loss:0.01166119950710288\n",
      "train loss:0.007827903698049728\n",
      "train loss:0.03065102284701284\n",
      "train loss:0.007408023412484782\n",
      "train loss:0.023513164641463837\n",
      "train loss:0.003789290426478659\n",
      "train loss:0.010305126624224267\n",
      "train loss:0.01303178636853965\n",
      "train loss:0.00378632312491496\n",
      "train loss:0.009994248271786538\n",
      "train loss:0.007210124750102204\n",
      "train loss:0.0026876036798182752\n",
      "train loss:0.004938895111972991\n",
      "train loss:0.011997968101795063\n",
      "train loss:0.006361318556644586\n",
      "train loss:0.0022114903567692803\n",
      "train loss:0.01914556442632362\n",
      "train loss:0.012136369214258966\n",
      "train loss:0.008044390506041534\n",
      "train loss:0.018584502918033714\n",
      "train loss:0.011036781774461825\n",
      "train loss:0.00922786884479418\n",
      "train loss:0.005148017137204131\n",
      "train loss:0.013271209269144844\n",
      "train loss:0.052397079368218434\n",
      "train loss:0.008933056705783348\n",
      "train loss:0.010807557607860903\n",
      "train loss:0.003624515189997193\n",
      "train loss:0.0035788742973914193\n",
      "train loss:0.002050087432311443\n",
      "train loss:0.021528741224294472\n",
      "train loss:0.0033417584603473455\n",
      "train loss:0.01832628498297608\n",
      "train loss:0.022975384326062467\n",
      "train loss:0.0015246592470534372\n",
      "train loss:0.010062274825298347\n",
      "train loss:0.005885411286783553\n",
      "train loss:0.05196297756532469\n",
      "train loss:0.005421801830047734\n",
      "train loss:0.02227539308334806\n",
      "train loss:0.0053942924372851146\n",
      "train loss:0.009189820077635504\n",
      "train loss:0.011732714162481417\n",
      "train loss:0.005107363719363033\n",
      "train loss:0.016319969037319377\n",
      "train loss:0.006694674320034055\n",
      "train loss:0.01030048276893366\n",
      "train loss:0.005128900227848552\n",
      "train loss:0.021586766855829106\n",
      "train loss:0.00624001288845562\n",
      "train loss:0.008590450958343834\n",
      "train loss:0.006672643141682319\n",
      "train loss:0.0017235936011612614\n",
      "train loss:0.0022078309277590276\n",
      "train loss:0.02164746223526538\n",
      "train loss:0.013872132589535164\n",
      "train loss:0.022321078700196333\n",
      "train loss:0.0043507699865793495\n",
      "train loss:0.012672923937287042\n",
      "train loss:0.019892051591010044\n",
      "train loss:0.005202179324142651\n",
      "train loss:0.0011242690545082328\n",
      "train loss:0.003092806638468693\n",
      "train loss:0.014181635821015039\n",
      "train loss:0.03081242156429274\n",
      "train loss:0.02399993242084875\n",
      "train loss:0.012040277192072584\n",
      "train loss:0.03854627562278611\n",
      "train loss:0.01022567992190164\n",
      "train loss:0.0474692340471899\n",
      "train loss:0.0200757337955449\n",
      "train loss:0.005372045416123\n",
      "train loss:0.005036323478603384\n",
      "train loss:0.026461537533943102\n",
      "train loss:0.001480931038440496\n",
      "train loss:0.001638752699958951\n",
      "train loss:0.022446523469522105\n",
      "train loss:0.008629409964605672\n",
      "train loss:0.005486325340420079\n",
      "train loss:0.002220763731564342\n",
      "train loss:0.002771143654371297\n",
      "train loss:0.005496092801193418\n",
      "train loss:0.016815372808919978\n",
      "train loss:0.008656566472986236\n",
      "train loss:0.009982703261005041\n",
      "train loss:0.002925417671173979\n",
      "train loss:0.007668752312382025\n",
      "train loss:0.006307608123912503\n",
      "train loss:0.007007994769755094\n",
      "train loss:0.01486664422278638\n",
      "train loss:0.003832569535554484\n",
      "train loss:0.011438914757251778\n",
      "train loss:0.002717933648489446\n",
      "train loss:0.05436238090698443\n",
      "train loss:0.029666296044046976\n",
      "train loss:0.022095576333999688\n",
      "train loss:0.005937413749434787\n",
      "train loss:0.010071586004657369\n",
      "train loss:0.01060641161193053\n",
      "train loss:0.0033973248058322973\n",
      "train loss:0.0016921134462672643\n",
      "train loss:0.023981942179581273\n",
      "train loss:0.029344631890840977\n",
      "train loss:0.003096960599616059\n",
      "train loss:0.02343391504692999\n",
      "train loss:0.02165636819394786\n",
      "train loss:0.0371961639495238\n",
      "train loss:0.014151034899256456\n",
      "train loss:0.006798923591678833\n",
      "train loss:0.00317059860479009\n",
      "train loss:0.009145550636862539\n",
      "train loss:0.030758733725553534\n",
      "train loss:0.010039560553907438\n",
      "train loss:0.004398811947133221\n",
      "train loss:0.00381903429163783\n",
      "train loss:0.001080274533997161\n",
      "train loss:0.006078174042421412\n",
      "train loss:0.010217383958862793\n",
      "train loss:0.01926052926027638\n",
      "train loss:0.008388641219651065\n",
      "train loss:0.01129736877026206\n",
      "train loss:0.03757848999670926\n",
      "train loss:0.009866452051221277\n",
      "train loss:0.007872618594336593\n",
      "train loss:0.002628882269434575\n",
      "train loss:0.02763774071858478\n",
      "train loss:0.011925702597067246\n",
      "train loss:0.03414922423340254\n",
      "train loss:0.006463493905295405\n",
      "train loss:0.04048527523445486\n",
      "train loss:0.005423123082466527\n",
      "train loss:0.018629148982467144\n",
      "train loss:0.01794190730528038\n",
      "train loss:0.008928909728218023\n",
      "train loss:0.06892041786240838\n",
      "train loss:0.004525027046635723\n",
      "train loss:0.03675265133806958\n",
      "train loss:0.01692676561725523\n",
      "train loss:0.056418338458141835\n",
      "train loss:0.007489460941038936\n",
      "train loss:0.04497479551495749\n",
      "train loss:0.006031979721239878\n",
      "train loss:0.052899850429372196\n",
      "train loss:0.005874141512633539\n",
      "train loss:0.007008381530078798\n",
      "train loss:0.011113709101102742\n",
      "train loss:0.011542518857061472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008504190506568605\n",
      "train loss:0.07054844630165466\n",
      "train loss:0.0077315271106507336\n",
      "train loss:0.02628154687158428\n",
      "train loss:0.017675575383200758\n",
      "train loss:0.0025506059207560444\n",
      "train loss:0.001174235616785292\n",
      "train loss:0.01558820059516448\n",
      "train loss:0.02337279758923017\n",
      "train loss:0.04861452094294555\n",
      "train loss:0.05933051141129328\n",
      "train loss:0.02911230931124915\n",
      "train loss:0.009645755969248273\n",
      "train loss:0.003441053562146089\n",
      "train loss:0.012568914197680454\n",
      "train loss:0.007865807120802204\n",
      "train loss:0.021220129795127204\n",
      "train loss:0.003289673595400393\n",
      "train loss:0.06307976935400705\n",
      "train loss:0.010625108294983133\n",
      "train loss:0.0008486837684384337\n",
      "train loss:0.0019537324499748297\n",
      "train loss:0.060203061511714805\n",
      "train loss:0.01299012396139476\n",
      "train loss:0.019244890984735558\n",
      "train loss:0.017874233581981844\n",
      "train loss:0.011160897130349574\n",
      "train loss:0.0012639758269406235\n",
      "train loss:0.02498316630527405\n",
      "train loss:0.003752499066347823\n",
      "train loss:0.007246202759488819\n",
      "train loss:0.011239233921017973\n",
      "train loss:0.003056182351022489\n",
      "train loss:0.008774146684512455\n",
      "train loss:0.0014900126406289984\n",
      "train loss:0.02336566122046425\n",
      "train loss:0.010257545306330376\n",
      "train loss:0.012199284999610552\n",
      "train loss:0.014493204684187013\n",
      "train loss:0.017622549178618493\n",
      "train loss:0.022261132370272715\n",
      "train loss:0.034909194480425815\n",
      "train loss:0.015612796156030409\n",
      "train loss:0.006238843223488904\n",
      "train loss:0.016769608845466678\n",
      "train loss:0.011010921885856135\n",
      "train loss:0.0029079266123652556\n",
      "train loss:0.01581561627793466\n",
      "train loss:0.003069002677830016\n",
      "train loss:0.018288562234628433\n",
      "train loss:0.00793657675620909\n",
      "train loss:0.017381417856755378\n",
      "train loss:0.021481342374194606\n",
      "train loss:0.02534894535483849\n",
      "train loss:0.02451273621010246\n",
      "train loss:0.05218783137636081\n",
      "train loss:0.03559167469507232\n",
      "train loss:0.017426533985751485\n",
      "train loss:0.017262174478069856\n",
      "train loss:0.014987113516371282\n",
      "train loss:0.011602387589401346\n",
      "train loss:0.008790115862362669\n",
      "train loss:0.002428917285529627\n",
      "train loss:0.015579969417517188\n",
      "train loss:0.015232007003644405\n",
      "train loss:0.006218670841223049\n",
      "train loss:0.016150497189138868\n",
      "train loss:0.01461183891081101\n",
      "train loss:0.008426926751212753\n",
      "train loss:0.008173149583346594\n",
      "train loss:0.016195461198922255\n",
      "train loss:0.017159919006858242\n",
      "train loss:0.02024443050171149\n",
      "train loss:0.010700211878975177\n",
      "train loss:0.008726841705900329\n",
      "train loss:0.00663108615803582\n",
      "train loss:0.00989670163749299\n",
      "train loss:0.007579242168329082\n",
      "train loss:0.02072170119721944\n",
      "train loss:0.04995999587754821\n",
      "train loss:0.025573346283909393\n",
      "train loss:0.011778241796169151\n",
      "train loss:0.01506296657987512\n",
      "train loss:0.007735196305706519\n",
      "train loss:0.005966905119458821\n",
      "train loss:0.042777477474469666\n",
      "train loss:0.00480356986048891\n",
      "train loss:0.005991966949002619\n",
      "train loss:0.0020855171188405032\n",
      "train loss:0.0012676552795068685\n",
      "train loss:0.046445691990447104\n",
      "train loss:0.0046142358274770525\n",
      "train loss:0.006277810168163938\n",
      "train loss:0.020310291122165557\n",
      "train loss:0.0035690384207498534\n",
      "train loss:0.019121740274958474\n",
      "train loss:0.022684851748998085\n",
      "train loss:0.005757005235358453\n",
      "train loss:0.08043781340511448\n",
      "train loss:0.0439267845647017\n",
      "train loss:0.018744690306583166\n",
      "train loss:0.0014818341283598607\n",
      "train loss:0.04217182999680183\n",
      "train loss:0.00939248311032044\n",
      "train loss:0.01807519649677156\n",
      "train loss:0.0057864889078825055\n",
      "train loss:0.007839756490892658\n",
      "train loss:0.004438613518060005\n",
      "train loss:0.03330925565285431\n",
      "train loss:0.021418802315096793\n",
      "train loss:0.04166005251219132\n",
      "train loss:0.015390452812352455\n",
      "train loss:0.005256373365988023\n",
      "train loss:0.005930201509110444\n",
      "train loss:0.0012133936251765391\n",
      "train loss:0.06179826211604818\n",
      "train loss:0.0185779460815097\n",
      "train loss:0.01653894279619367\n",
      "train loss:0.0019492522638319884\n",
      "train loss:0.03070952530588942\n",
      "train loss:0.06871262603792569\n",
      "train loss:0.01155087782710941\n",
      "train loss:0.013045795162887947\n",
      "train loss:0.026259541310351322\n",
      "train loss:0.004196510128170077\n",
      "train loss:0.0062555503663897834\n",
      "train loss:0.0025409396996469236\n",
      "train loss:0.026729748185817404\n",
      "train loss:0.029656645297942805\n",
      "train loss:0.025327915798293462\n",
      "train loss:0.014247439413820576\n",
      "train loss:0.008598434329973544\n",
      "train loss:0.05273563243734285\n",
      "train loss:0.01663799028324773\n",
      "train loss:0.0082052318218493\n",
      "train loss:0.004486142078964777\n",
      "train loss:0.007984782758672596\n",
      "train loss:0.005708698922326557\n",
      "train loss:0.008201946932176553\n",
      "train loss:0.005157256949656975\n",
      "train loss:0.015701469555868854\n",
      "train loss:0.05281154720867161\n",
      "train loss:0.0018896044024092193\n",
      "train loss:0.00806932076786797\n",
      "train loss:0.02009051483039315\n",
      "train loss:0.010010607750153942\n",
      "train loss:0.05543943894694315\n",
      "train loss:0.0030507587934592278\n",
      "train loss:0.0008189704721393898\n",
      "train loss:0.009761836052814\n",
      "train loss:0.007817793690025004\n",
      "train loss:0.003238676274485607\n",
      "train loss:0.009318195303000541\n",
      "train loss:0.00842718869913269\n",
      "train loss:0.054911004379018497\n",
      "train loss:0.005253048093214746\n",
      "train loss:0.004687837963802798\n",
      "train loss:0.003742643689807097\n",
      "train loss:0.01760499207616401\n",
      "train loss:0.00339871712476508\n",
      "train loss:0.04416443954328794\n",
      "train loss:0.02161016983576121\n",
      "train loss:0.007295352993259785\n",
      "train loss:0.002017775029026537\n",
      "train loss:0.0013359204925284813\n",
      "train loss:0.024042642451916087\n",
      "train loss:0.015128356254221336\n",
      "train loss:0.003645704440815766\n",
      "train loss:0.0083918782603656\n",
      "train loss:0.0033606347368335277\n",
      "train loss:0.006379564305535366\n",
      "train loss:0.010415943714082488\n",
      "train loss:0.009287989318759751\n",
      "train loss:0.03555409333306893\n",
      "train loss:0.028831926261319706\n",
      "train loss:0.014994512297833695\n",
      "train loss:0.010698147858493257\n",
      "train loss:0.015196124059943297\n",
      "train loss:0.008789723244958355\n",
      "train loss:0.05873281158913983\n",
      "train loss:0.012461708712621427\n",
      "train loss:0.0031314744996260428\n",
      "train loss:0.016653114569146345\n",
      "train loss:0.0023490031250537574\n",
      "train loss:0.009379896620444538\n",
      "train loss:0.015604648096136865\n",
      "train loss:0.006793846492652793\n",
      "train loss:0.13241246606893367\n",
      "train loss:0.014326954237537937\n",
      "train loss:0.010204779356502942\n",
      "train loss:0.015112998986037733\n",
      "train loss:0.007646219024349485\n",
      "train loss:0.011833437268351845\n",
      "train loss:0.00898081506597138\n",
      "train loss:0.003370595082767706\n",
      "train loss:0.006332250700679186\n",
      "train loss:0.023379803832989633\n",
      "train loss:0.014502468738900846\n",
      "train loss:0.02005375659063001\n",
      "train loss:0.09087883876082264\n",
      "train loss:0.01106126432291832\n",
      "train loss:0.008570580370989095\n",
      "train loss:0.0855308994590116\n",
      "train loss:0.002410453533205102\n",
      "train loss:0.0023023829212680084\n",
      "train loss:0.02429469244019651\n",
      "train loss:0.0075955619446751955\n",
      "train loss:0.013512325816534602\n",
      "train loss:0.002652198565326554\n",
      "train loss:0.005586890463687265\n",
      "train loss:0.008861339996183212\n",
      "train loss:0.03888426015412841\n",
      "train loss:0.0035919512214837284\n",
      "train loss:0.004802255772805071\n",
      "train loss:0.016959071743936634\n",
      "train loss:0.00706017723700848\n",
      "train loss:0.02656194102426792\n",
      "train loss:0.005934375979858807\n",
      "train loss:0.0074212834295936435\n",
      "train loss:0.009475144523175093\n",
      "train loss:0.0073732908789888784\n",
      "train loss:0.0149288108673701\n",
      "train loss:0.02302822496627359\n",
      "train loss:0.01054585154400226\n",
      "train loss:0.007674344538449724\n",
      "train loss:0.003761083619090276\n",
      "train loss:0.014403524741124727\n",
      "train loss:0.002410866981497232\n",
      "train loss:0.04037831224540095\n",
      "train loss:0.013802692857753656\n",
      "train loss:0.002020061014924636\n",
      "train loss:0.009612009267254713\n",
      "train loss:0.003116565565934279\n",
      "train loss:0.018111052584797324\n",
      "train loss:0.07862224864876159\n",
      "train loss:0.003384695610276786\n",
      "train loss:0.009303035732776101\n",
      "train loss:0.0014929985455541248\n",
      "train loss:0.0018568990347368971\n",
      "train loss:0.005645651723050531\n",
      "train loss:0.00857664346632727\n",
      "train loss:0.01178366983524668\n",
      "train loss:0.01458646975235067\n",
      "train loss:0.01640509157900992\n",
      "train loss:0.036009177391171925\n",
      "train loss:0.006699811405910681\n",
      "train loss:0.0020624766444774668\n",
      "train loss:0.004856748535539051\n",
      "train loss:0.023085694594799512\n",
      "train loss:0.010194653353466556\n",
      "train loss:0.003984648775326453\n",
      "train loss:0.005372157451429548\n",
      "train loss:0.0022065299896414274\n",
      "train loss:0.014441478350966753\n",
      "train loss:0.018330647485126216\n",
      "train loss:0.004808527606433522\n",
      "train loss:0.017667690646754455\n",
      "train loss:0.007166535164719597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01396075033902675\n",
      "train loss:0.014576671424028197\n",
      "train loss:0.025654018634316288\n",
      "train loss:0.0045412439801875175\n",
      "train loss:0.013142922459277364\n",
      "train loss:0.010924424735617406\n",
      "train loss:0.006677815323847788\n",
      "train loss:0.002374627732565382\n",
      "train loss:0.007439472239490685\n",
      "train loss:0.009771662956164596\n",
      "train loss:0.006522640679927031\n",
      "train loss:0.006297226917547591\n",
      "train loss:0.016848254759603543\n",
      "train loss:0.009439780595632856\n",
      "train loss:0.0028732705339945437\n",
      "train loss:0.0015166245508358247\n",
      "train loss:0.0026838029335095924\n",
      "train loss:0.02611888161872638\n",
      "train loss:0.000603367711729358\n",
      "train loss:0.006860083721327199\n",
      "train loss:0.020230776855887086\n",
      "train loss:0.01760628657667662\n",
      "train loss:0.012131463711701445\n",
      "train loss:0.009638826733133338\n",
      "train loss:0.006361335334417096\n",
      "train loss:0.0014818122709268741\n",
      "train loss:0.021785142885271228\n",
      "train loss:0.010985023139259049\n",
      "train loss:0.006233593560794043\n",
      "train loss:0.005784747387336117\n",
      "train loss:0.017920399927566225\n",
      "train loss:0.006171965754352573\n",
      "train loss:0.0022482181009107634\n",
      "train loss:0.002351450978092056\n",
      "train loss:0.006188831929518157\n",
      "train loss:0.016648020800471622\n",
      "train loss:0.017345025506356828\n",
      "train loss:0.005584390960235069\n",
      "train loss:0.005729653946044272\n",
      "train loss:0.004002134758818805\n",
      "train loss:0.012819443714330601\n",
      "train loss:0.006645451271276828\n",
      "train loss:0.0023621137615340185\n",
      "train loss:0.01961541957196925\n",
      "train loss:0.013680176596494655\n",
      "train loss:0.008806072138556975\n",
      "train loss:0.004343257630389532\n",
      "train loss:0.014410395377004177\n",
      "train loss:0.022852595754777886\n",
      "train loss:0.003932675153044258\n",
      "train loss:0.0007200426534111194\n",
      "train loss:0.03762541280298368\n",
      "train loss:0.003648158426363442\n",
      "train loss:0.0042120327273007475\n",
      "train loss:0.004483997008264373\n",
      "train loss:0.0161739896057012\n",
      "train loss:0.02916276899741393\n",
      "train loss:0.005088174293372556\n",
      "train loss:0.0026870784299456566\n",
      "train loss:0.0924134455064405\n",
      "train loss:0.00365776457093837\n",
      "train loss:0.0036166386161022397\n",
      "train loss:0.0033115039814905927\n",
      "train loss:0.006601529545077697\n",
      "train loss:0.048541479561662444\n",
      "train loss:0.0023597721925052175\n",
      "train loss:0.007131069874060043\n",
      "train loss:0.008150347741183171\n",
      "train loss:0.012493292909799043\n",
      "train loss:0.005203252012402144\n",
      "train loss:0.008965383981611862\n",
      "train loss:0.0036684573440033826\n",
      "train loss:0.04011289703227427\n",
      "train loss:0.003287456504031965\n",
      "train loss:0.016115904738928762\n",
      "train loss:0.002215586962969249\n",
      "train loss:0.007998811163086787\n",
      "train loss:0.010981638554834017\n",
      "train loss:0.005178351699487302\n",
      "train loss:0.04432923161129345\n",
      "train loss:0.0058608641213370475\n",
      "train loss:0.035027330142783\n",
      "train loss:0.005315844688258702\n",
      "train loss:0.01551350183987259\n",
      "train loss:0.005865970134298835\n",
      "train loss:0.0033293458825973225\n",
      "train loss:0.009684489370663612\n",
      "train loss:0.018903613238397315\n",
      "train loss:0.013045319745824966\n",
      "train loss:0.023362531037602628\n",
      "train loss:0.011317949357939776\n",
      "train loss:0.004160089394606614\n",
      "train loss:0.008330964110552546\n",
      "train loss:0.011096916024915839\n",
      "train loss:0.0069191128691273\n",
      "train loss:0.004502276274562374\n",
      "train loss:0.005628331467666916\n",
      "train loss:0.0020652142664930604\n",
      "train loss:0.008102625199724147\n",
      "train loss:0.02389843688514575\n",
      "=== epoch:9, train acc:0.994, test acc:0.986 ===\n",
      "train loss:0.007524864032624635\n",
      "train loss:0.008635540338099813\n",
      "train loss:0.0065427024495525975\n",
      "train loss:0.01091221841841451\n",
      "train loss:0.009131139193588746\n",
      "train loss:0.003423298784248288\n",
      "train loss:0.002415782538896668\n",
      "train loss:0.006255081163270738\n",
      "train loss:0.04813792001455966\n",
      "train loss:0.018619105662260844\n",
      "train loss:0.004285172596819114\n",
      "train loss:0.0035407493066876954\n",
      "train loss:0.005870384890560393\n",
      "train loss:0.010697852592250432\n",
      "train loss:0.013913481769296182\n",
      "train loss:0.001736093224765796\n",
      "train loss:0.0014129034616392287\n",
      "train loss:0.03116769297350946\n",
      "train loss:0.013604624094229589\n",
      "train loss:0.0049396537528851\n",
      "train loss:0.012235364850825083\n",
      "train loss:0.006964305187963406\n",
      "train loss:0.0030108462842844035\n",
      "train loss:0.014593526174529746\n",
      "train loss:0.003041700438065123\n",
      "train loss:0.043222976730732145\n",
      "train loss:0.006467799364474416\n",
      "train loss:0.029168456667418297\n",
      "train loss:0.01474204447832243\n",
      "train loss:0.027305683341868458\n",
      "train loss:0.028780433560874855\n",
      "train loss:0.002690367124217238\n",
      "train loss:0.05831691397760687\n",
      "train loss:0.02045516385025841\n",
      "train loss:0.0037753904784919644\n",
      "train loss:0.019367891296131926\n",
      "train loss:0.003958309216725807\n",
      "train loss:0.009534487546810758\n",
      "train loss:0.001219353516938002\n",
      "train loss:0.06727403829642288\n",
      "train loss:0.021518844008005716\n",
      "train loss:0.03645125085922451\n",
      "train loss:0.03637042350905948\n",
      "train loss:0.009207275947786375\n",
      "train loss:0.002911334461254496\n",
      "train loss:0.010206828390203615\n",
      "train loss:0.029435273625115707\n",
      "train loss:0.018213558932419355\n",
      "train loss:0.025706395034762682\n",
      "train loss:0.0009517371042283379\n",
      "train loss:0.014648864404415998\n",
      "train loss:0.00502919230404077\n",
      "train loss:0.006720981822532373\n",
      "train loss:0.018493407672925132\n",
      "train loss:0.0040063704567318255\n",
      "train loss:0.017723506330618588\n",
      "train loss:0.007091317792095311\n",
      "train loss:0.0031717278446816498\n",
      "train loss:0.0020914243672225897\n",
      "train loss:0.005487670368047534\n",
      "train loss:0.004374356534215944\n",
      "train loss:0.0361048289280502\n",
      "train loss:0.005027253154366009\n",
      "train loss:0.003433411666467853\n",
      "train loss:0.015490890588637592\n",
      "train loss:0.0035250442085541607\n",
      "train loss:0.006920252984192623\n",
      "train loss:0.006398453431641993\n",
      "train loss:0.00371265717435391\n",
      "train loss:0.004737117954288588\n",
      "train loss:0.0029240098758088052\n",
      "train loss:0.01720085528426944\n",
      "train loss:0.002920535642839099\n",
      "train loss:0.003008676256805624\n",
      "train loss:0.001916373681138705\n",
      "train loss:0.019029972460715295\n",
      "train loss:0.02464610807095416\n",
      "train loss:0.003263769668302964\n",
      "train loss:0.009124951719687904\n",
      "train loss:0.013689790652617962\n",
      "train loss:0.002847958972967863\n",
      "train loss:0.002342405906914955\n",
      "train loss:0.003550021352345017\n",
      "train loss:0.006168605920941098\n",
      "train loss:0.0028471586063482123\n",
      "train loss:0.014641178579175778\n",
      "train loss:0.008709136988700123\n",
      "train loss:0.0028178298940102846\n",
      "train loss:0.0015137599199680375\n",
      "train loss:0.019601843256949702\n",
      "train loss:0.0038817415705692006\n",
      "train loss:0.04699692137419666\n",
      "train loss:0.004324919313973585\n",
      "train loss:0.010745685221088923\n",
      "train loss:0.024799452729450035\n",
      "train loss:0.010710987673680956\n",
      "train loss:0.009229253358345969\n",
      "train loss:0.005009784901542952\n",
      "train loss:0.008939796945673328\n",
      "train loss:0.03919729779098073\n",
      "train loss:0.010436455740299524\n",
      "train loss:0.004541209831128612\n",
      "train loss:0.0038658470160310154\n",
      "train loss:0.03354998538850179\n",
      "train loss:0.004067854158667663\n",
      "train loss:0.02560768028711825\n",
      "train loss:0.04514962836503201\n",
      "train loss:0.012612567175898372\n",
      "train loss:0.00799853578103177\n",
      "train loss:0.007325014291980677\n",
      "train loss:0.0028169255179612\n",
      "train loss:0.002178896506571629\n",
      "train loss:0.05258931702265057\n",
      "train loss:0.014453782799856998\n",
      "train loss:0.008835617162692315\n",
      "train loss:0.003882922569741371\n",
      "train loss:0.00797429716136792\n",
      "train loss:0.0195971809973108\n",
      "train loss:0.0304401397320956\n",
      "train loss:0.08682947093141609\n",
      "train loss:0.020234109624438737\n",
      "train loss:0.002550979581315705\n",
      "train loss:0.0031781074625282855\n",
      "train loss:0.005331281633816817\n",
      "train loss:0.026815858544229437\n",
      "train loss:0.0019858406899334905\n",
      "train loss:0.012066550223800394\n",
      "train loss:0.012144834004040674\n",
      "train loss:0.043287036893495084\n",
      "train loss:0.0033897660485876185\n",
      "train loss:0.0026456540172221394\n",
      "train loss:0.006825737668693427\n",
      "train loss:0.005138007180336301\n",
      "train loss:0.011254868241375502\n",
      "train loss:0.007265299955328359\n",
      "train loss:0.0034625819338753305\n",
      "train loss:0.015213270522903402\n",
      "train loss:0.011574159583017394\n",
      "train loss:0.016175020158903687\n",
      "train loss:0.005882232413851216\n",
      "train loss:0.00568037193409192\n",
      "train loss:0.0010274365941673356\n",
      "train loss:0.005287951560695252\n",
      "train loss:0.00613434339662253\n",
      "train loss:0.012262804771732295\n",
      "train loss:0.0027310912818618626\n",
      "train loss:0.002247423136901889\n",
      "train loss:0.006217731737907772\n",
      "train loss:0.004843500931531203\n",
      "train loss:0.005766792521647867\n",
      "train loss:0.00240809627671477\n",
      "train loss:0.005057343660483469\n",
      "train loss:0.009147871585396287\n",
      "train loss:0.009261991613267694\n",
      "train loss:0.0063297926505366964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008185729383640391\n",
      "train loss:0.050266359894010716\n",
      "train loss:0.003999936411969294\n",
      "train loss:0.023973906559371566\n",
      "train loss:0.009924053488908817\n",
      "train loss:0.010440118588526502\n",
      "train loss:0.0022405357007503845\n",
      "train loss:0.005015652759482467\n",
      "train loss:0.009901039046584896\n",
      "train loss:0.00816855938087938\n",
      "train loss:0.041841161484315215\n",
      "train loss:0.02662841495313005\n",
      "train loss:0.008875264165187175\n",
      "train loss:0.0009100750825688654\n",
      "train loss:0.0032607034134631823\n",
      "train loss:0.012939207112792766\n",
      "train loss:0.010452849974946585\n",
      "train loss:0.01237266891358466\n",
      "train loss:0.0033941468936644348\n",
      "train loss:0.011707384137671884\n",
      "train loss:0.004636945104889333\n",
      "train loss:0.018816139884283968\n",
      "train loss:0.0038593051262584303\n",
      "train loss:0.006012692484200013\n",
      "train loss:0.003265870667993529\n",
      "train loss:0.004409856134711496\n",
      "train loss:0.003269326370685987\n",
      "train loss:0.041774891243961436\n",
      "train loss:0.024903099024024895\n",
      "train loss:0.005243309327138969\n",
      "train loss:0.010903822527743252\n",
      "train loss:0.004744353917773117\n",
      "train loss:0.010847620619032983\n",
      "train loss:0.006898868449594173\n",
      "train loss:0.008045706920454811\n",
      "train loss:0.003549532613474012\n",
      "train loss:0.010263285528248654\n",
      "train loss:0.0019820691698803133\n",
      "train loss:0.010214317279644367\n",
      "train loss:0.012737403604136317\n",
      "train loss:0.028973793634325264\n",
      "train loss:0.003006206620696077\n",
      "train loss:0.036718783662533096\n",
      "train loss:0.005581274360551864\n",
      "train loss:0.0012173534738996235\n",
      "train loss:0.02600622179054662\n",
      "train loss:0.007390848978238731\n",
      "train loss:0.02616454699850206\n",
      "train loss:0.005017454630057906\n",
      "train loss:0.022244119656634295\n",
      "train loss:0.013269464782633753\n",
      "train loss:0.003708584783175477\n",
      "train loss:0.02256963938358636\n",
      "train loss:0.0024051269314359987\n",
      "train loss:0.03220992399672195\n",
      "train loss:0.015165404461017733\n",
      "train loss:0.006501068060117953\n",
      "train loss:0.030496358084720458\n",
      "train loss:0.026297991417402907\n",
      "train loss:0.0026577675158225168\n",
      "train loss:0.006434655936689704\n",
      "train loss:0.008755114191378687\n",
      "train loss:0.01791885759727832\n",
      "train loss:0.00363912218553095\n",
      "train loss:0.007456947426295879\n",
      "train loss:0.0036040451787258147\n",
      "train loss:0.005686192987600234\n",
      "train loss:0.005193143463856149\n",
      "train loss:0.023821926919223305\n",
      "train loss:0.002556414164834044\n",
      "train loss:0.0024623947849390054\n",
      "train loss:0.004504030479421386\n",
      "train loss:0.003777006906013615\n",
      "train loss:0.0028115704413691606\n",
      "train loss:0.0018920084894932577\n",
      "train loss:0.005379724994915855\n",
      "train loss:0.004641191143321412\n",
      "train loss:0.007103135965888966\n",
      "train loss:0.013875160362269883\n",
      "train loss:0.005861180003722223\n",
      "train loss:0.019708868291705362\n",
      "train loss:0.011003527703607826\n",
      "train loss:0.006407284304260852\n",
      "train loss:0.012057219143309183\n",
      "train loss:0.10044605294608777\n",
      "train loss:0.007641908324042771\n",
      "train loss:0.002084687835157592\n",
      "train loss:0.014914354499293757\n",
      "train loss:0.006822068222856318\n",
      "train loss:0.011373627420856958\n",
      "train loss:0.003760258308781211\n",
      "train loss:0.01009949544162886\n",
      "train loss:0.000897472570534335\n",
      "train loss:0.0066601596698660824\n",
      "train loss:0.004984769186123155\n",
      "train loss:0.0032343363035939325\n",
      "train loss:0.005994368558829911\n",
      "train loss:0.005301573811394444\n",
      "train loss:0.010905594985532053\n",
      "train loss:0.001979596233061421\n",
      "train loss:0.009726397648068867\n",
      "train loss:0.001047482539106774\n",
      "train loss:0.021862812553238492\n",
      "train loss:0.015532304857744848\n",
      "train loss:0.015111145208107184\n",
      "train loss:0.0031579316066191855\n",
      "train loss:0.010513549497066621\n",
      "train loss:0.0023667057221866896\n",
      "train loss:0.004757664844993426\n",
      "train loss:0.008814542174239938\n",
      "train loss:0.01331440206085263\n",
      "train loss:0.005633049845161361\n",
      "train loss:0.0047231108907223405\n",
      "train loss:0.010830355225548781\n",
      "train loss:0.00913643144262977\n",
      "train loss:0.009175515230305291\n",
      "train loss:0.002355794111246635\n",
      "train loss:0.005004868754151546\n",
      "train loss:0.0022892997209128306\n",
      "train loss:0.03549241865524466\n",
      "train loss:0.002093220427523043\n",
      "train loss:0.012427013079406201\n",
      "train loss:0.009015598691263602\n",
      "train loss:0.03713482154007763\n",
      "train loss:0.012326101415848856\n",
      "train loss:0.018032872481398027\n",
      "train loss:0.0290959362606532\n",
      "train loss:0.005293551384996858\n",
      "train loss:0.002485391080059916\n",
      "train loss:0.005817548047115638\n",
      "train loss:0.006553605765780607\n",
      "train loss:0.012779834247534885\n",
      "train loss:0.003304520357624709\n",
      "train loss:0.017318335172719315\n",
      "train loss:0.01355632184089321\n",
      "train loss:0.007647304443395514\n",
      "train loss:0.004670349129931441\n",
      "train loss:0.012058855160221043\n",
      "train loss:0.010705153904462701\n",
      "train loss:0.007425371801148435\n",
      "train loss:0.009450993692793716\n",
      "train loss:0.0006750785339253311\n",
      "train loss:0.011781958760705655\n",
      "train loss:0.023390730699472676\n",
      "train loss:0.01828119680312704\n",
      "train loss:0.0017567231161853495\n",
      "train loss:0.002064266115944717\n",
      "train loss:0.025705535587693763\n",
      "train loss:0.0023829275887358296\n",
      "train loss:0.024681658923036545\n",
      "train loss:0.007902461943071547\n",
      "train loss:0.0043155386908396215\n",
      "train loss:0.0071168548283043675\n",
      "train loss:0.004602893473571657\n",
      "train loss:0.0027722473538787677\n",
      "train loss:0.014294246441890994\n",
      "train loss:0.0026252238947475663\n",
      "train loss:0.0010836633198976068\n",
      "train loss:0.004097297520464711\n",
      "train loss:0.0018837293002023072\n",
      "train loss:0.0035461947046359337\n",
      "train loss:0.005634595797741827\n",
      "train loss:0.010178766139720099\n",
      "train loss:0.012412518589831294\n",
      "train loss:0.007960249779789449\n",
      "train loss:0.006162010268664117\n",
      "train loss:0.005798619204153718\n",
      "train loss:0.0037483323209411543\n",
      "train loss:0.007497247900146367\n",
      "train loss:0.004517900159204551\n",
      "train loss:0.0018954262911136464\n",
      "train loss:0.01249984575464694\n",
      "train loss:0.004773760232446654\n",
      "train loss:0.002078898660341032\n",
      "train loss:0.009520413474598867\n",
      "train loss:0.002502019384209318\n",
      "train loss:0.0023496952299844253\n",
      "train loss:0.001521979958982897\n",
      "train loss:0.003958454419948631\n",
      "train loss:0.003301036752316446\n",
      "train loss:0.006018569870199154\n",
      "train loss:0.004161480163347911\n",
      "train loss:0.004258808803675274\n",
      "train loss:0.008182643065433329\n",
      "train loss:0.0030130847161417536\n",
      "train loss:0.006627460228082236\n",
      "train loss:0.011412105996783595\n",
      "train loss:0.0026788197664177754\n",
      "train loss:0.05640547520849251\n",
      "train loss:0.00496663722132078\n",
      "train loss:0.0017535573772441782\n",
      "train loss:0.0031059596114299056\n",
      "train loss:0.010564694838510653\n",
      "train loss:0.008459174570889344\n",
      "train loss:0.0064047112492513466\n",
      "train loss:0.016135663773190617\n",
      "train loss:0.008638047916211072\n",
      "train loss:0.0020329372780204416\n",
      "train loss:0.0017349206851447134\n",
      "train loss:0.0021042295329406456\n",
      "train loss:0.0010158241916968444\n",
      "train loss:0.007726395900492157\n",
      "train loss:0.007019661615757872\n",
      "train loss:0.005097861573715385\n",
      "train loss:0.0005727384353483992\n",
      "train loss:0.0028415456073229727\n",
      "train loss:0.006849835835958524\n",
      "train loss:0.009469347956832675\n",
      "train loss:0.022088417749311126\n",
      "train loss:0.001528139855307833\n",
      "train loss:0.0025134800010868574\n",
      "train loss:0.006218658028849358\n",
      "train loss:0.005731483220150764\n",
      "train loss:0.0017590786180830668\n",
      "train loss:0.007179074562436117\n",
      "train loss:0.011901049420057144\n",
      "train loss:0.04490322511754893\n",
      "train loss:0.003654769056494186\n",
      "train loss:0.004499273118249576\n",
      "train loss:0.005734742247065359\n",
      "train loss:0.035117441150960806\n",
      "train loss:0.003093800809657408\n",
      "train loss:0.010808494713107197\n",
      "train loss:0.020013293564362586\n",
      "train loss:0.028707069096121737\n",
      "train loss:0.009728583916189413\n",
      "train loss:0.012821990178786552\n",
      "train loss:0.009874532052513393\n",
      "train loss:0.0005778117210095604\n",
      "train loss:0.016808203094729832\n",
      "train loss:0.007132027665016094\n",
      "train loss:0.008026208520534423\n",
      "train loss:0.05412303882871994\n",
      "train loss:0.0073652000871894194\n",
      "train loss:0.017823258406114734\n",
      "train loss:0.00569020661490343\n",
      "train loss:0.011397451180776836\n",
      "train loss:0.009693351254655242\n",
      "train loss:0.002467570263031725\n",
      "train loss:0.006557428361808385\n",
      "train loss:0.0014845803979699893\n",
      "train loss:0.0016021154912851945\n",
      "train loss:0.004853311490286778\n",
      "train loss:0.013342864728055006\n",
      "train loss:0.014005849757432942\n",
      "train loss:0.0034146275795055776\n",
      "train loss:0.007157151628186443\n",
      "train loss:0.016957970009802224\n",
      "train loss:0.0038819953135968057\n",
      "train loss:0.0018661686220460903\n",
      "train loss:0.002166480418377591\n",
      "train loss:0.018303998231632406\n",
      "train loss:0.0008495056772460428\n",
      "train loss:0.04637373922073915\n",
      "train loss:0.004090368029206765\n",
      "train loss:0.0015061126820011428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03470825674499017\n",
      "train loss:0.0016116100684622494\n",
      "train loss:0.04584081547548344\n",
      "train loss:0.029727758343719685\n",
      "train loss:0.02787945287681385\n",
      "train loss:0.0007687712906624429\n",
      "train loss:0.019473431580813744\n",
      "train loss:0.005124727502718845\n",
      "train loss:0.0037248120796285777\n",
      "train loss:0.004158803533367614\n",
      "train loss:0.014959196993109108\n",
      "train loss:0.039219044086585775\n",
      "train loss:0.020123455824099568\n",
      "train loss:0.013387935734336465\n",
      "train loss:0.014999406605536149\n",
      "train loss:0.007301373517457738\n",
      "train loss:0.006776233974683036\n",
      "train loss:0.0036904196697312625\n",
      "train loss:0.01087615034754005\n",
      "train loss:0.0272772202896154\n",
      "train loss:0.011344588230111927\n",
      "train loss:0.0018153830255633323\n",
      "train loss:0.0018096988895847793\n",
      "train loss:0.022574352805777454\n",
      "train loss:0.01154687553257064\n",
      "train loss:0.005470461008527842\n",
      "train loss:0.004506560031759735\n",
      "train loss:0.00427043052253073\n",
      "train loss:0.021911329458542562\n",
      "train loss:0.003492213479001402\n",
      "train loss:0.020607632316610034\n",
      "train loss:0.009891335637339682\n",
      "train loss:0.002278157857069725\n",
      "train loss:0.0018157155462571678\n",
      "train loss:0.0015616802537441548\n",
      "train loss:0.015224823922195676\n",
      "train loss:0.00635338863675638\n",
      "train loss:0.026299039867635647\n",
      "train loss:0.008562067678448073\n",
      "train loss:0.0013143459162334172\n",
      "train loss:0.009572068306881145\n",
      "train loss:0.0037718660649298957\n",
      "train loss:0.029356510866283072\n",
      "train loss:0.0033490280335667344\n",
      "train loss:0.006872879406292042\n",
      "train loss:0.002838093932216256\n",
      "train loss:0.0070682716266229\n",
      "train loss:0.008285612134610692\n",
      "train loss:0.005452398493981326\n",
      "train loss:0.0032284121888180545\n",
      "train loss:0.04951055373900029\n",
      "train loss:0.009889980027848086\n",
      "train loss:0.016299911472794946\n",
      "train loss:0.0245241658993135\n",
      "train loss:0.010206612673785212\n",
      "train loss:0.02337087256826534\n",
      "train loss:0.0045901565669592345\n",
      "train loss:0.005752997668626086\n",
      "train loss:0.016875217295840156\n",
      "train loss:0.002370150184479955\n",
      "train loss:0.021671495586103304\n",
      "train loss:0.00547178035731527\n",
      "train loss:0.011876575112923617\n",
      "train loss:0.0041404161440079254\n",
      "train loss:0.0020326404660350357\n",
      "train loss:0.017574953821932887\n",
      "train loss:0.0014266266183362549\n",
      "train loss:0.005835185079012725\n",
      "train loss:0.018680370874364388\n",
      "train loss:0.015714469478390784\n",
      "train loss:0.006316476539648234\n",
      "train loss:0.0014823059429233058\n",
      "train loss:0.014471264568477306\n",
      "train loss:0.008404245581782661\n",
      "train loss:0.005273129515918672\n",
      "train loss:0.005539359378150928\n",
      "train loss:0.0050318786932349304\n",
      "train loss:0.04254097385514186\n",
      "train loss:0.010420909277231225\n",
      "train loss:0.02623429989718513\n",
      "train loss:0.008167967911896832\n",
      "train loss:0.0049230528683732525\n",
      "train loss:0.07403143628627422\n",
      "train loss:0.002813513156155681\n",
      "train loss:0.0039399140455747385\n",
      "train loss:0.0007716176296363396\n",
      "train loss:0.0014023798433330306\n",
      "train loss:0.021556038084485106\n",
      "train loss:0.0016842501353180426\n",
      "train loss:0.003530574485076388\n",
      "train loss:0.021284642185274517\n",
      "train loss:0.006749430625358199\n",
      "train loss:0.008913724581051087\n",
      "train loss:0.016957751959132863\n",
      "train loss:0.04003814466523127\n",
      "train loss:0.010154803545195159\n",
      "train loss:0.0354030515401236\n",
      "train loss:0.0023817544095514178\n",
      "train loss:0.007228130699737629\n",
      "train loss:0.16384994324530397\n",
      "train loss:0.0025709772582798375\n",
      "train loss:0.005832221605014123\n",
      "train loss:0.019295366071893548\n",
      "train loss:0.007787416754508109\n",
      "train loss:0.17312827961745164\n",
      "train loss:0.07110752193582488\n",
      "train loss:0.0046155631250132355\n",
      "train loss:0.0027326465656314224\n",
      "train loss:0.010683082544950252\n",
      "train loss:0.009361751970573581\n",
      "train loss:0.0034183539152835697\n",
      "train loss:0.010296316228988436\n",
      "train loss:0.004583245791918819\n",
      "train loss:0.015744221690840977\n",
      "train loss:0.0069175359525533876\n",
      "train loss:0.01498473090333954\n",
      "train loss:0.021659087274086594\n",
      "train loss:0.036176854044854\n",
      "train loss:0.004165120216440981\n",
      "train loss:0.006473974698659624\n",
      "train loss:0.014511058282098784\n",
      "train loss:0.012413271738034103\n",
      "train loss:0.006837994806063594\n",
      "train loss:0.035251194913447415\n",
      "train loss:0.00734774616763477\n",
      "train loss:0.0026123738780096982\n",
      "train loss:0.0027930893881850365\n",
      "train loss:0.006641281385860568\n",
      "train loss:0.011569310675151476\n",
      "train loss:0.0016690263853231702\n",
      "train loss:0.0031034094652320453\n",
      "train loss:0.007102742489045047\n",
      "train loss:0.022932319284500124\n",
      "train loss:0.009942757411363377\n",
      "train loss:0.017309998600450335\n",
      "train loss:0.0034350050345259824\n",
      "train loss:0.0016482096399526708\n",
      "train loss:0.0015228052150609351\n",
      "train loss:0.0041435639588803435\n",
      "train loss:0.006295513034812872\n",
      "train loss:0.0024362923011649797\n",
      "train loss:0.026838244339211524\n",
      "train loss:0.01144533032315896\n",
      "train loss:0.03564131988267734\n",
      "train loss:0.0029946626927760205\n",
      "train loss:0.002304852644501004\n",
      "train loss:0.014579441453407957\n",
      "train loss:0.029137394370952953\n",
      "train loss:0.0019631473186741025\n",
      "train loss:0.013900057912972472\n",
      "train loss:0.004105141865524825\n",
      "train loss:0.0027502119262362724\n",
      "train loss:0.01666893540877608\n",
      "train loss:0.026327382744240735\n",
      "train loss:0.0027332899372199027\n",
      "train loss:0.024082824882898965\n",
      "train loss:0.009200502122512673\n",
      "train loss:0.002846464351525887\n",
      "train loss:0.05149637121608119\n",
      "train loss:0.06899900406761306\n",
      "train loss:0.0024653358832120945\n",
      "train loss:0.01829148524723451\n",
      "train loss:0.010935804826515141\n",
      "train loss:0.0031840573460102744\n",
      "train loss:0.04045385615497404\n",
      "train loss:0.03686903738898884\n",
      "train loss:0.029038215531428668\n",
      "train loss:0.004496027152505768\n",
      "train loss:0.005745731820176231\n",
      "train loss:0.02205696227550294\n",
      "train loss:0.009909747434057443\n",
      "train loss:0.002101378265852699\n",
      "train loss:0.03959989303433396\n",
      "train loss:0.005980936895635038\n",
      "train loss:0.012686228743826904\n",
      "train loss:0.011871362323753864\n",
      "train loss:0.01631941762425723\n",
      "train loss:0.007536980526691258\n",
      "train loss:0.0033007438528733007\n",
      "train loss:0.0014764565001030164\n",
      "train loss:0.06719903885437022\n",
      "train loss:0.004874626191717013\n",
      "train loss:0.03282745925119789\n",
      "train loss:0.004275358700570568\n",
      "train loss:0.005527126416992375\n",
      "train loss:0.0068246566158428725\n",
      "train loss:0.0040411895727257945\n",
      "train loss:0.0031450025181717677\n",
      "train loss:0.025138648650695226\n",
      "=== epoch:10, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.006942370380875736\n",
      "train loss:0.010178668336254222\n",
      "train loss:0.005834963516888061\n",
      "train loss:0.03276019385563981\n",
      "train loss:0.0025167047771989426\n",
      "train loss:0.0013315886558877069\n",
      "train loss:0.003109300238613621\n",
      "train loss:0.014992964334604812\n",
      "train loss:0.07069170353406017\n",
      "train loss:0.05831336358101941\n",
      "train loss:0.006202500888829505\n",
      "train loss:0.02893662679647524\n",
      "train loss:0.0036081703605773162\n",
      "train loss:0.017251663064056254\n",
      "train loss:0.006077644815470466\n",
      "train loss:0.0030432071111233944\n",
      "train loss:0.002695606272947951\n",
      "train loss:0.03432341164203259\n",
      "train loss:0.025024787432937696\n",
      "train loss:0.02925651277782091\n",
      "train loss:0.009289398511460451\n",
      "train loss:0.00935224672897859\n",
      "train loss:0.052900350814102486\n",
      "train loss:0.005974096594315389\n",
      "train loss:0.03350338205000498\n",
      "train loss:0.011855235777553617\n",
      "train loss:0.002353127959988425\n",
      "train loss:0.009597445968120637\n",
      "train loss:0.015281352144300204\n",
      "train loss:0.007148372781990581\n",
      "train loss:0.0024924534927015644\n",
      "train loss:0.0071367327599418315\n",
      "train loss:0.00852146193321324\n",
      "train loss:0.013939518733155075\n",
      "train loss:0.030643946619720336\n",
      "train loss:0.0027559796053548673\n",
      "train loss:0.007156744531111664\n",
      "train loss:0.020119553444828537\n",
      "train loss:0.023379031908698927\n",
      "train loss:0.003650819437110828\n",
      "train loss:0.010495080413413847\n",
      "train loss:0.00827207389853351\n",
      "train loss:0.010428637125650867\n",
      "train loss:0.003614972389552013\n",
      "train loss:0.04309608298946646\n",
      "train loss:0.011222297859723363\n",
      "train loss:0.022295573772137728\n",
      "train loss:0.013272569819192495\n",
      "train loss:0.0037700399202976105\n",
      "train loss:0.003843704124182434\n",
      "train loss:0.00725354601607894\n",
      "train loss:0.006795921180298281\n",
      "train loss:0.003968278964552115\n",
      "train loss:0.011312381188838743\n",
      "train loss:0.0029591101230350358\n",
      "train loss:0.008162567037862866\n",
      "train loss:0.008425758733352893\n",
      "train loss:0.013070276126377157\n",
      "train loss:0.003898025797795641\n",
      "train loss:0.003196542367602251\n",
      "train loss:0.048651051170621115\n",
      "train loss:0.02174753131129251\n",
      "train loss:0.012138660580599384\n",
      "train loss:0.009777039012131736\n",
      "train loss:0.023340756112930485\n",
      "train loss:0.018295772638533565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00939846824997539\n",
      "train loss:0.03212990715440193\n",
      "train loss:0.031646448358310326\n",
      "train loss:0.022006563356487027\n",
      "train loss:0.025437510650679052\n",
      "train loss:0.009116250377519935\n",
      "train loss:0.0063691947667549875\n",
      "train loss:0.019569079222756417\n",
      "train loss:0.005088861451476698\n",
      "train loss:0.000500410327958071\n",
      "train loss:0.0030348994146127406\n",
      "train loss:0.04654255009881595\n",
      "train loss:0.005618111394366553\n",
      "train loss:0.005022072537618153\n",
      "train loss:0.016260224517447568\n",
      "train loss:0.010107142271317543\n",
      "train loss:0.0128579678531624\n",
      "train loss:0.002048202267766338\n",
      "train loss:0.01095626148628761\n",
      "train loss:0.007847409166146686\n",
      "train loss:0.006987999917873589\n",
      "train loss:0.004105677799500734\n",
      "train loss:0.03399215371157566\n",
      "train loss:0.03351440103947516\n",
      "train loss:0.0014181136249882531\n",
      "train loss:0.02225601939612474\n",
      "train loss:0.001559649587869882\n",
      "train loss:0.01700090019507883\n",
      "train loss:0.01766246375360051\n",
      "train loss:0.0031768595126835026\n",
      "train loss:0.0020965490973400046\n",
      "train loss:0.003446327974738295\n",
      "train loss:0.025914721173380943\n",
      "train loss:0.0021102326064663594\n",
      "train loss:0.004967389715149237\n",
      "train loss:0.006479308329145019\n",
      "train loss:0.0072752360525423065\n",
      "train loss:0.004761443897455049\n",
      "train loss:0.02564706676492605\n",
      "train loss:0.020100429746158013\n",
      "train loss:0.00470864462364671\n",
      "train loss:0.00296841701327062\n",
      "train loss:0.007871728897050673\n",
      "train loss:0.0030034519471015685\n",
      "train loss:0.006653001952789122\n",
      "train loss:0.008731329981176364\n",
      "train loss:0.049588640301535175\n",
      "train loss:0.01224601105398351\n",
      "train loss:0.012459675916191501\n",
      "train loss:0.00678221923926715\n",
      "train loss:0.0012219463669515898\n",
      "train loss:0.006776643140191282\n",
      "train loss:0.018780562383098266\n",
      "train loss:0.006639540722847226\n",
      "train loss:0.020135304839338432\n",
      "train loss:0.0036484789781677206\n",
      "train loss:0.019543258649673826\n",
      "train loss:0.0058660340374587314\n",
      "train loss:0.0039346169831554955\n",
      "train loss:0.037699791545548714\n",
      "train loss:0.0018722810718559242\n",
      "train loss:0.004287421517327811\n",
      "train loss:0.005384309861897812\n",
      "train loss:0.01322057636112307\n",
      "train loss:0.0054018719938629615\n",
      "train loss:0.037118140428851955\n",
      "train loss:0.011729930434804555\n",
      "train loss:0.0169171881709611\n",
      "train loss:0.008998116027334115\n",
      "train loss:0.003939543764250883\n",
      "train loss:0.0017712883182379308\n",
      "train loss:0.020124583389685934\n",
      "train loss:0.003830772706756701\n",
      "train loss:0.005895020451280807\n",
      "train loss:0.018736864167894034\n",
      "train loss:0.0016886908986671317\n",
      "train loss:0.002397745818900903\n",
      "train loss:0.02793099379449584\n",
      "train loss:0.007333576627866109\n",
      "train loss:0.0061763214332217885\n",
      "train loss:0.012675262041845093\n",
      "train loss:0.002923955236080133\n",
      "train loss:0.005851099919098097\n",
      "train loss:0.0005434831708512014\n",
      "train loss:0.0030815423661817694\n",
      "train loss:0.0008711598767426111\n",
      "train loss:0.02231673771635753\n",
      "train loss:0.0048066785613980695\n",
      "train loss:0.020226220115424652\n",
      "train loss:0.009431120933902682\n",
      "train loss:0.012418924093741535\n",
      "train loss:0.029419626043124328\n",
      "train loss:0.012408217686489389\n",
      "train loss:0.0019365952316393144\n",
      "train loss:0.004521321917308262\n",
      "train loss:0.0013346901745846162\n",
      "train loss:0.0008995034477351391\n",
      "train loss:0.004670220707241205\n",
      "train loss:0.00629244447792432\n",
      "train loss:0.0117081576803137\n",
      "train loss:0.028656859470246286\n",
      "train loss:0.0027993851737992126\n",
      "train loss:0.006980866376894892\n",
      "train loss:0.012190236343779215\n",
      "train loss:0.009821349384891357\n",
      "train loss:0.0017521572371248567\n",
      "train loss:0.003404186840957741\n",
      "train loss:0.001380497670063868\n",
      "train loss:0.006161397454516021\n",
      "train loss:0.009741942375179079\n",
      "train loss:0.009585555201206082\n",
      "train loss:0.009041659691491203\n",
      "train loss:0.014403969322784245\n",
      "train loss:0.015466274993787985\n",
      "train loss:0.004622789728911436\n",
      "train loss:0.009614916766765987\n",
      "train loss:0.0031053954087688295\n",
      "train loss:0.003521090014766335\n",
      "train loss:0.006624244311106431\n",
      "train loss:0.0009385106815098896\n",
      "train loss:0.005537227610259288\n",
      "train loss:0.02035411007853644\n",
      "train loss:0.002479700826916338\n",
      "train loss:0.019731126135407645\n",
      "train loss:0.0020051911869826892\n",
      "train loss:0.0316489269892427\n",
      "train loss:0.0025487279076179185\n",
      "train loss:0.014773278187028886\n",
      "train loss:0.010331270323183659\n",
      "train loss:0.010145247707169373\n",
      "train loss:0.0012736327985454715\n",
      "train loss:0.0031199063996816957\n",
      "train loss:0.0018257240392384958\n",
      "train loss:0.0034254145867331632\n",
      "train loss:0.0005593641713951907\n",
      "train loss:0.00048342848844290694\n",
      "train loss:0.0009487277222999871\n",
      "train loss:0.01761825877867232\n",
      "train loss:0.00378323946151194\n",
      "train loss:0.0006206651939825339\n",
      "train loss:0.000563060657528676\n",
      "train loss:0.00672021072433008\n",
      "train loss:0.002837778256602869\n",
      "train loss:0.006243389860697994\n",
      "train loss:0.0026726441982770233\n",
      "train loss:0.003698658534060055\n",
      "train loss:0.028992910092180253\n",
      "train loss:0.005960957544657118\n",
      "train loss:0.00409320835315224\n",
      "train loss:0.019760682656688414\n",
      "train loss:0.0010927053403523507\n",
      "train loss:0.005503781464914267\n",
      "train loss:0.015684929700593077\n",
      "train loss:0.014041007991925782\n",
      "train loss:0.005421037156526919\n",
      "train loss:0.00844757077450519\n",
      "train loss:0.005885168790933196\n",
      "train loss:0.020948573493357946\n",
      "train loss:0.01116059843722778\n",
      "train loss:0.015635692858892783\n",
      "train loss:0.03757924663396712\n",
      "train loss:0.008518774265635186\n",
      "train loss:0.010221877599959024\n",
      "train loss:0.00410111667679996\n",
      "train loss:0.006291422372018366\n",
      "train loss:0.002568146927168544\n",
      "train loss:0.011170943398087689\n",
      "train loss:0.007888734658485873\n",
      "train loss:0.005211326693006638\n",
      "train loss:0.0038104448108920996\n",
      "train loss:0.009621909272250328\n",
      "train loss:0.009020854711459695\n",
      "train loss:0.0065549546694687886\n",
      "train loss:0.03218624151989923\n",
      "train loss:0.0015946633379376677\n",
      "train loss:0.014546680029768236\n",
      "train loss:0.019752390025498154\n",
      "train loss:0.0047937680678291445\n",
      "train loss:0.004539093033970418\n",
      "train loss:0.0007793966146648827\n",
      "train loss:0.003726924914859435\n",
      "train loss:0.003198360927260993\n",
      "train loss:0.006804595378788284\n",
      "train loss:0.002586379561976541\n",
      "train loss:0.023869746955719782\n",
      "train loss:0.002414256655166791\n",
      "train loss:0.057153511743102375\n",
      "train loss:0.010221491975938263\n",
      "train loss:0.013506834918644912\n",
      "train loss:0.0032358011929020346\n",
      "train loss:0.0007911912078194061\n",
      "train loss:0.0029612790394060932\n",
      "train loss:0.004761356392314765\n",
      "train loss:0.015200684570083299\n",
      "train loss:0.017975113746620433\n",
      "train loss:0.008059117097129573\n",
      "train loss:0.0022556836196720854\n",
      "train loss:0.0019052125982914085\n",
      "train loss:0.008793216265842329\n",
      "train loss:0.0009293491446062606\n",
      "train loss:0.010382037333630903\n",
      "train loss:0.009679111962249229\n",
      "train loss:0.017055780813178933\n",
      "train loss:0.006243273698459357\n",
      "train loss:0.0034715171641306252\n",
      "train loss:0.007731678391984844\n",
      "train loss:0.00318772181920608\n",
      "train loss:0.02837097325815515\n",
      "train loss:0.004664590557432049\n",
      "train loss:0.03290937773471455\n",
      "train loss:0.024239718071445742\n",
      "train loss:0.0021823362775545085\n",
      "train loss:0.0025151167732803906\n",
      "train loss:0.004842337184101913\n",
      "train loss:0.0014295445096753011\n",
      "train loss:0.004270227701100134\n",
      "train loss:0.0065802566477201705\n",
      "train loss:0.009908494929352397\n",
      "train loss:0.013733103166965903\n",
      "train loss:0.0022433784303389943\n",
      "train loss:0.020392483776862612\n",
      "train loss:0.03122491007246408\n",
      "train loss:0.006266870076079084\n",
      "train loss:0.006845290377695202\n",
      "train loss:0.0044100365484509435\n",
      "train loss:0.01258860661983168\n",
      "train loss:0.010441998099251884\n",
      "train loss:0.005432988866337354\n",
      "train loss:0.003398112419969247\n",
      "train loss:0.03788815111729326\n",
      "train loss:0.007517543042159129\n",
      "train loss:0.003041030243254686\n",
      "train loss:0.004134141916855329\n",
      "train loss:0.018192305717402456\n",
      "train loss:0.002107941845227365\n",
      "train loss:0.06325118877428029\n",
      "train loss:0.005292221865925897\n",
      "train loss:0.006814023912562064\n",
      "train loss:0.006334124471470155\n",
      "train loss:0.004500508121603722\n",
      "train loss:0.01003954094314249\n",
      "train loss:0.006552789528470218\n",
      "train loss:0.006152086967060848\n",
      "train loss:0.005271725950703583\n",
      "train loss:0.006019140873127108\n",
      "train loss:0.02794307499930947\n",
      "train loss:0.02912435247274206\n",
      "train loss:0.0003387289664968083\n",
      "train loss:0.0023773436207932407\n",
      "train loss:0.0005687970359410827\n",
      "train loss:0.0026662521721025558\n",
      "train loss:0.004932170825400936\n",
      "train loss:0.02792456079317353\n",
      "train loss:0.006635634979628342\n",
      "train loss:0.009869277364925162\n",
      "train loss:0.0011542843253227303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005621440003773387\n",
      "train loss:0.002184884943763949\n",
      "train loss:0.014304277891034327\n",
      "train loss:0.003933206947188422\n",
      "train loss:0.006545045884922608\n",
      "train loss:0.002643465431838918\n",
      "train loss:0.006872663406840828\n",
      "train loss:0.0033880272506771323\n",
      "train loss:0.005160219018034229\n",
      "train loss:0.002588594770159107\n",
      "train loss:0.003324241693513727\n",
      "train loss:0.0057339586003533624\n",
      "train loss:0.00715563757882912\n",
      "train loss:0.022489951285719414\n",
      "train loss:0.014449764695075687\n",
      "train loss:0.009689905094705338\n",
      "train loss:0.0034513859843621915\n",
      "train loss:0.012224375416933156\n",
      "train loss:0.003596016955862188\n",
      "train loss:0.0007939614798634133\n",
      "train loss:0.0076091881863306786\n",
      "train loss:0.0031639402086773615\n",
      "train loss:0.037320904637379484\n",
      "train loss:0.004083895997067604\n",
      "train loss:0.0010340062488061901\n",
      "train loss:0.013258379154796773\n",
      "train loss:0.0015216905139492198\n",
      "train loss:0.005358400423721611\n",
      "train loss:0.011796684229381666\n",
      "train loss:0.009663017191735363\n",
      "train loss:0.005957346334417307\n",
      "train loss:0.0020151515666463667\n",
      "train loss:0.0025549821612320684\n",
      "train loss:0.0065184332400191934\n",
      "train loss:0.0013217413100141415\n",
      "train loss:0.019615989357956273\n",
      "train loss:0.003672449376858006\n",
      "train loss:0.0033972380823457005\n",
      "train loss:0.01135637973528352\n",
      "train loss:0.004149150690096523\n",
      "train loss:0.016285961802254372\n",
      "train loss:0.013903418892872374\n",
      "train loss:0.002874436698768525\n",
      "train loss:0.03835854032702612\n",
      "train loss:0.008308141468038781\n",
      "train loss:0.0014687450492570555\n",
      "train loss:0.0010623277051840913\n",
      "train loss:0.004694283883329923\n",
      "train loss:0.003044608461861573\n",
      "train loss:0.022759124793861805\n",
      "train loss:0.006151506310545729\n",
      "train loss:0.02531814685796003\n",
      "train loss:0.007134835820795696\n",
      "train loss:0.0030896770301543403\n",
      "train loss:0.00879141264109032\n",
      "train loss:0.0027943420101534206\n",
      "train loss:0.00251756862161058\n",
      "train loss:0.004137364861630988\n",
      "train loss:0.005332573350548367\n",
      "train loss:0.0013614314116038887\n",
      "train loss:0.012818992410865713\n",
      "train loss:0.0008822240467640993\n",
      "train loss:0.0019037891961973018\n",
      "train loss:0.0006402969860510791\n",
      "train loss:0.005122060326661369\n",
      "train loss:0.01004275103638081\n",
      "train loss:0.007906967537628505\n",
      "train loss:0.007869065933243264\n",
      "train loss:0.023311357440787144\n",
      "train loss:0.016013827013781054\n",
      "train loss:0.01577556648299273\n",
      "train loss:0.005488369312073149\n",
      "train loss:0.0045484595478652\n",
      "train loss:0.004720126414541054\n",
      "train loss:0.014160989910100756\n",
      "train loss:0.0025475783768758257\n",
      "train loss:0.011820725057417967\n",
      "train loss:0.0013284752002683522\n",
      "train loss:0.019893461672122095\n",
      "train loss:0.011159173494771343\n",
      "train loss:0.0014995311392432549\n",
      "train loss:0.0035265522461869403\n",
      "train loss:0.004399778097363859\n",
      "train loss:0.0072699049166886605\n",
      "train loss:0.04046623919972483\n",
      "train loss:0.006075217229602661\n",
      "train loss:0.004898166292309207\n",
      "train loss:0.003772608135382\n",
      "train loss:0.012516612643607018\n",
      "train loss:0.010368935567534786\n",
      "train loss:0.0023707269030127567\n",
      "train loss:0.008993718657536665\n",
      "train loss:0.011444783744469198\n",
      "train loss:0.0023310253595106565\n",
      "train loss:0.007454604479770446\n",
      "train loss:0.02290404185919941\n",
      "train loss:0.007913800576006333\n",
      "train loss:0.009015807701359376\n",
      "train loss:0.004136101892497604\n",
      "train loss:0.0033626303045603406\n",
      "train loss:0.047132213525958006\n",
      "train loss:0.0011479400037503933\n",
      "train loss:0.016818172315314045\n",
      "train loss:0.0022635876549128233\n",
      "train loss:0.006822236514456673\n",
      "train loss:0.001711190501647811\n",
      "train loss:0.019214427310371884\n",
      "train loss:0.012818646647461504\n",
      "train loss:0.004077608768785844\n",
      "train loss:0.003012676976079427\n",
      "train loss:0.005335960262359915\n",
      "train loss:0.0021343667822587096\n",
      "train loss:0.0058199080248843935\n",
      "train loss:0.006065723200192135\n",
      "train loss:0.0016511867617870918\n",
      "train loss:0.0035644763104658857\n",
      "train loss:0.004873785625084917\n",
      "train loss:0.0008931021910056554\n",
      "train loss:0.0020189930716765577\n",
      "train loss:0.0020492012224486863\n",
      "train loss:0.022146449200784738\n",
      "train loss:0.05997268088085116\n",
      "train loss:0.004036839422375462\n",
      "train loss:0.0015134452880499925\n",
      "train loss:0.0005315870267461022\n",
      "train loss:0.006833380014578937\n",
      "train loss:0.0010473103154564124\n",
      "train loss:0.00939723682913874\n",
      "train loss:0.0013787840291102304\n",
      "train loss:0.006546531265637212\n",
      "train loss:0.00033047030203249637\n",
      "train loss:0.0018490071566833238\n",
      "train loss:0.0033370215482789074\n",
      "train loss:0.0012591193380295912\n",
      "train loss:0.003335126936408734\n",
      "train loss:0.0062773123862769845\n",
      "train loss:0.001999594144686008\n",
      "train loss:0.002461492089337008\n",
      "train loss:0.007993140345331863\n",
      "train loss:0.0017299411889547824\n",
      "train loss:0.0006272650567180117\n",
      "train loss:0.009156901243721663\n",
      "train loss:0.033551885796096734\n",
      "train loss:0.0008846369747277417\n",
      "train loss:0.003872591116405985\n",
      "train loss:0.011045966855490093\n",
      "train loss:0.07514087696627633\n",
      "train loss:0.0008043508366418484\n",
      "train loss:0.0023463301413284786\n",
      "train loss:0.007581438397131896\n",
      "train loss:0.0013433173858728548\n",
      "train loss:0.009946506460080065\n",
      "train loss:0.0026524377916853194\n",
      "train loss:0.004730704642663919\n",
      "train loss:0.010842933993548371\n",
      "train loss:0.011587878108503409\n",
      "train loss:0.0006683112369856698\n",
      "train loss:0.005441052989788405\n",
      "train loss:0.002319559714774723\n",
      "train loss:0.00513180530514607\n",
      "train loss:0.0020017268547045898\n",
      "train loss:0.01511021554302295\n",
      "train loss:0.0037311468480444266\n",
      "train loss:0.0013930495750772058\n",
      "train loss:0.013095148884559673\n",
      "train loss:0.004668385202614067\n",
      "train loss:0.008459739962056678\n",
      "train loss:0.0028826363295484264\n",
      "train loss:0.0023174620533191323\n",
      "train loss:0.005208912973372235\n",
      "train loss:0.0007371585493943587\n",
      "train loss:0.0024988371824792056\n",
      "train loss:0.003589824226808811\n",
      "train loss:0.0006463932315072267\n",
      "train loss:0.001212377835216627\n",
      "train loss:0.00031410913707930204\n",
      "train loss:0.0014581812135071586\n",
      "train loss:0.004079861989325913\n",
      "train loss:0.0036043360553388746\n",
      "train loss:0.002094232556756612\n",
      "train loss:0.004677470151981633\n",
      "train loss:0.003226639489511025\n",
      "train loss:0.006601501531443076\n",
      "train loss:0.02439639644691451\n",
      "train loss:0.008833656963082746\n",
      "train loss:0.003733269404231454\n",
      "train loss:0.005257897444486706\n",
      "train loss:0.008732014955526207\n",
      "train loss:0.0071186306930742585\n",
      "train loss:0.06460474196347928\n",
      "train loss:0.004753920294466496\n",
      "train loss:0.0026321764364941836\n",
      "train loss:0.010329160679235772\n",
      "train loss:0.006729590329502841\n",
      "train loss:0.043885496266125264\n",
      "train loss:0.018998424743812695\n",
      "train loss:0.004015222715911728\n",
      "train loss:0.004695079717812817\n",
      "train loss:0.0032705114125114883\n",
      "train loss:0.008661410388790034\n",
      "train loss:0.004744107301783628\n",
      "train loss:0.014605221489207206\n",
      "train loss:0.0041866996365350516\n",
      "train loss:0.03308463374332672\n",
      "train loss:0.005460543117482223\n",
      "train loss:0.0012941181643576292\n",
      "train loss:0.0025958199388735497\n",
      "train loss:0.002349423623689151\n",
      "train loss:0.016114166938297887\n",
      "train loss:0.00034295671561077685\n",
      "train loss:0.0019632109735564255\n",
      "train loss:0.010963215082819965\n",
      "train loss:0.021756615095648094\n",
      "train loss:0.004115178723497131\n",
      "train loss:0.010099734422433062\n",
      "train loss:0.03943663598169689\n",
      "train loss:0.0028711142394776366\n",
      "train loss:0.009020489158007945\n",
      "train loss:0.0031881981221668926\n",
      "train loss:0.008756871065851192\n",
      "train loss:0.0022416599204116896\n",
      "train loss:0.021496965559324233\n",
      "train loss:0.0011264399086547878\n",
      "train loss:0.02224398356193405\n",
      "train loss:0.00844208264211405\n",
      "train loss:0.0045278053674962385\n",
      "train loss:0.005164337622027261\n",
      "train loss:0.011694700438726302\n",
      "train loss:0.0019078472813536035\n",
      "train loss:0.04098583437674295\n",
      "train loss:0.001212519757240776\n",
      "train loss:0.022006578246905942\n",
      "train loss:0.008442022667513767\n",
      "train loss:0.011977350872961711\n",
      "train loss:0.025990625025817515\n",
      "train loss:0.0046832147693207675\n",
      "train loss:0.004437093787067021\n",
      "train loss:0.002650313380142472\n",
      "train loss:0.011213864727850464\n",
      "train loss:0.004245238075094335\n",
      "train loss:0.0037757291630315217\n",
      "train loss:0.006259664788336696\n",
      "train loss:0.005142978030904053\n",
      "train loss:0.0007463513911392392\n",
      "train loss:0.0029201022425835777\n",
      "train loss:0.007838030907409574\n",
      "train loss:0.006058371513188726\n",
      "train loss:0.003662125262972412\n",
      "train loss:0.00856975244270897\n",
      "train loss:0.04024403998223567\n",
      "train loss:0.004579929242182815\n",
      "train loss:0.0026509252835799687\n",
      "train loss:0.008523419050925206\n",
      "train loss:0.006108692869170255\n",
      "train loss:0.003443603897072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001572675391451394\n",
      "train loss:0.009608596983462628\n",
      "train loss:0.005684430523294468\n",
      "train loss:0.007586633173764779\n",
      "train loss:0.0058796849514518145\n",
      "train loss:0.0025994535184969657\n",
      "train loss:0.0007687681590815606\n",
      "train loss:0.012138352179472466\n",
      "train loss:0.0023335829623309817\n",
      "train loss:0.014771240909489954\n",
      "train loss:0.0018678564359857525\n",
      "train loss:0.002174977469921134\n",
      "train loss:0.024025297472239405\n",
      "train loss:0.003147025003933744\n",
      "train loss:0.01593793163569359\n",
      "train loss:0.0015249776130223586\n",
      "train loss:0.013496435218844501\n",
      "train loss:0.007686535200474195\n",
      "train loss:0.0017421789775288244\n",
      "train loss:0.002966007264701473\n",
      "train loss:0.0034764706839781378\n",
      "train loss:0.006422186468281426\n",
      "train loss:0.007181973510720645\n",
      "=== epoch:11, train acc:0.995, test acc:0.989 ===\n",
      "train loss:0.005590760716214006\n",
      "train loss:0.018606831859930496\n",
      "train loss:0.020399144706346486\n",
      "train loss:0.0026803949168658376\n",
      "train loss:0.007456725847821501\n",
      "train loss:0.0033782073175886956\n",
      "train loss:0.007699430101831737\n",
      "train loss:0.004329234057420544\n",
      "train loss:0.003855233020700681\n",
      "train loss:0.004043336784090763\n",
      "train loss:0.007586640291437245\n",
      "train loss:0.00032544731564638065\n",
      "train loss:0.005369295593347569\n",
      "train loss:0.0025313394063547047\n",
      "train loss:0.013878104572902004\n",
      "train loss:0.004997803902642887\n",
      "train loss:0.0032215353392359585\n",
      "train loss:0.0037416114971161813\n",
      "train loss:0.00754864583736775\n",
      "train loss:0.00939306381143621\n",
      "train loss:0.00217303099852298\n",
      "train loss:0.013454441569643094\n",
      "train loss:0.004456648011918731\n",
      "train loss:0.0014849419109263338\n",
      "train loss:0.0012078849330012672\n",
      "train loss:0.0007214841361553551\n",
      "train loss:0.004571013979989181\n",
      "train loss:0.004526013471232813\n",
      "train loss:0.039249808258947076\n",
      "train loss:0.0010560606461874125\n",
      "train loss:0.0030300190748209317\n",
      "train loss:0.012487466286277546\n",
      "train loss:0.007452415482312274\n",
      "train loss:0.01564688472577078\n",
      "train loss:0.012677510415188421\n",
      "train loss:0.007364509728300558\n",
      "train loss:0.002259383556600637\n",
      "train loss:0.001573067419305505\n",
      "train loss:0.020500651089126486\n",
      "train loss:0.0015246166410358703\n",
      "train loss:0.0012144825604284435\n",
      "train loss:0.012887134616397773\n",
      "train loss:0.002349169278679491\n",
      "train loss:0.004121177967880893\n",
      "train loss:0.02677710265973386\n",
      "train loss:0.0021333381479092845\n",
      "train loss:0.0029286027721017517\n",
      "train loss:0.0060989378321241435\n",
      "train loss:0.003141316951736488\n",
      "train loss:0.004477090685641237\n",
      "train loss:0.003404126832170036\n",
      "train loss:0.003034181524622846\n",
      "train loss:0.011407699374381882\n",
      "train loss:0.005518454264231628\n",
      "train loss:0.049116349029502064\n",
      "train loss:0.005813316863617408\n",
      "train loss:0.03740191520564841\n",
      "train loss:0.010850804254261392\n",
      "train loss:0.010134518575726899\n",
      "train loss:0.0013196686350862804\n",
      "train loss:0.008694664214498372\n",
      "train loss:0.010509829224492638\n",
      "train loss:0.004679723300061153\n",
      "train loss:0.019311958396826565\n",
      "train loss:0.015860536856655574\n",
      "train loss:0.013146613886882905\n",
      "train loss:0.010166210163476639\n",
      "train loss:0.06035877970867975\n",
      "train loss:0.001366642107533539\n",
      "train loss:0.002486630840211036\n",
      "train loss:0.004798030921639492\n",
      "train loss:0.00541953697478409\n",
      "train loss:0.01346364716261702\n",
      "train loss:0.018030878424752803\n",
      "train loss:0.003563325097689479\n",
      "train loss:0.0016405168127500327\n",
      "train loss:0.002185518570928584\n",
      "train loss:0.009253635391772003\n",
      "train loss:0.00034641694561096404\n",
      "train loss:0.006269631469163013\n",
      "train loss:0.008221191191950207\n",
      "train loss:0.0018710148892621165\n",
      "train loss:0.0010123377467315306\n",
      "train loss:0.0018268814236319453\n",
      "train loss:0.011472630082342583\n",
      "train loss:0.005076292393454996\n",
      "train loss:0.00553955755887646\n",
      "train loss:0.023715553077455667\n",
      "train loss:0.005707218677000003\n",
      "train loss:0.003777298025645321\n",
      "train loss:0.0008197512708800239\n",
      "train loss:0.00597155003146964\n",
      "train loss:0.008477194247352847\n",
      "train loss:0.0025162008016276923\n",
      "train loss:0.0069856312799168345\n",
      "train loss:0.007463883392151463\n",
      "train loss:0.020482910919533096\n",
      "train loss:0.0012944793628087983\n",
      "train loss:0.003138750340548297\n",
      "train loss:0.03388811012936391\n",
      "train loss:0.008473706634800675\n",
      "train loss:0.005313171397201282\n",
      "train loss:0.0013271138241389199\n",
      "train loss:0.0037850291915309743\n",
      "train loss:0.025250353414532804\n",
      "train loss:0.0010274206274082705\n",
      "train loss:0.004851083461539394\n",
      "train loss:0.000662776774233236\n",
      "train loss:0.0036112815130836325\n",
      "train loss:0.004555008172370392\n",
      "train loss:0.004488237772228431\n",
      "train loss:0.00737578446225354\n",
      "train loss:0.0005904024667034891\n",
      "train loss:0.005229858171326495\n",
      "train loss:0.004142123978748196\n",
      "train loss:0.011811219628718067\n",
      "train loss:0.08674526722938614\n",
      "train loss:0.012602031938484004\n",
      "train loss:0.00535726983229071\n",
      "train loss:0.0008928746403773402\n",
      "train loss:0.0004524541150812431\n",
      "train loss:0.003869557242581102\n",
      "train loss:0.0010560902635988298\n",
      "train loss:0.012895685674764769\n",
      "train loss:0.004766748247448483\n",
      "train loss:0.0025591527947232406\n",
      "train loss:0.0035185126674357314\n",
      "train loss:0.008397042843344436\n",
      "train loss:0.009549246724321387\n",
      "train loss:0.006304838698017491\n",
      "train loss:0.0023341477673292114\n",
      "train loss:0.00665067527697625\n",
      "train loss:0.010803435159947007\n",
      "train loss:0.0014526224983759264\n",
      "train loss:0.004939733892478288\n",
      "train loss:0.004243135890280459\n",
      "train loss:0.008935466573834028\n",
      "train loss:0.0053212203386848456\n",
      "train loss:0.056213821667104896\n",
      "train loss:0.006138254431204487\n",
      "train loss:0.002107848862995915\n",
      "train loss:0.005886706108547188\n",
      "train loss:0.006659181866190492\n",
      "train loss:0.001894231518613228\n",
      "train loss:0.002327562230348313\n",
      "train loss:0.012952104139297956\n",
      "train loss:0.0012301874742592148\n",
      "train loss:0.004116649779400285\n",
      "train loss:0.022086702871911786\n",
      "train loss:0.013719040431442245\n",
      "train loss:0.003805900340596466\n",
      "train loss:0.0023080991083415797\n",
      "train loss:0.0029355784188687057\n",
      "train loss:0.0024307624558506185\n",
      "train loss:0.009154509588623634\n",
      "train loss:0.002135640939330597\n",
      "train loss:0.012440757527859916\n",
      "train loss:0.019194050614821285\n",
      "train loss:0.0065705706195937465\n",
      "train loss:0.0030074934596893187\n",
      "train loss:0.0006917742670919718\n",
      "train loss:0.004303593115063714\n",
      "train loss:0.001681900733495896\n",
      "train loss:0.002161358703817703\n",
      "train loss:0.000862560275079583\n",
      "train loss:0.0020559649593829016\n",
      "train loss:0.003923884889591934\n",
      "train loss:0.00043552763982862433\n",
      "train loss:0.0009416261115537341\n",
      "train loss:0.0010014386746869557\n",
      "train loss:0.004114991639364819\n",
      "train loss:0.0047797015172627985\n",
      "train loss:0.011702616161318973\n",
      "train loss:0.0017746209500069563\n",
      "train loss:0.001119211167059976\n",
      "train loss:0.004614241319576755\n",
      "train loss:0.003886008656476388\n",
      "train loss:0.0036637770105870902\n",
      "train loss:0.001561798170155905\n",
      "train loss:0.003977365927770151\n",
      "train loss:0.007376533968417197\n",
      "train loss:0.004343343143379858\n",
      "train loss:0.010898438156719774\n",
      "train loss:0.005284931482060193\n",
      "train loss:0.0020132235240464254\n",
      "train loss:0.001963040234248098\n",
      "train loss:0.0231417749261416\n",
      "train loss:0.008325515380655369\n",
      "train loss:0.0022592746138497114\n",
      "train loss:0.009547325053395336\n",
      "train loss:0.025950863562126295\n",
      "train loss:0.011676445850823608\n",
      "train loss:0.021622819414882137\n",
      "train loss:0.0008510619553894101\n",
      "train loss:0.005874347521722575\n",
      "train loss:0.009857621922122157\n",
      "train loss:0.0016650857492099302\n",
      "train loss:0.04195217593589236\n",
      "train loss:0.0017185836754141294\n",
      "train loss:0.07041632589829089\n",
      "train loss:0.0026791423081660775\n",
      "train loss:0.01020262720042312\n",
      "train loss:0.00776402954042052\n",
      "train loss:0.004988706982258589\n",
      "train loss:0.002019025815581153\n",
      "train loss:0.0012197921287551087\n",
      "train loss:0.00828644782162683\n",
      "train loss:0.014848077382312686\n",
      "train loss:0.005461199838309312\n",
      "train loss:0.0011460601640640258\n",
      "train loss:0.0011482937837958616\n",
      "train loss:0.004079720183640002\n",
      "train loss:0.006877737970308408\n",
      "train loss:0.0022962455349742512\n",
      "train loss:0.004258056258418141\n",
      "train loss:0.004037524459781233\n",
      "train loss:0.018426616028978632\n",
      "train loss:0.0008264201941276282\n",
      "train loss:0.04114468353303139\n",
      "train loss:0.022759330276633228\n",
      "train loss:0.0041582574816095355\n",
      "train loss:0.011058673004671093\n",
      "train loss:0.0026947327279601137\n",
      "train loss:0.00116177845854709\n",
      "train loss:0.0039549437132631975\n",
      "train loss:0.004849321361641569\n",
      "train loss:0.001223071655001601\n",
      "train loss:0.012627612061082719\n",
      "train loss:0.0005489466908327334\n",
      "train loss:0.0020007486257384434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002756993287214366\n",
      "train loss:0.0028388254927056928\n",
      "train loss:0.00434233989335608\n",
      "train loss:0.0022336977113668528\n",
      "train loss:0.004033821536464772\n",
      "train loss:0.006243569275408801\n",
      "train loss:0.0020921302022882397\n",
      "train loss:0.001238041421031166\n",
      "train loss:0.005488450885970847\n",
      "train loss:0.013766637869127574\n",
      "train loss:0.00111588786621452\n",
      "train loss:0.0023416569316762727\n",
      "train loss:0.008280015948765354\n",
      "train loss:0.006817576592543594\n",
      "train loss:0.008764719824330552\n",
      "train loss:0.0006261504554561288\n",
      "train loss:0.0024514832205297914\n",
      "train loss:0.010749303918006934\n",
      "train loss:0.002462920507583153\n",
      "train loss:0.0021045596097176845\n",
      "train loss:0.003978194028843916\n",
      "train loss:0.0013224697041703697\n",
      "train loss:0.02023388253398955\n",
      "train loss:0.0014989349773535583\n",
      "train loss:0.002135601998280202\n",
      "train loss:0.0018696055142748184\n",
      "train loss:0.005953587710378223\n",
      "train loss:0.0021408145525878383\n",
      "train loss:0.0014255480948837482\n",
      "train loss:0.0021033703976642486\n",
      "train loss:0.004017813871592412\n",
      "train loss:0.0051243137695704145\n",
      "train loss:0.004439880236064214\n",
      "train loss:0.0069013037338097605\n",
      "train loss:0.0025918606101014824\n",
      "train loss:0.0019388434377223202\n",
      "train loss:0.004738559441105861\n",
      "train loss:0.0007101773568780929\n",
      "train loss:0.005695063025011124\n",
      "train loss:0.0021348844493120677\n",
      "train loss:0.001016359688383239\n",
      "train loss:0.003697010371047244\n",
      "train loss:0.010130643925531271\n",
      "train loss:0.0004605036500099544\n",
      "train loss:0.0035448430955388006\n",
      "train loss:0.007960961001890395\n",
      "train loss:0.011994606000602042\n",
      "train loss:0.0003243274636849657\n",
      "train loss:0.0019492992220896972\n",
      "train loss:0.0005696271996912177\n",
      "train loss:0.009181906002169607\n",
      "train loss:0.0012953141895004293\n",
      "train loss:0.005518836240502436\n",
      "train loss:0.0019908321406044136\n",
      "train loss:0.0039347541736552945\n",
      "train loss:0.0061635370136243995\n",
      "train loss:0.0016720641882688068\n",
      "train loss:0.00366817340823276\n",
      "train loss:0.0005357212029010128\n",
      "train loss:0.005206843048604141\n",
      "train loss:0.008739861167253324\n",
      "train loss:0.0018932357541652366\n",
      "train loss:0.0016966369697675465\n",
      "train loss:0.0008460417099273767\n",
      "train loss:0.005091164042318598\n",
      "train loss:0.004325466806747691\n",
      "train loss:0.00024967351216885855\n",
      "train loss:0.002054644408762591\n",
      "train loss:0.004694231340393928\n",
      "train loss:0.0021587895695120815\n",
      "train loss:0.005157524995296997\n",
      "train loss:0.01971803992764469\n",
      "train loss:0.0019331427454377071\n",
      "train loss:0.002631332755147488\n",
      "train loss:0.04189154529536137\n",
      "train loss:0.001150570766209131\n",
      "train loss:0.008090935384819848\n",
      "train loss:0.0018866871859048195\n",
      "train loss:0.014990625814715703\n",
      "train loss:0.0031898983720930526\n",
      "train loss:0.031093864810174825\n",
      "train loss:0.00153844656892783\n",
      "train loss:0.004761759419208413\n",
      "train loss:0.003425352148679454\n",
      "train loss:0.008340374044171109\n",
      "train loss:0.008144777411435792\n",
      "train loss:0.00377750064539928\n",
      "train loss:0.018600768407813235\n",
      "train loss:0.0011845477861600188\n",
      "train loss:0.0007253885856044989\n",
      "train loss:0.029819087767022353\n",
      "train loss:0.0032392565450651244\n",
      "train loss:0.0019124588285032071\n",
      "train loss:0.0033357507370382765\n",
      "train loss:0.0021771423508156126\n",
      "train loss:0.0012933409462273075\n",
      "train loss:0.01735972300285324\n",
      "train loss:0.007050973498392\n",
      "train loss:0.002584685806122539\n",
      "train loss:0.005463789134179586\n",
      "train loss:0.0025771246417516736\n",
      "train loss:0.01751969869485028\n",
      "train loss:0.0087164142157834\n",
      "train loss:0.003771815507870266\n",
      "train loss:0.0010610260159424785\n",
      "train loss:0.003790349437428828\n",
      "train loss:0.0021455546273504962\n",
      "train loss:0.0006107615832737218\n",
      "train loss:0.0023191145475619747\n",
      "train loss:0.0002064362643184219\n",
      "train loss:0.0017753195265229728\n",
      "train loss:0.0015775844706652257\n",
      "train loss:0.0010242373395802117\n",
      "train loss:0.002363828442184625\n",
      "train loss:0.0005288605030637676\n",
      "train loss:0.009622531438860256\n",
      "train loss:0.008696572547185288\n",
      "train loss:0.0060006236271992084\n",
      "train loss:0.005923332371075423\n",
      "train loss:0.007165669533080342\n",
      "train loss:0.06817461347729555\n",
      "train loss:0.008593988333278268\n",
      "train loss:0.0032583336369370764\n",
      "train loss:0.0017608437373532293\n",
      "train loss:0.004712258995577787\n",
      "train loss:0.0011099161026818587\n",
      "train loss:0.08497821477687592\n",
      "train loss:0.0018076591343157416\n",
      "train loss:0.006533626918324027\n",
      "train loss:0.014172409721301573\n",
      "train loss:0.0024709740264986665\n",
      "train loss:0.0027471446725367073\n",
      "train loss:0.024761085749122707\n",
      "train loss:0.0008684497773203608\n",
      "train loss:0.003003265019721795\n",
      "train loss:0.0010836654289412475\n",
      "train loss:0.0022153956198182525\n",
      "train loss:0.0040719971810989275\n",
      "train loss:0.0033853413696180155\n",
      "train loss:0.004879660228069226\n",
      "train loss:0.003871601653733576\n",
      "train loss:0.004588602942339169\n",
      "train loss:0.009846215622993782\n",
      "train loss:0.002248578216779362\n",
      "train loss:0.03091481736534593\n",
      "train loss:0.023294730715389976\n",
      "train loss:0.0019214743921004845\n",
      "train loss:0.0019100096122063239\n",
      "train loss:0.017310404568677287\n",
      "train loss:0.004780331978791049\n",
      "train loss:0.002399591139308662\n",
      "train loss:0.005541473432934022\n",
      "train loss:0.010285372399451305\n",
      "train loss:0.004133784740418161\n",
      "train loss:0.0350605677735828\n",
      "train loss:0.01134747985971048\n",
      "train loss:0.0009983676672020306\n",
      "train loss:0.02198313583373263\n",
      "train loss:0.006427994420406492\n",
      "train loss:0.005701641765390939\n",
      "train loss:0.0034374448699834837\n",
      "train loss:0.007528067393527718\n",
      "train loss:0.03755213174101912\n",
      "train loss:0.002771814007860265\n",
      "train loss:0.0007601631552982391\n",
      "train loss:0.006072991882096068\n",
      "train loss:0.002259205154119327\n",
      "train loss:0.012556549907035848\n",
      "train loss:0.009458030699086472\n",
      "train loss:0.008584221503812453\n",
      "train loss:0.005859951768796392\n",
      "train loss:0.0007424990861438849\n",
      "train loss:0.004505315511266099\n",
      "train loss:0.002262482624939006\n",
      "train loss:0.002289805684841079\n",
      "train loss:0.0030681225071181894\n",
      "train loss:0.002233443307234135\n",
      "train loss:0.005520710015997755\n",
      "train loss:0.005019718076582263\n",
      "train loss:0.01114811553965927\n",
      "train loss:0.001826648207820419\n",
      "train loss:0.038396097465006586\n",
      "train loss:0.006082701819748284\n",
      "train loss:0.006181548750300076\n",
      "train loss:0.00010255731427705555\n",
      "train loss:0.0029708953512171095\n",
      "train loss:0.0024471675841951116\n",
      "train loss:0.0003520230173468138\n",
      "train loss:0.0004429084147035298\n",
      "train loss:0.0013790693334123849\n",
      "train loss:0.010097196085541146\n",
      "train loss:0.0025479547681861513\n",
      "train loss:0.009703060334908885\n",
      "train loss:0.0062781577610383135\n",
      "train loss:0.0023579482654888027\n",
      "train loss:0.0005887713236896438\n",
      "train loss:0.016075230829356742\n",
      "train loss:0.0022390215702123247\n",
      "train loss:0.01282874029020366\n",
      "train loss:0.0032253671447748855\n",
      "train loss:0.002060330627832912\n",
      "train loss:0.005968803098578841\n",
      "train loss:0.0032513399569690134\n",
      "train loss:0.0036898431518196067\n",
      "train loss:0.005708028653987016\n",
      "train loss:0.001054353518208998\n",
      "train loss:0.003486134379365768\n",
      "train loss:0.0007086963374906511\n",
      "train loss:0.003120070954589344\n",
      "train loss:0.0005833310496821358\n",
      "train loss:0.012119695933728065\n",
      "train loss:0.019870657626432336\n",
      "train loss:0.0025873350902854294\n",
      "train loss:0.010298898599378386\n",
      "train loss:0.004861235643532918\n",
      "train loss:0.0023955838407571225\n",
      "train loss:0.0005558567170500533\n",
      "train loss:0.0028346957417709697\n",
      "train loss:0.0012352901512891438\n",
      "train loss:0.002076769115800251\n",
      "train loss:0.005210056802022591\n",
      "train loss:0.0054544791581701306\n",
      "train loss:0.005951247037558663\n",
      "train loss:0.0023055859116629675\n",
      "train loss:0.0038168094412291886\n",
      "train loss:0.002296858185772187\n",
      "train loss:0.0007772705653323876\n",
      "train loss:0.005994301119946429\n",
      "train loss:0.00519549563326511\n",
      "train loss:0.016084275448232915\n",
      "train loss:0.003740830932951615\n",
      "train loss:0.004566024431681935\n",
      "train loss:0.0025747961139025604\n",
      "train loss:0.003314023741547434\n",
      "train loss:0.002044854336346122\n",
      "train loss:0.0004187907842077447\n",
      "train loss:0.0006128245904007086\n",
      "train loss:0.004751905285659821\n",
      "train loss:0.007277535826521551\n",
      "train loss:0.007517329378386041\n",
      "train loss:0.0022145680886950596\n",
      "train loss:0.0015337500810898802\n",
      "train loss:0.0015005058775934969\n",
      "train loss:0.0035008804682749774\n",
      "train loss:0.0006364451542384066\n",
      "train loss:0.004715653748913175\n",
      "train loss:0.012524057802676836\n",
      "train loss:0.0031363594550785257\n",
      "train loss:0.0008701784445537437\n",
      "train loss:0.005121488169787809\n",
      "train loss:0.007743049311578704\n",
      "train loss:0.010034713860456033\n",
      "train loss:0.008268280477797091\n",
      "train loss:0.0035017589924872007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009045239216569123\n",
      "train loss:0.0032595718068727836\n",
      "train loss:0.003948521760965579\n",
      "train loss:0.005282441914951933\n",
      "train loss:0.0034806330162275314\n",
      "train loss:0.022972322195909466\n",
      "train loss:0.01040504998247429\n",
      "train loss:0.028915274989219517\n",
      "train loss:0.0007014508435026115\n",
      "train loss:0.005418814670480824\n",
      "train loss:0.008607103139434628\n",
      "train loss:0.005008199305553035\n",
      "train loss:0.004663989800829684\n",
      "train loss:0.00122133846511989\n",
      "train loss:0.0016069459856173493\n",
      "train loss:0.009134878423236379\n",
      "train loss:0.003406390770802566\n",
      "train loss:0.007849258078996297\n",
      "train loss:0.001050718121270875\n",
      "train loss:0.007162016267771349\n",
      "train loss:0.002746844750901192\n",
      "train loss:0.045654763199359266\n",
      "train loss:0.004292634710307875\n",
      "train loss:0.0014436615188163577\n",
      "train loss:0.0034070239139118463\n",
      "train loss:0.010381585325736771\n",
      "train loss:0.005107469791492626\n",
      "train loss:0.004462769403879676\n",
      "train loss:0.007562474884709649\n",
      "train loss:0.046166865602042424\n",
      "train loss:0.004937563582299529\n",
      "train loss:0.01025365008250503\n",
      "train loss:0.009346716876248606\n",
      "train loss:0.005791777880793179\n",
      "train loss:0.0031103989109174364\n",
      "train loss:0.015073018712902675\n",
      "train loss:0.03254779280136347\n",
      "train loss:0.0027564043568408412\n",
      "train loss:0.005479067015336996\n",
      "train loss:0.007728219396836814\n",
      "train loss:0.00858921890554849\n",
      "train loss:0.017067779226007062\n",
      "train loss:0.00488570941459587\n",
      "train loss:0.0013427540257448733\n",
      "train loss:0.00798129947844505\n",
      "train loss:0.006238991721230407\n",
      "train loss:0.006710689133080126\n",
      "train loss:0.0077203877267627615\n",
      "train loss:0.0034991960658287617\n",
      "train loss:0.007687555982112403\n",
      "train loss:0.010058332950589666\n",
      "train loss:0.004701653095965457\n",
      "train loss:0.015752946644949483\n",
      "train loss:0.040517085341058495\n",
      "train loss:0.007150005959078723\n",
      "train loss:0.005043809526647525\n",
      "train loss:0.002270859044066748\n",
      "train loss:0.012160420472505852\n",
      "train loss:0.0038782036019587096\n",
      "train loss:0.003543208638837596\n",
      "train loss:0.004372706682937919\n",
      "train loss:0.002946061934364594\n",
      "train loss:0.0011763100110435776\n",
      "train loss:0.0042071049614133445\n",
      "train loss:0.0036204582303031784\n",
      "train loss:0.0028375885374442482\n",
      "train loss:0.004612904045606695\n",
      "train loss:0.0007812457032743262\n",
      "train loss:0.007176240128074401\n",
      "train loss:0.022826049789537662\n",
      "train loss:0.042222418897469485\n",
      "train loss:0.004351428809219486\n",
      "train loss:0.00703388771879015\n",
      "train loss:0.003006651181171488\n",
      "train loss:0.0026719834327754103\n",
      "train loss:0.001931119833331576\n",
      "train loss:0.0013871820187466688\n",
      "train loss:0.019732242578137105\n",
      "train loss:0.002766990107436469\n",
      "train loss:0.06706294002170865\n",
      "train loss:0.024945687880233734\n",
      "train loss:0.011752425316537031\n",
      "train loss:0.01996207793813875\n",
      "train loss:0.0007909278774122715\n",
      "train loss:0.0050796124797711315\n",
      "train loss:0.0006200324826643117\n",
      "train loss:0.0005698195748338172\n",
      "train loss:0.004229672112420316\n",
      "train loss:0.002092154251104074\n",
      "train loss:0.008747593909843011\n",
      "train loss:0.022738145882837336\n",
      "train loss:0.006554723776296855\n",
      "train loss:0.007503463786356174\n",
      "train loss:0.014898656428372705\n",
      "train loss:0.0013832210330712291\n",
      "train loss:0.0072074807838007635\n",
      "train loss:0.02122257770832516\n",
      "train loss:0.03541435313111976\n",
      "train loss:0.0014124822026593722\n",
      "train loss:0.002141791471685\n",
      "train loss:0.011424655068936442\n",
      "train loss:0.01255319764543752\n",
      "train loss:0.006945380173181349\n",
      "train loss:0.008786760551703889\n",
      "train loss:0.005957896911763162\n",
      "train loss:0.0024510086269418914\n",
      "train loss:0.007933607981052918\n",
      "train loss:0.0020363429535189296\n",
      "train loss:0.0013651339373775796\n",
      "train loss:0.031313658246907815\n",
      "train loss:0.0007482996552218301\n",
      "train loss:0.0007673519208071823\n",
      "train loss:0.0034226246590038046\n",
      "train loss:0.006604715095274616\n",
      "train loss:0.005859762957686928\n",
      "train loss:0.014195384870069083\n",
      "=== epoch:12, train acc:0.995, test acc:0.98 ===\n",
      "train loss:0.0010149311453217173\n",
      "train loss:0.004143417225566754\n",
      "train loss:0.005274793894916205\n",
      "train loss:0.010133454416384313\n",
      "train loss:0.0008142634448112014\n",
      "train loss:0.0027146405071973257\n",
      "train loss:0.0018725863969703519\n",
      "train loss:0.0066751325742349125\n",
      "train loss:0.003421057669985122\n",
      "train loss:0.0029483344464324105\n",
      "train loss:0.0026011004110067077\n",
      "train loss:0.016803934465621943\n",
      "train loss:0.0007039444686625417\n",
      "train loss:0.00040967010790369325\n",
      "train loss:0.0037031055385844907\n",
      "train loss:0.0011179637425203213\n",
      "train loss:0.0038153804161887486\n",
      "train loss:0.009843048906924199\n",
      "train loss:0.005882970928792617\n",
      "train loss:0.03891582518961176\n",
      "train loss:0.016928734454558725\n",
      "train loss:0.007095517710023509\n",
      "train loss:0.006977394522919706\n",
      "train loss:0.001932470709260163\n",
      "train loss:0.007351156624850025\n",
      "train loss:0.011448926570201148\n",
      "train loss:0.005100747360859378\n",
      "train loss:0.006630206989612295\n",
      "train loss:0.009166349490894569\n",
      "train loss:0.002586895158580635\n",
      "train loss:0.015407336680601512\n",
      "train loss:0.0038296924124457048\n",
      "train loss:0.014652147732364527\n",
      "train loss:0.035237982650104895\n",
      "train loss:0.006540606345047377\n",
      "train loss:0.0481028598524615\n",
      "train loss:0.0028463773556713172\n",
      "train loss:0.0010377064708774223\n",
      "train loss:0.0008369870668678451\n",
      "train loss:0.0014505607749332081\n",
      "train loss:0.007959541554695283\n",
      "train loss:0.003052547900442244\n",
      "train loss:0.0033344999001577104\n",
      "train loss:0.00675367654678662\n",
      "train loss:0.005403220875341233\n",
      "train loss:0.002352661810633595\n",
      "train loss:0.005684553215257209\n",
      "train loss:0.00724594229252246\n",
      "train loss:0.0041492990150641205\n",
      "train loss:0.01374786573989637\n",
      "train loss:0.0048675873374450515\n",
      "train loss:0.0015739056943908016\n",
      "train loss:0.0008995034542651997\n",
      "train loss:0.005115847745581005\n",
      "train loss:0.012146935955523398\n",
      "train loss:0.003629624691820865\n",
      "train loss:0.005365153704348206\n",
      "train loss:0.00393351705551748\n",
      "train loss:0.0038637316061394954\n",
      "train loss:0.0021531135877786317\n",
      "train loss:0.001611362088853618\n",
      "train loss:0.006167397190573489\n",
      "train loss:0.009208830508158813\n",
      "train loss:0.001209122897472711\n",
      "train loss:0.02822244470213053\n",
      "train loss:0.004940318638451383\n",
      "train loss:0.01277076617134801\n",
      "train loss:0.004140472247563249\n",
      "train loss:0.00206824634273048\n",
      "train loss:0.008490088315666718\n",
      "train loss:0.002708570164342943\n",
      "train loss:0.015442885687714172\n",
      "train loss:0.003190564842997537\n",
      "train loss:0.009352736353869077\n",
      "train loss:0.006567849671394779\n",
      "train loss:0.012100495776511656\n",
      "train loss:0.0030909477747730263\n",
      "train loss:0.0013012399169568733\n",
      "train loss:0.0022682112523159893\n",
      "train loss:0.0009491571002114112\n",
      "train loss:0.00029965080396833287\n",
      "train loss:0.008377894994460532\n",
      "train loss:0.002794872091362405\n",
      "train loss:0.003680072584144889\n",
      "train loss:0.03517679725414668\n",
      "train loss:0.0031034237332150157\n",
      "train loss:0.022950584050043597\n",
      "train loss:0.020295198565477773\n",
      "train loss:0.0024542437918056974\n",
      "train loss:0.0020555981236269343\n",
      "train loss:0.0015976292984519421\n",
      "train loss:0.018462367928986388\n",
      "train loss:0.0036163100721743192\n",
      "train loss:0.012650719587914038\n",
      "train loss:0.015877224792791755\n",
      "train loss:0.0005106030162255481\n",
      "train loss:0.007083289728932974\n",
      "train loss:0.0036399394829559305\n",
      "train loss:0.01182951511791138\n",
      "train loss:0.0017538251909547623\n",
      "train loss:0.002316779250312369\n",
      "train loss:0.012164194452222584\n",
      "train loss:0.0032197487073940202\n",
      "train loss:0.0024301259888344024\n",
      "train loss:0.012480328998292902\n",
      "train loss:0.0043796996642305255\n",
      "train loss:0.01758137627407378\n",
      "train loss:0.0077132875377272855\n",
      "train loss:0.007136660062632625\n",
      "train loss:0.005564503309770431\n",
      "train loss:0.0017997754603444566\n",
      "train loss:0.000801895430559904\n",
      "train loss:0.014138144556288354\n",
      "train loss:0.004473314778581793\n",
      "train loss:0.004153288689822658\n",
      "train loss:0.0013310173899313154\n",
      "train loss:0.007925782410531892\n",
      "train loss:0.013726914393365382\n",
      "train loss:0.009490129733252292\n",
      "train loss:0.0037393791596425086\n",
      "train loss:0.025132604643287527\n",
      "train loss:0.009878644590388513\n",
      "train loss:0.009752082129232564\n",
      "train loss:0.0027922310383192645\n",
      "train loss:0.00531239342808556\n",
      "train loss:0.02402254686565337\n",
      "train loss:0.0007446737544732395\n",
      "train loss:0.029522697631545674\n",
      "train loss:0.006373429932937745\n",
      "train loss:0.006181911299639221\n",
      "train loss:0.0031492245900358313\n",
      "train loss:0.0007697430298933812\n",
      "train loss:0.01900312503792013\n",
      "train loss:0.001587409465825298\n",
      "train loss:0.006548386653795107\n",
      "train loss:0.001297164720626095\n",
      "train loss:0.0008801650062569343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015839117737002136\n",
      "train loss:0.009267639885110148\n",
      "train loss:0.002451404375924968\n",
      "train loss:0.007038460787277906\n",
      "train loss:0.00031414683218040505\n",
      "train loss:0.0033121000914756345\n",
      "train loss:0.008815038036028263\n",
      "train loss:0.0016111233712514258\n",
      "train loss:0.05272449590069484\n",
      "train loss:0.005960209520723593\n",
      "train loss:0.0059283417358317395\n",
      "train loss:0.021180706771436082\n",
      "train loss:0.007630951981995784\n",
      "train loss:0.0028865042566650644\n",
      "train loss:0.0011145668729690716\n",
      "train loss:0.0010274024405030253\n",
      "train loss:0.007070281407092233\n",
      "train loss:0.005422786438231372\n",
      "train loss:0.0033677425927196897\n",
      "train loss:0.008479724021517697\n",
      "train loss:0.002041929556980799\n",
      "train loss:0.004316181516352323\n",
      "train loss:0.0014637258567874775\n",
      "train loss:0.0005332030425823519\n",
      "train loss:0.011419564079918182\n",
      "train loss:0.004822617418530965\n",
      "train loss:0.0074520497358063235\n",
      "train loss:0.0006265024126763999\n",
      "train loss:0.008137354189479737\n",
      "train loss:0.0003658326098518197\n",
      "train loss:0.00479094617328089\n",
      "train loss:0.015592336008015677\n",
      "train loss:0.004177497628068102\n",
      "train loss:0.002601002916626527\n",
      "train loss:0.0013502589179658965\n",
      "train loss:0.004365236384202632\n",
      "train loss:0.0010378112419189484\n",
      "train loss:0.009576889845742668\n",
      "train loss:0.0025124683151431463\n",
      "train loss:0.007380970294273173\n",
      "train loss:0.0031759186893844\n",
      "train loss:0.001196718864071293\n",
      "train loss:0.0012138649499423089\n",
      "train loss:0.004080907885745741\n",
      "train loss:0.005042741931578935\n",
      "train loss:0.003545115434974847\n",
      "train loss:0.004146654994508625\n",
      "train loss:0.003478460820947823\n",
      "train loss:0.01129170262003055\n",
      "train loss:0.0010930704153790168\n",
      "train loss:0.007568237800573138\n",
      "train loss:0.001664360031387649\n",
      "train loss:0.0042252917532700565\n",
      "train loss:0.005308759996435215\n",
      "train loss:0.005521329967174763\n",
      "train loss:0.003224119470087845\n",
      "train loss:0.002904368526393443\n",
      "train loss:0.003091083506314984\n",
      "train loss:0.0013715249300805892\n",
      "train loss:0.012960567765459157\n",
      "train loss:0.002112695363316504\n",
      "train loss:0.0014779982858653398\n",
      "train loss:0.00293913910563114\n",
      "train loss:0.0057988011039189005\n",
      "train loss:0.004803313002083403\n",
      "train loss:0.0015724135871909516\n",
      "train loss:0.005390808476147474\n",
      "train loss:0.004312476800468549\n",
      "train loss:0.005329537266075997\n",
      "train loss:0.006058379941282065\n",
      "train loss:0.0027086422232701023\n",
      "train loss:0.0020589995853658506\n",
      "train loss:0.0065355921487330205\n",
      "train loss:0.0056660277376370605\n",
      "train loss:0.010941538777685918\n",
      "train loss:0.009505173448635718\n",
      "train loss:0.00794173489576757\n",
      "train loss:0.0013902236730304587\n",
      "train loss:0.005524164738537559\n",
      "train loss:0.006773089382134947\n",
      "train loss:0.007508894053278403\n",
      "train loss:0.005569483338508918\n",
      "train loss:0.002480519370413436\n",
      "train loss:0.0015308977359214805\n",
      "train loss:0.003919807460028721\n",
      "train loss:0.005560686072098844\n",
      "train loss:0.025500473068915844\n",
      "train loss:0.036390040278088905\n",
      "train loss:0.0015163202982584366\n",
      "train loss:0.010493710564339731\n",
      "train loss:0.008580579725576748\n",
      "train loss:0.009404896883744632\n",
      "train loss:0.012160306267477843\n",
      "train loss:0.0010352481751170638\n",
      "train loss:0.01281137057661337\n",
      "train loss:0.00043007610070294636\n",
      "train loss:0.004651851927199673\n",
      "train loss:0.0008721817545506136\n",
      "train loss:0.011008522497160795\n",
      "train loss:0.014887904763697534\n",
      "train loss:0.018018389331049597\n",
      "train loss:0.005174951168554518\n",
      "train loss:0.0017411151315820691\n",
      "train loss:0.0034381193517574377\n",
      "train loss:0.01201464570326076\n",
      "train loss:0.002146911990195059\n",
      "train loss:0.012957797920192915\n",
      "train loss:0.0035709190841642195\n",
      "train loss:0.011760250780256888\n",
      "train loss:0.02034314013855379\n",
      "train loss:9.893946276737193e-05\n",
      "train loss:0.0019504226594922608\n",
      "train loss:0.019971137313474437\n",
      "train loss:0.005218843589107348\n",
      "train loss:0.001377005501681575\n",
      "train loss:0.007009402387037299\n",
      "train loss:0.010931958126594622\n",
      "train loss:0.05045510736936243\n",
      "train loss:0.008062862687533874\n",
      "train loss:0.00656151201966885\n",
      "train loss:0.0013192679111231152\n",
      "train loss:0.0035508909593375475\n",
      "train loss:0.0045260439625158825\n",
      "train loss:0.007596093178987655\n",
      "train loss:0.01298899727127401\n",
      "train loss:0.0011585798259298639\n",
      "train loss:0.004139922388179711\n",
      "train loss:0.013815120885721826\n",
      "train loss:0.022879313419986436\n",
      "train loss:0.011943516326797372\n",
      "train loss:0.004728959041915643\n",
      "train loss:0.011151641398999226\n",
      "train loss:0.018023815562444506\n",
      "train loss:0.0027390331910180444\n",
      "train loss:0.02704503637844299\n",
      "train loss:0.015896183177738298\n",
      "train loss:0.00045914514166069614\n",
      "train loss:0.009621237530610857\n",
      "train loss:0.001763533099600189\n",
      "train loss:0.033657840484064186\n",
      "train loss:0.011051830578822414\n",
      "train loss:0.0024508646791368046\n",
      "train loss:0.015192836074645779\n",
      "train loss:0.00409860960125057\n",
      "train loss:0.004183050841849105\n",
      "train loss:0.002705136658222487\n",
      "train loss:0.0029535851516186724\n",
      "train loss:0.0035662760919517073\n",
      "train loss:0.0008385520498522863\n",
      "train loss:0.005236153460929099\n",
      "train loss:0.001468480404148197\n",
      "train loss:0.002080881925939461\n",
      "train loss:0.011993528937346273\n",
      "train loss:0.007976907495045754\n",
      "train loss:0.0009549027143857237\n",
      "train loss:0.011192473843306962\n",
      "train loss:0.029518575182923272\n",
      "train loss:0.004246177821103654\n",
      "train loss:0.024548572106836385\n",
      "train loss:0.0028270809840625333\n",
      "train loss:0.0035631620799579313\n",
      "train loss:0.0017470968488690656\n",
      "train loss:0.02527491403452574\n",
      "train loss:0.002684654311656634\n",
      "train loss:0.0038140863790650514\n",
      "train loss:0.004657922636554341\n",
      "train loss:0.002757409576856335\n",
      "train loss:0.0011876783334037818\n",
      "train loss:0.019188485828547534\n",
      "train loss:0.0038098772661732056\n",
      "train loss:0.004871787754171756\n",
      "train loss:0.0011055110254807531\n",
      "train loss:0.013256302921263926\n",
      "train loss:0.02677776585979872\n",
      "train loss:0.0012937992711283266\n",
      "train loss:0.003945428795522561\n",
      "train loss:0.008211013173319742\n",
      "train loss:0.002525239955475059\n",
      "train loss:0.0038311451805550095\n",
      "train loss:0.0032758279465155914\n",
      "train loss:0.0017878667001979035\n",
      "train loss:0.00209240769227291\n",
      "train loss:0.003562337636832695\n",
      "train loss:0.007225870854040473\n",
      "train loss:0.00855013646063505\n",
      "train loss:0.004783103504306247\n",
      "train loss:0.002681075805556528\n",
      "train loss:0.0028597479738143947\n",
      "train loss:0.00040177672398103984\n",
      "train loss:0.0021433321881478896\n",
      "train loss:0.010994972613922573\n",
      "train loss:0.0019754956701200925\n",
      "train loss:0.015303084317251792\n",
      "train loss:0.0014523482241318058\n",
      "train loss:0.007059476572820555\n",
      "train loss:0.0033577987902061036\n",
      "train loss:0.001797141019410142\n",
      "train loss:0.01433349832116136\n",
      "train loss:0.003294047387701352\n",
      "train loss:0.006809828648024676\n",
      "train loss:0.0013113721085144556\n",
      "train loss:0.014870309638334593\n",
      "train loss:0.01600000895530542\n",
      "train loss:0.012082963101000842\n",
      "train loss:0.010873892683645114\n",
      "train loss:0.0037503327918763526\n",
      "train loss:0.028639154102234242\n",
      "train loss:0.019836133545386506\n",
      "train loss:0.0031196171802591655\n",
      "train loss:0.005909995233053105\n",
      "train loss:0.0006130815372086739\n",
      "train loss:0.009095026194685288\n",
      "train loss:0.004292367590598904\n",
      "train loss:0.014355697498636107\n",
      "train loss:0.005396216031518758\n",
      "train loss:0.005712234251979134\n",
      "train loss:0.00460063846949904\n",
      "train loss:0.0007684170652446996\n",
      "train loss:0.0025298473628425342\n",
      "train loss:0.009625918947463796\n",
      "train loss:0.004290467745511384\n",
      "train loss:0.004569930003704252\n",
      "train loss:0.004263402018563129\n",
      "train loss:0.002410529612444574\n",
      "train loss:0.003282546362820628\n",
      "train loss:0.0010723649552654576\n",
      "train loss:0.0017892439749396477\n",
      "train loss:0.005011980016729388\n",
      "train loss:0.010101079851839436\n",
      "train loss:0.017199918802349452\n",
      "train loss:0.005110426321766743\n",
      "train loss:0.004920099227016038\n",
      "train loss:0.006118635441144354\n",
      "train loss:0.0022783178251467666\n",
      "train loss:0.002764364325087182\n",
      "train loss:0.005142744172295868\n",
      "train loss:0.002686740615964509\n",
      "train loss:0.0015985925105982777\n",
      "train loss:0.009638061443066845\n",
      "train loss:0.0038270052363088237\n",
      "train loss:0.0006308530253428708\n",
      "train loss:0.00021185168674218839\n",
      "train loss:0.0066402230241645235\n",
      "train loss:0.0033731044226014053\n",
      "train loss:0.005900798558740099\n",
      "train loss:0.0038736460492760703\n",
      "train loss:0.0006790768021990044\n",
      "train loss:0.0050841632453557176\n",
      "train loss:0.030777587421906515\n",
      "train loss:0.0013438222488960014\n",
      "train loss:0.03374361178594597\n",
      "train loss:0.004155993070250493\n",
      "train loss:0.007123308598723971\n",
      "train loss:0.006261867796518683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004995503015869419\n",
      "train loss:0.0017269491414272807\n",
      "train loss:0.0011093039305433827\n",
      "train loss:0.004520013179672361\n",
      "train loss:0.0019108341577755068\n",
      "train loss:0.015175332753472087\n",
      "train loss:0.0043469245385888335\n",
      "train loss:0.006948471036892283\n",
      "train loss:0.0028079743349320786\n",
      "train loss:0.01592486343976265\n",
      "train loss:0.0018114464502918424\n",
      "train loss:0.010218145232930055\n",
      "train loss:0.06235574217279134\n",
      "train loss:0.0032395207493790667\n",
      "train loss:0.01669616338775731\n",
      "train loss:0.0006711833984698862\n",
      "train loss:0.01860114273200841\n",
      "train loss:0.005380461668819234\n",
      "train loss:0.004580460527178207\n",
      "train loss:0.017726907557801458\n",
      "train loss:0.004323786316837573\n",
      "train loss:0.0011002702820733464\n",
      "train loss:0.0013848334383543743\n",
      "train loss:0.012969834928432102\n",
      "train loss:0.005497272901040001\n",
      "train loss:0.0011981819971409256\n",
      "train loss:0.0007664898610207518\n",
      "train loss:0.0007194028790488431\n",
      "train loss:0.0019831634564778434\n",
      "train loss:0.005796420556379999\n",
      "train loss:0.008265048060416757\n",
      "train loss:0.004908456395270344\n",
      "train loss:0.003879136975984865\n",
      "train loss:0.004979286382386599\n",
      "train loss:0.001479860733447799\n",
      "train loss:0.009946462279213704\n",
      "train loss:0.02553087516347121\n",
      "train loss:0.0005192438590641618\n",
      "train loss:0.008186322636326158\n",
      "train loss:0.02667203532809123\n",
      "train loss:0.0025660910980333544\n",
      "train loss:0.0029061866311380514\n",
      "train loss:0.002159768055581207\n",
      "train loss:0.004949395443867151\n",
      "train loss:0.02474992909254815\n",
      "train loss:0.0016603025576464594\n",
      "train loss:0.009698173263035993\n",
      "train loss:0.007003826509119766\n",
      "train loss:0.0035231574649775732\n",
      "train loss:0.0020352433127778825\n",
      "train loss:0.005603812188099564\n",
      "train loss:0.0007590643928505385\n",
      "train loss:0.0009592438414924309\n",
      "train loss:0.01300429923972169\n",
      "train loss:0.0005622713190281719\n",
      "train loss:0.00809852224680439\n",
      "train loss:0.005101814261279983\n",
      "train loss:0.006538261228064669\n",
      "train loss:0.002610339232360763\n",
      "train loss:0.0029283837274795433\n",
      "train loss:0.0018637612671734117\n",
      "train loss:0.0010423993592527272\n",
      "train loss:0.025566796883942745\n",
      "train loss:0.0018125615184492125\n",
      "train loss:0.0028455610175539005\n",
      "train loss:0.00562703417390378\n",
      "train loss:0.0020234986810706416\n",
      "train loss:0.0032207006008708335\n",
      "train loss:0.002641015539092319\n",
      "train loss:0.0006793015444939968\n",
      "train loss:0.00267107406073768\n",
      "train loss:0.00504871440075698\n",
      "train loss:0.001026972078716676\n",
      "train loss:0.0005041003717569071\n",
      "train loss:0.00667277050480698\n",
      "train loss:0.014347996749173449\n",
      "train loss:0.003167959134001915\n",
      "train loss:0.00027962889151109593\n",
      "train loss:0.005061613588970282\n",
      "train loss:0.004285139990576141\n",
      "train loss:0.00307139455963156\n",
      "train loss:0.00029067461446709894\n",
      "train loss:0.004828205900827779\n",
      "train loss:0.006349471263349171\n",
      "train loss:0.00685412071035462\n",
      "train loss:0.002356111981927961\n",
      "train loss:0.0005909848441284423\n",
      "train loss:0.007631903696645102\n",
      "train loss:0.0037989487739069246\n",
      "train loss:0.001562581922269632\n",
      "train loss:0.004850207747151791\n",
      "train loss:0.0003483389269054523\n",
      "train loss:0.01900283298704443\n",
      "train loss:0.004534805072036175\n",
      "train loss:0.0004184017132215791\n",
      "train loss:0.0004781592580061066\n",
      "train loss:0.0005848032999426468\n",
      "train loss:0.001311047880130953\n",
      "train loss:0.0012835696698854124\n",
      "train loss:0.0007048787421425841\n",
      "train loss:0.003814680767915637\n",
      "train loss:0.001127189376400537\n",
      "train loss:0.0019391543613009718\n",
      "train loss:0.0012903680900751646\n",
      "train loss:0.0026165423248098864\n",
      "train loss:0.015629635910799647\n",
      "train loss:0.0009125662198893715\n",
      "train loss:0.004888560691612715\n",
      "train loss:0.008758993565227639\n",
      "train loss:0.0011708341559408717\n",
      "train loss:0.00025332465489245356\n",
      "train loss:1.9508739365942775e-05\n",
      "train loss:0.0037850380109974717\n",
      "train loss:0.012577741647483648\n",
      "train loss:0.008863147801070358\n",
      "train loss:0.02312375700449456\n",
      "train loss:0.006739013734903144\n",
      "train loss:0.0013072040501970162\n",
      "train loss:0.010658569437213428\n",
      "train loss:0.0026566652453171875\n",
      "train loss:0.0014729337719382987\n",
      "train loss:0.002561955173991505\n",
      "train loss:0.0004411079000030647\n",
      "train loss:0.01485447167632114\n",
      "train loss:0.0031954899075410416\n",
      "train loss:0.004799853098228167\n",
      "train loss:0.00039668155582214766\n",
      "train loss:0.013975307927570981\n",
      "train loss:0.006217931351005977\n",
      "train loss:0.006211091056867628\n",
      "train loss:0.0038389386699461767\n",
      "train loss:0.0009238158360811295\n",
      "train loss:0.0042296772980737396\n",
      "train loss:0.006458221457823695\n",
      "train loss:0.006003636916978841\n",
      "train loss:0.028293596219614258\n",
      "train loss:0.003203493966247819\n",
      "train loss:0.0036416426840934313\n",
      "train loss:0.0007072231696509924\n",
      "train loss:0.0032914639929950192\n",
      "train loss:0.0022307987175847937\n",
      "train loss:0.0014679828987903046\n",
      "train loss:0.0042946899281609205\n",
      "train loss:0.0005581784793498262\n",
      "train loss:0.001210106664055522\n",
      "train loss:0.002668384673593635\n",
      "train loss:0.006429300168966504\n",
      "train loss:0.001106711408556561\n",
      "train loss:0.014957612814632523\n",
      "train loss:0.0026078682619122984\n",
      "train loss:0.005947895399788912\n",
      "train loss:0.0016127674560845052\n",
      "train loss:0.00224898978227583\n",
      "train loss:0.0009063932558377994\n",
      "train loss:0.003336877178747124\n",
      "train loss:0.0013175860584963078\n",
      "train loss:0.005315655468395392\n",
      "train loss:0.010258732839444373\n",
      "train loss:0.0010369384307415282\n",
      "train loss:0.002102937148170015\n",
      "train loss:0.0036262333979542438\n",
      "train loss:0.008100746511811375\n",
      "train loss:0.0005321244480251157\n",
      "train loss:0.006679480942200765\n",
      "train loss:0.004829972666287999\n",
      "train loss:0.004548532085695328\n",
      "train loss:0.0035109139598346966\n",
      "train loss:0.007136660120722595\n",
      "train loss:0.0023660636450372687\n",
      "train loss:0.019106845031125017\n",
      "train loss:0.011227959006300428\n",
      "train loss:0.001968764741196928\n",
      "train loss:0.0036726193654116335\n",
      "train loss:0.0031997077699681673\n",
      "train loss:0.0013850140443578476\n",
      "train loss:0.00262030130041336\n",
      "train loss:0.000336182068601952\n",
      "train loss:0.0009899157763941166\n",
      "train loss:0.01450995277023131\n",
      "train loss:0.00189141398892008\n",
      "train loss:0.006519804521696672\n",
      "train loss:0.0010753776424266325\n",
      "train loss:0.0012205754824880307\n",
      "train loss:0.0003318576044427995\n",
      "train loss:0.0031145984420543143\n",
      "train loss:0.004466738712216269\n",
      "train loss:0.035146862355354795\n",
      "train loss:0.0466385535084915\n",
      "train loss:0.0063274549366618684\n",
      "train loss:0.001405125549914482\n",
      "train loss:0.00042164246481225814\n",
      "train loss:0.0016563858215809218\n",
      "train loss:0.0016755469040256898\n",
      "train loss:0.0018069927828570293\n",
      "train loss:0.002071093342766423\n",
      "train loss:0.02507125528933521\n",
      "train loss:0.03092084095720374\n",
      "train loss:0.011978938009946568\n",
      "train loss:0.014792304025996614\n",
      "train loss:0.003573962479470971\n",
      "train loss:0.006497362931173074\n",
      "train loss:0.002414477033824446\n",
      "train loss:0.018610927929915415\n",
      "train loss:0.003728030181890845\n",
      "train loss:0.1720563625430065\n",
      "train loss:0.0033643944352441772\n",
      "train loss:0.0044315943162891855\n",
      "train loss:0.001267155608015859\n",
      "train loss:0.012561989107837075\n",
      "=== epoch:13, train acc:0.995, test acc:0.985 ===\n",
      "train loss:0.005581305758497738\n",
      "train loss:0.004572162758127669\n",
      "train loss:0.005069362629528761\n",
      "train loss:0.011559781295832197\n",
      "train loss:0.002287856269600391\n",
      "train loss:0.000924371861352605\n",
      "train loss:0.0006773634484540992\n",
      "train loss:0.038490738249409476\n",
      "train loss:0.00483245009761578\n",
      "train loss:0.003799920213499719\n",
      "train loss:0.004308609914637328\n",
      "train loss:0.0030469649508462885\n",
      "train loss:0.00024051308500182844\n",
      "train loss:0.010912345474423664\n",
      "train loss:0.0008761084772609251\n",
      "train loss:0.005503228783744239\n",
      "train loss:0.0012705413471857199\n",
      "train loss:0.005373119191032604\n",
      "train loss:0.003594002164107709\n",
      "train loss:0.004024234595873278\n",
      "train loss:0.004867537298270321\n",
      "train loss:0.006672613445868694\n",
      "train loss:0.030007087216460324\n",
      "train loss:0.004135766906743538\n",
      "train loss:0.0037850804366953137\n",
      "train loss:0.0010978062891512928\n",
      "train loss:0.002163084268496495\n",
      "train loss:0.00108189790516473\n",
      "train loss:0.0028023347191982687\n",
      "train loss:0.0005373522069386792\n",
      "train loss:0.0038241699897127745\n",
      "train loss:0.0015276384791563743\n",
      "train loss:0.002465972133547498\n",
      "train loss:0.0007065688077539362\n",
      "train loss:0.0020253113315270785\n",
      "train loss:0.008643250722206671\n",
      "train loss:0.0055479330277071245\n",
      "train loss:0.0011933942984467154\n",
      "train loss:0.003113154467193558\n",
      "train loss:0.005256384152354228\n",
      "train loss:0.002477775141683282\n",
      "train loss:0.009409062933016589\n",
      "train loss:0.0018924031981585431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0021619352036313607\n",
      "train loss:0.0028886854125122776\n",
      "train loss:0.0031673231059170144\n",
      "train loss:0.0039897783444193076\n",
      "train loss:0.0024886815411632322\n",
      "train loss:0.004694387520931959\n",
      "train loss:0.0011746272142453215\n",
      "train loss:0.012262186511645184\n",
      "train loss:0.009114189276483248\n",
      "train loss:0.001971168798384292\n",
      "train loss:0.0015093318076587034\n",
      "train loss:0.0012424489114068239\n",
      "train loss:0.002156206626415748\n",
      "train loss:0.016046147134699637\n",
      "train loss:0.001327502845163819\n",
      "train loss:0.004764839089085384\n",
      "train loss:0.0007678578757949671\n",
      "train loss:0.0005302078869385405\n",
      "train loss:0.010048418835066195\n",
      "train loss:0.02103660258784382\n",
      "train loss:0.001330559504502696\n",
      "train loss:0.0007892323032699278\n",
      "train loss:0.015859796094106867\n",
      "train loss:0.0025369507802828688\n",
      "train loss:0.004986846912828186\n",
      "train loss:0.0016368873714550636\n",
      "train loss:0.008709071964956027\n",
      "train loss:0.0012610347723809561\n",
      "train loss:0.008452357315262607\n",
      "train loss:0.004807680243540219\n",
      "train loss:0.010789821702916638\n",
      "train loss:0.0007632259560026264\n",
      "train loss:0.0014601435674872604\n",
      "train loss:0.000696946086471381\n",
      "train loss:0.009783269637260584\n",
      "train loss:0.003771385723656492\n",
      "train loss:0.0006991707032023341\n",
      "train loss:0.03198627190254254\n",
      "train loss:0.001681818777585331\n",
      "train loss:0.0032596119834859298\n",
      "train loss:0.0026444986613972515\n",
      "train loss:0.0004937811249964175\n",
      "train loss:0.0011525652133299263\n",
      "train loss:0.0002483160159264255\n",
      "train loss:0.0019081439236608127\n",
      "train loss:0.030467273762510187\n",
      "train loss:0.008274911221046472\n",
      "train loss:0.0054996889401735605\n",
      "train loss:0.000694140030748493\n",
      "train loss:0.0019483534658740823\n",
      "train loss:0.0005821762729756028\n",
      "train loss:0.002232910783475797\n",
      "train loss:0.0008785796861603205\n",
      "train loss:0.0037181215404579406\n",
      "train loss:0.002767408131097338\n",
      "train loss:0.007754814362736387\n",
      "train loss:0.0005423771904819509\n",
      "train loss:0.0007127565926264365\n",
      "train loss:0.0007718872302590928\n",
      "train loss:0.00045978120087902146\n",
      "train loss:0.0031320581574332297\n",
      "train loss:0.026169459508297032\n",
      "train loss:0.007122445002136033\n",
      "train loss:0.012770733489825763\n",
      "train loss:0.05510967592750015\n",
      "train loss:0.00770568951544636\n",
      "train loss:0.003178735636920917\n",
      "train loss:0.0014322601346422011\n",
      "train loss:0.0011623013168723785\n",
      "train loss:0.0013577252361581258\n",
      "train loss:0.0024747344441693074\n",
      "train loss:0.0006346311196684457\n",
      "train loss:0.0024274679715345984\n",
      "train loss:0.0005921987783062927\n",
      "train loss:0.008058429051170067\n",
      "train loss:0.0197983940762049\n",
      "train loss:0.00562941347658732\n",
      "train loss:0.005097609075459531\n",
      "train loss:0.000489313989030458\n",
      "train loss:0.0010786648909625427\n",
      "train loss:0.002696283244439909\n",
      "train loss:0.002382798037763539\n",
      "train loss:0.006048134135106432\n",
      "train loss:0.0025268460995453686\n",
      "train loss:0.005552798971758049\n",
      "train loss:0.0033905572577430094\n",
      "train loss:0.001846315813844359\n",
      "train loss:0.0017921306708325072\n",
      "train loss:0.025300746980482618\n",
      "train loss:0.0016538832741948757\n",
      "train loss:0.0019546771058999\n",
      "train loss:0.0050128603621541435\n",
      "train loss:0.0083072705249698\n",
      "train loss:0.0054956331684341666\n",
      "train loss:0.005919201625715714\n",
      "train loss:0.0017668123236242303\n",
      "train loss:0.005647069169200864\n",
      "train loss:0.0002665411934176371\n",
      "train loss:0.004084910001677484\n",
      "train loss:0.005392227513366459\n",
      "train loss:0.0023644465249478878\n",
      "train loss:0.0034348709795108475\n",
      "train loss:0.004119677772091531\n",
      "train loss:0.0011155925398749378\n",
      "train loss:0.0015275926033146941\n",
      "train loss:0.0005327804336558825\n",
      "train loss:0.0024049035879316156\n",
      "train loss:0.0026804675124907458\n",
      "train loss:0.0014531894591524987\n",
      "train loss:0.026606339212976324\n",
      "train loss:0.007338533671146107\n",
      "train loss:0.008179648202286905\n",
      "train loss:0.01295921900610899\n",
      "train loss:0.0055760780940555385\n",
      "train loss:0.004213118517545979\n",
      "train loss:0.0012321881690868417\n",
      "train loss:0.002257350885261425\n",
      "train loss:0.0008096329554431147\n",
      "train loss:0.00018903272748202124\n",
      "train loss:0.002649760370797178\n",
      "train loss:0.005959146645622371\n",
      "train loss:0.006596868551301879\n",
      "train loss:0.007599342452292692\n",
      "train loss:0.001917475806170263\n",
      "train loss:0.009652877734964083\n",
      "train loss:0.0005420384731143589\n",
      "train loss:0.0046374483745367425\n",
      "train loss:0.007410948681605543\n",
      "train loss:0.003854402773681741\n",
      "train loss:0.0021788841708970615\n",
      "train loss:0.0011688118158852566\n",
      "train loss:0.008634863075286922\n",
      "train loss:0.002898263356676353\n",
      "train loss:0.0008579405872641771\n",
      "train loss:0.0026123988566810474\n",
      "train loss:0.0002918747302510452\n",
      "train loss:0.002128541877250893\n",
      "train loss:0.0008015401961884906\n",
      "train loss:0.0023663014593743167\n",
      "train loss:0.002367876305509256\n",
      "train loss:0.0017069832144274762\n",
      "train loss:0.0031040564688452122\n",
      "train loss:0.0016115002047460115\n",
      "train loss:0.0022665018998035353\n",
      "train loss:0.0005155913558084463\n",
      "train loss:0.0018835005483781569\n",
      "train loss:0.0120348881581213\n",
      "train loss:0.0008424846610000696\n",
      "train loss:0.00063986461958804\n",
      "train loss:0.002108634749908305\n",
      "train loss:0.0006479282303912314\n",
      "train loss:0.018535544107530312\n",
      "train loss:0.01158563165486253\n",
      "train loss:0.003318316033854779\n",
      "train loss:0.0005487201113078334\n",
      "train loss:0.017247187103820227\n",
      "train loss:0.0008803744487325389\n",
      "train loss:0.0014312267680073468\n",
      "train loss:0.0032608117768723756\n",
      "train loss:0.0018656482211103795\n",
      "train loss:0.006178489794973036\n",
      "train loss:0.0032997582786097606\n",
      "train loss:0.003602794439953282\n",
      "train loss:0.007145827131761797\n",
      "train loss:0.0012170724268187084\n",
      "train loss:0.0012061917900212777\n",
      "train loss:0.0011632383526833665\n",
      "train loss:0.005189100776912949\n",
      "train loss:0.0010098629317347688\n",
      "train loss:0.0007909182532019653\n",
      "train loss:0.00046479371493974637\n",
      "train loss:0.004944338853184794\n",
      "train loss:0.004640206138256348\n",
      "train loss:0.002065805085231306\n",
      "train loss:0.01850660488359665\n",
      "train loss:0.004984892323031147\n",
      "train loss:0.0018779819441025565\n",
      "train loss:0.0021932790833448035\n",
      "train loss:0.0008014279081522795\n",
      "train loss:0.003168627281101802\n",
      "train loss:0.0008749319221430671\n",
      "train loss:0.0023314035918783763\n",
      "train loss:0.006769611374905834\n",
      "train loss:0.0006666015930570467\n",
      "train loss:0.00321707328164748\n",
      "train loss:0.0009104637066662901\n",
      "train loss:0.0034288315279488784\n",
      "train loss:0.002310262285231473\n",
      "train loss:0.007221831697196367\n",
      "train loss:0.0012870567477805336\n",
      "train loss:0.0046091667671638165\n",
      "train loss:0.005659102517111453\n",
      "train loss:0.003068024648341964\n",
      "train loss:0.024037943133572295\n",
      "train loss:0.0010727003343098263\n",
      "train loss:0.022242293275484184\n",
      "train loss:0.001731791484095862\n",
      "train loss:0.01932072487550317\n",
      "train loss:0.0001209853676260122\n",
      "train loss:0.0037245113075737744\n",
      "train loss:0.0018858831040938346\n",
      "train loss:0.0015678541770127055\n",
      "train loss:0.005547494648410877\n",
      "train loss:0.012942451246196926\n",
      "train loss:0.03845404693034624\n",
      "train loss:0.0010857736820506926\n",
      "train loss:0.009599775247324263\n",
      "train loss:0.0027317521810306237\n",
      "train loss:0.0069350436724403145\n",
      "train loss:0.0005195933230551185\n",
      "train loss:0.00011555957710616563\n",
      "train loss:0.0019021852473026838\n",
      "train loss:0.004282645946267487\n",
      "train loss:0.0015539847871928161\n",
      "train loss:0.00029429355418505987\n",
      "train loss:0.001887350313564238\n",
      "train loss:0.005189543822709289\n",
      "train loss:0.0010757123574876388\n",
      "train loss:0.0056753053131131884\n",
      "train loss:0.0037036950482404567\n",
      "train loss:0.006497706319499426\n",
      "train loss:0.0008286927488347789\n",
      "train loss:0.0015697261547876938\n",
      "train loss:0.0002057448363456095\n",
      "train loss:0.0030246550218241243\n",
      "train loss:0.16193688156312233\n",
      "train loss:0.00039284553320788194\n",
      "train loss:0.013009531835064902\n",
      "train loss:0.000996708303895403\n",
      "train loss:0.0027327094263541324\n",
      "train loss:0.013411695064345237\n",
      "train loss:0.005905185859618094\n",
      "train loss:0.007021203693815956\n",
      "train loss:0.006757999042957816\n",
      "train loss:0.00035917221225314\n",
      "train loss:0.0032333986321055486\n",
      "train loss:0.00013495256711974863\n",
      "train loss:0.0014782186108352976\n",
      "train loss:0.0038138336926423987\n",
      "train loss:0.002597336650522763\n",
      "train loss:0.004963648418279045\n",
      "train loss:0.001737173468241827\n",
      "train loss:0.017126700766390522\n",
      "train loss:0.0032656683005752333\n",
      "train loss:0.0076251424884974705\n",
      "train loss:0.005775464280321119\n",
      "train loss:0.0005728625078762538\n",
      "train loss:0.0012395977761039834\n",
      "train loss:0.003923231215809349\n",
      "train loss:0.008721694958069013\n",
      "train loss:0.0010066839108944638\n",
      "train loss:0.0015492175358869705\n",
      "train loss:0.003996502045394803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005011296220792168\n",
      "train loss:0.005521539797469034\n",
      "train loss:0.006688991804343193\n",
      "train loss:0.0044866786812501865\n",
      "train loss:0.000950166603157587\n",
      "train loss:0.002098588681677866\n",
      "train loss:0.0015825077283412176\n",
      "train loss:0.004956983159606321\n",
      "train loss:0.004878297239119069\n",
      "train loss:0.004861892563350576\n",
      "train loss:0.0008698050568890567\n",
      "train loss:0.0013119442498109861\n",
      "train loss:0.007242323758070483\n",
      "train loss:0.00732259578992965\n",
      "train loss:0.011655704878172173\n",
      "train loss:0.002417549010845299\n",
      "train loss:0.0009531382469510405\n",
      "train loss:0.0029553690209942595\n",
      "train loss:0.005028537109711007\n",
      "train loss:0.01409923311814086\n",
      "train loss:0.00161001616696847\n",
      "train loss:0.0003042708962619988\n",
      "train loss:0.0016160458932742846\n",
      "train loss:0.0005762971272577066\n",
      "train loss:0.015222064204763353\n",
      "train loss:0.0013192279270990215\n",
      "train loss:0.002151127413595767\n",
      "train loss:0.0009730269922909151\n",
      "train loss:0.008704945064075159\n",
      "train loss:0.0026452559756212314\n",
      "train loss:0.013250347019829084\n",
      "train loss:0.0033012126915974473\n",
      "train loss:0.0004036326937614466\n",
      "train loss:0.00021031829159072674\n",
      "train loss:0.00032969904577045815\n",
      "train loss:0.012222037612567674\n",
      "train loss:0.003028961719399099\n",
      "train loss:0.0018943083047065934\n",
      "train loss:0.0002781948479714546\n",
      "train loss:0.0011829434738628898\n",
      "train loss:0.0015095784180488329\n",
      "train loss:0.002497003181006463\n",
      "train loss:0.00036931663652681033\n",
      "train loss:0.004526956833532243\n",
      "train loss:0.003484864231869037\n",
      "train loss:0.006667476780967324\n",
      "train loss:0.0032185811413020854\n",
      "train loss:0.0007122288611288157\n",
      "train loss:0.0001999080520535497\n",
      "train loss:0.002332612405290312\n",
      "train loss:0.0025424932971727767\n",
      "train loss:0.00018447682054641916\n",
      "train loss:0.01001882362124257\n",
      "train loss:0.0696229951330865\n",
      "train loss:0.0002461543542085366\n",
      "train loss:0.0012345303562110198\n",
      "train loss:0.0051316256072961\n",
      "train loss:0.0009646580934503152\n",
      "train loss:0.005895403705211418\n",
      "train loss:0.00021780809467835066\n",
      "train loss:0.012315236248628982\n",
      "train loss:0.0031567554976498404\n",
      "train loss:0.009131875547758411\n",
      "train loss:0.0009827380775988416\n",
      "train loss:0.0010694176915651379\n",
      "train loss:0.0012662959582035716\n",
      "train loss:0.0015987419461301377\n",
      "train loss:0.0006204763195085395\n",
      "train loss:0.00490254310580035\n",
      "train loss:0.0038142737977770913\n",
      "train loss:0.013672939473354797\n",
      "train loss:0.004325564767198561\n",
      "train loss:0.0019330362250325986\n",
      "train loss:0.0013254375544839235\n",
      "train loss:0.0025487404959219358\n",
      "train loss:0.0002329835270481007\n",
      "train loss:0.0037870885045060833\n",
      "train loss:0.0013969122371389384\n",
      "train loss:0.01733647759293749\n",
      "train loss:0.0007883510635039518\n",
      "train loss:0.0038047744203988224\n",
      "train loss:0.004069647056262973\n",
      "train loss:0.003333821011958986\n",
      "train loss:0.016952105712785742\n",
      "train loss:0.0008802046957439966\n",
      "train loss:0.0006615933862533294\n",
      "train loss:0.007560757201068837\n",
      "train loss:0.006134124719972775\n",
      "train loss:0.0018872555734610462\n",
      "train loss:0.0034789004503277114\n",
      "train loss:0.0007528810936893656\n",
      "train loss:0.0015889031819304915\n",
      "train loss:0.0039015428866950117\n",
      "train loss:0.004204527051020435\n",
      "train loss:0.0017315549471241499\n",
      "train loss:0.024753007242835866\n",
      "train loss:0.0008021570053467071\n",
      "train loss:0.002704209785637539\n",
      "train loss:0.0015964244634368546\n",
      "train loss:0.001732817006514811\n",
      "train loss:0.0007114637012658686\n",
      "train loss:0.0060947027659501544\n",
      "train loss:0.002002437805060027\n",
      "train loss:0.004030179741103317\n",
      "train loss:0.0007771328425222903\n",
      "train loss:0.002437886717159783\n",
      "train loss:0.0019308217790602637\n",
      "train loss:0.0009070362647379893\n",
      "train loss:0.007104207731093387\n",
      "train loss:0.0020976319742981495\n",
      "train loss:0.0008781129596376356\n",
      "train loss:0.00483682065862486\n",
      "train loss:0.0003159280621274523\n",
      "train loss:0.0018684522752315236\n",
      "train loss:0.004925325154284353\n",
      "train loss:0.01095811807416951\n",
      "train loss:0.0013291218353582784\n",
      "train loss:0.0018117577560285154\n",
      "train loss:0.0008661223019937862\n",
      "train loss:0.006034491286209057\n",
      "train loss:0.007080903430334774\n",
      "train loss:0.0037706088229494334\n",
      "train loss:0.0008334679554278544\n",
      "train loss:0.0021056251335992227\n",
      "train loss:0.015646729828904627\n",
      "train loss:0.0051871413274086845\n",
      "train loss:0.008569973646100827\n",
      "train loss:0.0018904443404462886\n",
      "train loss:0.0004641212007941736\n",
      "train loss:0.002205913444589123\n",
      "train loss:0.018638215567066484\n",
      "train loss:0.0014908127666058437\n",
      "train loss:0.001192885217432888\n",
      "train loss:0.00707675814377786\n",
      "train loss:0.03258376550890706\n",
      "train loss:0.008014633283514552\n",
      "train loss:0.010055154824653276\n",
      "train loss:0.0017546673407452021\n",
      "train loss:0.005699676835152703\n",
      "train loss:0.0037980215317512177\n",
      "train loss:0.0014715220330271438\n",
      "train loss:0.009459313480851913\n",
      "train loss:0.0033023278841974773\n",
      "train loss:0.005996721551202484\n",
      "train loss:0.00266300334144149\n",
      "train loss:0.001372136024019008\n",
      "train loss:0.004550426330236505\n",
      "train loss:0.001965279541661244\n",
      "train loss:0.004012932214694721\n",
      "train loss:0.002773335783092874\n",
      "train loss:0.01169098307124529\n",
      "train loss:0.01256628215338982\n",
      "train loss:0.01209181995026019\n",
      "train loss:0.0026978901536697493\n",
      "train loss:0.008116607520440541\n",
      "train loss:0.0034262200081021676\n",
      "train loss:0.0016307410062070171\n",
      "train loss:0.0030838403025993224\n",
      "train loss:0.0024179839551505006\n",
      "train loss:0.0006408296252076149\n",
      "train loss:0.0010945336620537187\n",
      "train loss:0.016421174809342763\n",
      "train loss:0.0009846892794240988\n",
      "train loss:0.0009541061305279152\n",
      "train loss:0.0023539938484354664\n",
      "train loss:0.0031957819320022375\n",
      "train loss:0.001201045736797168\n",
      "train loss:0.0013181545675922815\n",
      "train loss:0.0023609065626963685\n",
      "train loss:0.0032158697138199555\n",
      "train loss:0.0034445769387431986\n",
      "train loss:0.0015020058070340319\n",
      "train loss:0.0005727095765357468\n",
      "train loss:0.0014455919349166866\n",
      "train loss:0.0019139026678267094\n",
      "train loss:0.0033450802731959128\n",
      "train loss:0.002581493183650544\n",
      "train loss:0.0014226428999571262\n",
      "train loss:0.010887997590139578\n",
      "train loss:0.010393931438004893\n",
      "train loss:0.0010233717469878701\n",
      "train loss:0.005986820248059418\n",
      "train loss:0.027061102824216858\n",
      "train loss:0.0026162423636971136\n",
      "train loss:0.0004902673152452817\n",
      "train loss:0.004746063481292202\n",
      "train loss:0.003710336266735112\n",
      "train loss:0.0020589262625245086\n",
      "train loss:0.000979094640664577\n",
      "train loss:0.005716097868218448\n",
      "train loss:0.009881282538203664\n",
      "train loss:0.0021089553308760705\n",
      "train loss:0.001840334547285295\n",
      "train loss:0.00220554816589673\n",
      "train loss:0.0014226337143661927\n",
      "train loss:0.004867736867245278\n",
      "train loss:0.0021768091090801204\n",
      "train loss:0.001252216043075349\n",
      "train loss:0.003981245645850661\n",
      "train loss:0.0010937276722926901\n",
      "train loss:0.0013257517545898646\n",
      "train loss:0.00803987553509491\n",
      "train loss:0.003208205500647456\n",
      "train loss:0.006558592144164682\n",
      "train loss:0.0004219192144332831\n",
      "train loss:0.0010347938209978723\n",
      "train loss:0.0018604578403192667\n",
      "train loss:0.012957444149603077\n",
      "train loss:0.002594408881631378\n",
      "train loss:0.00418836784108888\n",
      "train loss:0.003270357904066569\n",
      "train loss:0.0020088120355460704\n",
      "train loss:0.0013575314093476395\n",
      "train loss:0.0037576066813082526\n",
      "train loss:0.00432507965736509\n",
      "train loss:0.003959155940470686\n",
      "train loss:0.0004988690871252154\n",
      "train loss:0.0013546586726374118\n",
      "train loss:0.00048656906680736293\n",
      "train loss:0.000425034831433866\n",
      "train loss:0.0035476015292571213\n",
      "train loss:0.0003032115636484732\n",
      "train loss:0.007257639296300652\n",
      "train loss:0.0010590215173313532\n",
      "train loss:0.00038211066205280474\n",
      "train loss:0.00015885656988129943\n",
      "train loss:0.0009503360225108577\n",
      "train loss:0.0011568654891274358\n",
      "train loss:0.008489605933496559\n",
      "train loss:0.004033664574927867\n",
      "train loss:0.014630644488748689\n",
      "train loss:0.005838133714458467\n",
      "train loss:0.006359740216346836\n",
      "train loss:0.00015195391331200025\n",
      "train loss:0.0012472552321853314\n",
      "train loss:0.004021821134402654\n",
      "train loss:0.005915926533427002\n",
      "train loss:0.009923945426422697\n",
      "train loss:0.024293888551766552\n",
      "train loss:0.0035611422003443234\n",
      "train loss:0.00025859615734335914\n",
      "train loss:0.01711634027405624\n",
      "train loss:0.004270955329590054\n",
      "train loss:0.05750980472826592\n",
      "train loss:0.0011996368991065876\n",
      "train loss:0.006076626345863832\n",
      "train loss:0.016914181303262624\n",
      "train loss:0.00180023258506608\n",
      "train loss:0.0019255767884736972\n",
      "train loss:0.0035182308224935618\n",
      "train loss:0.006598543845216178\n",
      "train loss:0.003345777333665851\n",
      "train loss:0.006510393970725305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0029159834803055766\n",
      "train loss:0.0012493719025703201\n",
      "train loss:0.005114225070462521\n",
      "train loss:0.0002774583353444735\n",
      "train loss:0.006445760942315323\n",
      "train loss:0.0029315932774239325\n",
      "train loss:0.0036026893922305294\n",
      "train loss:0.001343134418030001\n",
      "train loss:0.002673752524339119\n",
      "train loss:0.005341740293916009\n",
      "train loss:0.004451911726105626\n",
      "train loss:0.0007216167463359413\n",
      "train loss:0.005303616948307955\n",
      "train loss:0.0008683346349263747\n",
      "train loss:0.0014601696242048233\n",
      "train loss:0.0023217269326678337\n",
      "train loss:0.0008497061622526679\n",
      "train loss:0.0007780162486790301\n",
      "train loss:0.0049124717195159805\n",
      "train loss:0.0014397480208844485\n",
      "train loss:0.0031752930383228224\n",
      "train loss:0.0008807764897725996\n",
      "train loss:0.001829625815861844\n",
      "train loss:0.003117866377227347\n",
      "train loss:0.0028931225276488137\n",
      "train loss:0.008275776770972387\n",
      "train loss:0.007110017558075817\n",
      "train loss:0.0014622202677248577\n",
      "train loss:0.000521143449150184\n",
      "train loss:0.006879078867784616\n",
      "train loss:0.005684345489109016\n",
      "train loss:0.03408713522387215\n",
      "train loss:7.014283539200677e-05\n",
      "train loss:0.0030927026739919735\n",
      "train loss:0.010098642956241322\n",
      "train loss:0.0009771127931208416\n",
      "train loss:0.007129647208827511\n",
      "train loss:0.005577577618176835\n",
      "train loss:0.009837452913086256\n",
      "train loss:0.003131542760556377\n",
      "train loss:0.004152138170484331\n",
      "train loss:0.004121567981380787\n",
      "train loss:0.0013324483966057515\n",
      "train loss:0.006476336850642001\n",
      "train loss:0.007269288250599834\n",
      "train loss:0.03774349614415654\n",
      "train loss:0.004273535217648036\n",
      "train loss:0.005877586818980447\n",
      "train loss:0.0027913755137218698\n",
      "train loss:0.0003353653700223582\n",
      "train loss:0.0006590274198719141\n",
      "=== epoch:14, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.01052566110286621\n",
      "train loss:0.005988648247144688\n",
      "train loss:0.0037732194071263504\n",
      "train loss:0.0021055464251757295\n",
      "train loss:0.0015735502034113008\n",
      "train loss:0.01079569658337229\n",
      "train loss:0.0009321569279380385\n",
      "train loss:0.0049511498298215415\n",
      "train loss:0.0017950696209543813\n",
      "train loss:0.0038300632048321537\n",
      "train loss:0.0012284332733855003\n",
      "train loss:0.008333928236355872\n",
      "train loss:0.0008583538006437701\n",
      "train loss:0.007038846947792752\n",
      "train loss:0.001468663909136426\n",
      "train loss:0.010377524504312776\n",
      "train loss:0.01034980976449598\n",
      "train loss:0.0013012076666658707\n",
      "train loss:0.0007129885132282591\n",
      "train loss:0.0022987755187933033\n",
      "train loss:0.004732947785049611\n",
      "train loss:0.004250626218854689\n",
      "train loss:0.0013445361271932049\n",
      "train loss:0.0006255211096137616\n",
      "train loss:0.004638147660858975\n",
      "train loss:0.001907530655563461\n",
      "train loss:0.002143393004599094\n",
      "train loss:0.0001555849503499572\n",
      "train loss:0.0025122815758758603\n",
      "train loss:0.0012575064167309163\n",
      "train loss:0.0002063099587701264\n",
      "train loss:0.030381780633015366\n",
      "train loss:0.001013251753168543\n",
      "train loss:0.006805897189896703\n",
      "train loss:0.005190951089792947\n",
      "train loss:0.0038562587544074996\n",
      "train loss:0.0008907147426414053\n",
      "train loss:0.00019340798027994347\n",
      "train loss:0.0033908453217368077\n",
      "train loss:0.0005833762917369751\n",
      "train loss:0.025619291977778045\n",
      "train loss:0.004367258485631058\n",
      "train loss:0.01417521542286714\n",
      "train loss:0.00021193531926644147\n",
      "train loss:0.003666349380107221\n",
      "train loss:0.00217181498411967\n",
      "train loss:0.002394333523094057\n",
      "train loss:0.0015484014969354353\n",
      "train loss:0.004026816030712936\n",
      "train loss:0.0021389079876528304\n",
      "train loss:0.006587832895465757\n",
      "train loss:0.000743488153220472\n",
      "train loss:0.026918568245927386\n",
      "train loss:0.0017228469519039425\n",
      "train loss:0.0014918683044837975\n",
      "train loss:0.00046776460202394926\n",
      "train loss:0.0011128737842511117\n",
      "train loss:0.003523944077750128\n",
      "train loss:0.005317149743789145\n",
      "train loss:0.00784135333211607\n",
      "train loss:0.005887511657008912\n",
      "train loss:0.00012277581164783742\n",
      "train loss:0.0012041213456434178\n",
      "train loss:0.00689871355486244\n",
      "train loss:0.0020101256030898166\n",
      "train loss:0.0013821302622714297\n",
      "train loss:0.015255990319093382\n",
      "train loss:0.0072359458533733855\n",
      "train loss:0.0030660709493793947\n",
      "train loss:0.015694563909185603\n",
      "train loss:0.016443195137369113\n",
      "train loss:0.00024986778087862\n",
      "train loss:0.00014363505939301316\n",
      "train loss:0.004337701618369572\n",
      "train loss:0.00028158365044713655\n",
      "train loss:0.009530782198513905\n",
      "train loss:0.004391652079761121\n",
      "train loss:0.0032445678268859814\n",
      "train loss:0.0122842469547798\n",
      "train loss:0.002000823487917752\n",
      "train loss:0.005865746840074396\n",
      "train loss:0.0030741300320144853\n",
      "train loss:0.1434326950380492\n",
      "train loss:0.006291682901238557\n",
      "train loss:0.005197183102057623\n",
      "train loss:0.008768019006927967\n",
      "train loss:0.003108268929792224\n",
      "train loss:0.005392594713924621\n",
      "train loss:0.008837365803647992\n",
      "train loss:0.0038052145680490834\n",
      "train loss:0.003528813987730207\n",
      "train loss:0.0010249351846998535\n",
      "train loss:0.002238088316970843\n",
      "train loss:0.00223762653746129\n",
      "train loss:0.006379404025245023\n",
      "train loss:0.0013875660845313529\n",
      "train loss:0.0014363152807519142\n",
      "train loss:0.013450145648817864\n",
      "train loss:0.003207218256288868\n",
      "train loss:0.00047428901486644957\n",
      "train loss:0.016894430943207327\n",
      "train loss:0.00616388037848555\n",
      "train loss:0.0007607807435921568\n",
      "train loss:0.002432632926156383\n",
      "train loss:0.0013925496631104375\n",
      "train loss:0.002039230265357013\n",
      "train loss:0.013102379401639339\n",
      "train loss:0.0008672856198992103\n",
      "train loss:0.004765249806185774\n",
      "train loss:0.002258613359501969\n",
      "train loss:0.0006072343824178849\n",
      "train loss:0.0010852056434434577\n",
      "train loss:0.00883230407884286\n",
      "train loss:0.001685318846114403\n",
      "train loss:0.00773552265943288\n",
      "train loss:0.0345168550501062\n",
      "train loss:0.0005636496892484568\n",
      "train loss:0.00235831302709843\n",
      "train loss:0.002771009383320257\n",
      "train loss:0.002209226836060387\n",
      "train loss:0.002158577231931556\n",
      "train loss:0.0025231930455680306\n",
      "train loss:0.0014700114104988368\n",
      "train loss:0.004329516505434694\n",
      "train loss:0.006296983539212308\n",
      "train loss:0.0012479525420311163\n",
      "train loss:0.0004909939900010959\n",
      "train loss:0.0029364714406991147\n",
      "train loss:0.0007602338141502071\n",
      "train loss:0.0058752537280174185\n",
      "train loss:0.0025482221032460377\n",
      "train loss:0.003218584618753142\n",
      "train loss:0.003327939626987619\n",
      "train loss:0.00170413879673501\n",
      "train loss:0.0034306102629408516\n",
      "train loss:0.0004168287648972904\n",
      "train loss:0.007363393618288491\n",
      "train loss:0.0037369761818869395\n",
      "train loss:0.007505872973896809\n",
      "train loss:0.0032168855449959044\n",
      "train loss:0.003288887591333357\n",
      "train loss:0.00023526752574440368\n",
      "train loss:0.002191247669448114\n",
      "train loss:0.0008587768957026016\n",
      "train loss:0.0010443154939737348\n",
      "train loss:0.06917155884334372\n",
      "train loss:0.002058947807076787\n",
      "train loss:0.000530875837457451\n",
      "train loss:0.004084191753917237\n",
      "train loss:0.002350364028817295\n",
      "train loss:0.0025707076368908454\n",
      "train loss:0.0015239937655795218\n",
      "train loss:0.0009147897162335269\n",
      "train loss:0.006756666061213889\n",
      "train loss:0.0008001979724986095\n",
      "train loss:0.008503217967501413\n",
      "train loss:0.010288823570096401\n",
      "train loss:0.004134844687344747\n",
      "train loss:0.0026249612352167383\n",
      "train loss:0.00376561022473655\n",
      "train loss:0.0008093533164872067\n",
      "train loss:0.0009519981268262331\n",
      "train loss:0.0005316364158284742\n",
      "train loss:0.00042256425049678656\n",
      "train loss:0.004534476751080808\n",
      "train loss:0.006247675919013838\n",
      "train loss:0.0025542927994364256\n",
      "train loss:0.00073255929715685\n",
      "train loss:0.0005796251262336887\n",
      "train loss:0.0017750831613332339\n",
      "train loss:0.0014743409516776705\n",
      "train loss:0.0025402626372168905\n",
      "train loss:0.0007986346388440868\n",
      "train loss:0.006996149998167636\n",
      "train loss:0.0008696591131811547\n",
      "train loss:0.005299904709757658\n",
      "train loss:0.003925983238549223\n",
      "train loss:0.00401369707531881\n",
      "train loss:0.0007319927635495527\n",
      "train loss:0.007354705714278958\n",
      "train loss:0.000360347041764329\n",
      "train loss:0.0016299279985123164\n",
      "train loss:0.008755790464904429\n",
      "train loss:0.001748060980971948\n",
      "train loss:0.0012772986392901213\n",
      "train loss:0.0016333933702274645\n",
      "train loss:0.00599414702778845\n",
      "train loss:0.0005319765518695652\n",
      "train loss:0.0026433346930326233\n",
      "train loss:0.002425818923195856\n",
      "train loss:0.0001695524134982521\n",
      "train loss:0.0010910234051369416\n",
      "train loss:0.005950550462915763\n",
      "train loss:0.001115821381896505\n",
      "train loss:0.0016956095156711792\n",
      "train loss:0.010575770799804186\n",
      "train loss:0.0006721569781692753\n",
      "train loss:0.0017880866176507534\n",
      "train loss:0.0006719013108478068\n",
      "train loss:0.007306407033691673\n",
      "train loss:0.001774481466319264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0055481717860120265\n",
      "train loss:0.0007016050100017557\n",
      "train loss:0.006585971170064899\n",
      "train loss:0.01925585973978723\n",
      "train loss:0.001307910263501333\n",
      "train loss:0.0007093172514844742\n",
      "train loss:0.00044435817371685937\n",
      "train loss:0.005070304169790808\n",
      "train loss:0.0006172396256378238\n",
      "train loss:0.0071645393984745955\n",
      "train loss:0.0005980363305823711\n",
      "train loss:0.004105578182198165\n",
      "train loss:0.006705140040407843\n",
      "train loss:0.0035346708559733844\n",
      "train loss:0.004251580478280715\n",
      "train loss:0.0009676128965697164\n",
      "train loss:0.010063716485290515\n",
      "train loss:0.00030853253768273073\n",
      "train loss:0.001426456420296096\n",
      "train loss:0.010534072144396023\n",
      "train loss:0.006664135210447194\n",
      "train loss:0.0001171204106244144\n",
      "train loss:0.0022869772887974395\n",
      "train loss:0.0012741552611501455\n",
      "train loss:0.00514058172814189\n",
      "train loss:0.003127874516434308\n",
      "train loss:0.0054347770581191735\n",
      "train loss:0.0013476168357187588\n",
      "train loss:0.002821955225630363\n",
      "train loss:0.0008498180051683917\n",
      "train loss:0.0033755074807590695\n",
      "train loss:0.005518652120878783\n",
      "train loss:0.00037670164321055915\n",
      "train loss:0.004764484595633844\n",
      "train loss:0.0005298275482681024\n",
      "train loss:0.005455266951978881\n",
      "train loss:0.0008006610583458244\n",
      "train loss:0.00032332390869771834\n",
      "train loss:0.0002697867008225359\n",
      "train loss:0.0006602802991114748\n",
      "train loss:0.0003849632047424131\n",
      "train loss:0.0009770368579543962\n",
      "train loss:0.006726710988312041\n",
      "train loss:0.0013376682966687531\n",
      "train loss:0.004115482177814238\n",
      "train loss:0.00123238230397976\n",
      "train loss:0.0018764156804968034\n",
      "train loss:0.00027267166503228206\n",
      "train loss:0.017774288275819165\n",
      "train loss:0.00011678350556094333\n",
      "train loss:0.0023401616386638695\n",
      "train loss:0.003872486101926913\n",
      "train loss:0.0010160643447635195\n",
      "train loss:0.001988397589402432\n",
      "train loss:0.006396714380753898\n",
      "train loss:0.00146671551927503\n",
      "train loss:0.0004061611564854788\n",
      "train loss:0.007262442652486607\n",
      "train loss:0.002717056144166016\n",
      "train loss:0.00834341147631787\n",
      "train loss:0.000646119602597261\n",
      "train loss:0.001346244392076415\n",
      "train loss:0.0014811394331874512\n",
      "train loss:0.0013035211992930484\n",
      "train loss:0.004172870425551129\n",
      "train loss:0.00491916479640175\n",
      "train loss:0.003088256750864674\n",
      "train loss:0.004651573233217303\n",
      "train loss:0.0020795121393632236\n",
      "train loss:0.004639343316441612\n",
      "train loss:0.0014988037689596515\n",
      "train loss:0.0012715508019865021\n",
      "train loss:0.004190290440959162\n",
      "train loss:0.01056700824093687\n",
      "train loss:0.00016349942046473936\n",
      "train loss:0.0011679039347727502\n",
      "train loss:0.00012448815211795394\n",
      "train loss:0.004909765135554547\n",
      "train loss:0.0007812303818638168\n",
      "train loss:0.0006145156964288303\n",
      "train loss:0.000666469204526892\n",
      "train loss:0.0033573878051115554\n",
      "train loss:0.008363731755123631\n",
      "train loss:0.0014859561690768633\n",
      "train loss:0.00012225170709031288\n",
      "train loss:0.0014969498176118398\n",
      "train loss:0.005264441715528164\n",
      "train loss:0.002851397391270834\n",
      "train loss:0.007601699442074774\n",
      "train loss:0.00018071122185023603\n",
      "train loss:0.002877729290900444\n",
      "train loss:0.005055671630328516\n",
      "train loss:0.001453968450847523\n",
      "train loss:0.00022445167666231052\n",
      "train loss:0.0005220020819636348\n",
      "train loss:0.00016016637860395998\n",
      "train loss:0.004687139962821905\n",
      "train loss:0.0010222994501755261\n",
      "train loss:0.0031663252197643168\n",
      "train loss:0.005081318768772389\n",
      "train loss:0.0044816272432908364\n",
      "train loss:0.00164937543054351\n",
      "train loss:0.005722425023628856\n",
      "train loss:0.010083386194226216\n",
      "train loss:0.020391253604834382\n",
      "train loss:0.0036646167566402126\n",
      "train loss:0.0019253175578581535\n",
      "train loss:0.0006880196227389423\n",
      "train loss:0.002417488642815478\n",
      "train loss:0.004970745788369736\n",
      "train loss:0.002997783795621688\n",
      "train loss:0.000648093907328843\n",
      "train loss:0.0018408675947102532\n",
      "train loss:0.0024627644964553544\n",
      "train loss:0.0012651967813679527\n",
      "train loss:0.0034018560778593214\n",
      "train loss:0.008081329268309121\n",
      "train loss:0.003468353411009037\n",
      "train loss:0.001980468560505009\n",
      "train loss:0.00022313280241804116\n",
      "train loss:0.0041512454651909956\n",
      "train loss:0.0028026440604601312\n",
      "train loss:0.002100943522879958\n",
      "train loss:0.003644856606838732\n",
      "train loss:0.002235547817710637\n",
      "train loss:0.003740807891045141\n",
      "train loss:0.000540256024544748\n",
      "train loss:0.002022063764971433\n",
      "train loss:0.002280015877431536\n",
      "train loss:0.0030360808426422355\n",
      "train loss:0.0038092062392679343\n",
      "train loss:0.003394305224194911\n",
      "train loss:0.0026881139215221496\n",
      "train loss:0.0021873122156470287\n",
      "train loss:0.0034634313457919553\n",
      "train loss:0.0010633922027804953\n",
      "train loss:0.0011277590076006396\n",
      "train loss:0.003884909885413472\n",
      "train loss:0.001234743011139273\n",
      "train loss:0.0006474952256135482\n",
      "train loss:0.002055971928845578\n",
      "train loss:0.002651129990805878\n",
      "train loss:0.0014754780240043988\n",
      "train loss:0.0005434799575700644\n",
      "train loss:0.006442905352703705\n",
      "train loss:0.003776227085854922\n",
      "train loss:0.0018006893495105148\n",
      "train loss:0.026578070424954456\n",
      "train loss:0.0003732778604391529\n",
      "train loss:0.000657869947259316\n",
      "train loss:0.001571516038956962\n",
      "train loss:0.00043714312446469487\n",
      "train loss:0.004317936121649358\n",
      "train loss:0.0002792175403263013\n",
      "train loss:0.0022292936091002262\n",
      "train loss:0.00043885587961698216\n",
      "train loss:0.001335285116313598\n",
      "train loss:0.00018956696363053835\n",
      "train loss:0.001791417431834311\n",
      "train loss:0.0006675561122355783\n",
      "train loss:0.008692161557469973\n",
      "train loss:0.003939752705999532\n",
      "train loss:0.00012221146130960987\n",
      "train loss:0.004925306669537776\n",
      "train loss:0.0004966925840859295\n",
      "train loss:0.00010822257824349627\n",
      "train loss:0.002430343119953374\n",
      "train loss:0.00261452221474275\n",
      "train loss:0.00527477410973435\n",
      "train loss:0.0028475094825670083\n",
      "train loss:0.013914489262595054\n",
      "train loss:0.0012774510375318077\n",
      "train loss:0.0006156113444576171\n",
      "train loss:0.003859236363137026\n",
      "train loss:0.029355488680720493\n",
      "train loss:0.0027619056067637975\n",
      "train loss:0.0005409341503413822\n",
      "train loss:0.0006353240205245174\n",
      "train loss:0.0012436729817413082\n",
      "train loss:0.0006384818637957232\n",
      "train loss:0.0007820233615359468\n",
      "train loss:0.001405456424988966\n",
      "train loss:0.0020915284483326337\n",
      "train loss:0.005621305448413907\n",
      "train loss:0.0015055017222082162\n",
      "train loss:0.018685602091050187\n",
      "train loss:0.0008864765737670445\n",
      "train loss:0.0016948017563513417\n",
      "train loss:0.005141180258931118\n",
      "train loss:0.0022824780654390766\n",
      "train loss:0.002196578568725777\n",
      "train loss:0.003167512568739856\n",
      "train loss:0.0001621475941521875\n",
      "train loss:0.0013324423273201474\n",
      "train loss:0.00027054555524972355\n",
      "train loss:0.0035897443116935206\n",
      "train loss:0.0003332648999264881\n",
      "train loss:0.003992102399654503\n",
      "train loss:0.0023578798678209104\n",
      "train loss:0.0005979775782437864\n",
      "train loss:0.00910506437842404\n",
      "train loss:0.0015277870474053542\n",
      "train loss:0.004262045068861909\n",
      "train loss:0.004177203871736534\n",
      "train loss:0.0001184474580321006\n",
      "train loss:0.0015028458277804026\n",
      "train loss:5.857564391775335e-05\n",
      "train loss:0.0033989663647656003\n",
      "train loss:0.001637798115096923\n",
      "train loss:0.003037166728110587\n",
      "train loss:0.0013773350674686914\n",
      "train loss:0.0010346286734920001\n",
      "train loss:0.00258871206685778\n",
      "train loss:0.04842401392733536\n",
      "train loss:0.0033155419013991237\n",
      "train loss:0.0003623973343555036\n",
      "train loss:0.002603752566928253\n",
      "train loss:0.00320260463829379\n",
      "train loss:0.0004020043976267266\n",
      "train loss:0.0032164439978355245\n",
      "train loss:0.001698846408506633\n",
      "train loss:0.006560167798711014\n",
      "train loss:0.0007345677386216846\n",
      "train loss:0.0020893744947759075\n",
      "train loss:0.0004779513976783007\n",
      "train loss:0.005256487980773111\n",
      "train loss:0.0011423291397772148\n",
      "train loss:0.001074633625246224\n",
      "train loss:0.007113173367588707\n",
      "train loss:0.005740650109127496\n",
      "train loss:0.0007463111746212006\n",
      "train loss:0.0035152403196019207\n",
      "train loss:0.00146582039982841\n",
      "train loss:0.00029203814581271596\n",
      "train loss:0.009482540338454833\n",
      "train loss:0.002170881149143435\n",
      "train loss:0.0019882544319637326\n",
      "train loss:0.002116934050866414\n",
      "train loss:0.003988408003915494\n",
      "train loss:0.0007313565166505414\n",
      "train loss:0.005946326388836849\n",
      "train loss:0.0011658568651752848\n",
      "train loss:0.016148355790204967\n",
      "train loss:0.0038236462940076914\n",
      "train loss:0.0011722416830431996\n",
      "train loss:0.0033639183424033613\n",
      "train loss:0.0002975051100920361\n",
      "train loss:0.001616332047330194\n",
      "train loss:0.0015820930760304592\n",
      "train loss:0.001473994205690131\n",
      "train loss:0.0008761109430092684\n",
      "train loss:0.0013176083994947587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011307998589922829\n",
      "train loss:0.0009713289794828897\n",
      "train loss:0.05732878191043974\n",
      "train loss:0.000901076477386555\n",
      "train loss:0.0008210708733189554\n",
      "train loss:0.0010039773590564264\n",
      "train loss:0.0014200777040924025\n",
      "train loss:0.008598610993963429\n",
      "train loss:0.0031815382092427046\n",
      "train loss:0.013122461596964136\n",
      "train loss:0.004852269050239633\n",
      "train loss:0.0011240404849331938\n",
      "train loss:0.002758684154948189\n",
      "train loss:0.000502853716373474\n",
      "train loss:0.0006404301637387409\n",
      "train loss:0.0027363138516892315\n",
      "train loss:0.0012563673390341644\n",
      "train loss:0.0026703162899961138\n",
      "train loss:0.001051918168712165\n",
      "train loss:0.0018478356726184398\n",
      "train loss:0.0021952799055112906\n",
      "train loss:0.0016376877982930357\n",
      "train loss:0.0029931239723705906\n",
      "train loss:0.0006658085711078388\n",
      "train loss:0.0004512047015877871\n",
      "train loss:0.0026549935033956394\n",
      "train loss:0.005646552280630152\n",
      "train loss:0.00263397876240144\n",
      "train loss:0.0020100309405400967\n",
      "train loss:0.018876925649889905\n",
      "train loss:0.005115949182185659\n",
      "train loss:0.00038363862395441125\n",
      "train loss:0.0005887335043664943\n",
      "train loss:0.0019892436057151143\n",
      "train loss:0.011377257565636708\n",
      "train loss:0.002499470175635974\n",
      "train loss:0.0005081566317386032\n",
      "train loss:0.002416509570683894\n",
      "train loss:0.019443032412491623\n",
      "train loss:0.015346259013445019\n",
      "train loss:0.0199580522248845\n",
      "train loss:0.005516590967822835\n",
      "train loss:0.0047651767790952565\n",
      "train loss:0.0017032570969776233\n",
      "train loss:0.0019099140187239837\n",
      "train loss:0.002058378525466211\n",
      "train loss:0.0018451856684796363\n",
      "train loss:0.010794961487263048\n",
      "train loss:0.00015142464880089785\n",
      "train loss:0.002843600676463002\n",
      "train loss:0.00143198399708316\n",
      "train loss:0.045658554906567256\n",
      "train loss:0.006346517393057923\n",
      "train loss:0.009065913476102892\n",
      "train loss:0.0009119602872829219\n",
      "train loss:0.0021132989506458116\n",
      "train loss:0.0037837196586560924\n",
      "train loss:0.0006103354534926997\n",
      "train loss:0.012976504774013303\n",
      "train loss:0.0014822099822300225\n",
      "train loss:0.0005965832474817264\n",
      "train loss:0.0007733885686928209\n",
      "train loss:0.0007334263904131694\n",
      "train loss:0.00803859002563422\n",
      "train loss:0.003159602921451844\n",
      "train loss:0.006253530861895663\n",
      "train loss:0.0038314109248971267\n",
      "train loss:0.020695373785704452\n",
      "train loss:0.0036591312027232977\n",
      "train loss:0.013293351969515074\n",
      "train loss:0.001552394716335643\n",
      "train loss:0.00010134415951671007\n",
      "train loss:0.0007917824155283676\n",
      "train loss:0.0013546125721497315\n",
      "train loss:0.0007761213810709372\n",
      "train loss:0.0026000659520252134\n",
      "train loss:0.0023330167763179464\n",
      "train loss:0.001968781787221453\n",
      "train loss:0.0010820841898388429\n",
      "train loss:0.00040985885540705674\n",
      "train loss:0.003620491335816301\n",
      "train loss:0.001097164028563218\n",
      "train loss:0.003778301049881143\n",
      "train loss:0.0017585618813830228\n",
      "train loss:0.03540148193947421\n",
      "train loss:0.005415128892616611\n",
      "train loss:0.011404667476848271\n",
      "train loss:0.0023825780076932247\n",
      "train loss:0.0016740233120594535\n",
      "train loss:0.0023202254198602342\n",
      "train loss:0.004415917738552887\n",
      "train loss:0.024312127150924904\n",
      "train loss:0.003917971832657481\n",
      "train loss:0.00027895902797705303\n",
      "train loss:0.004552489970096083\n",
      "train loss:0.011863156098849503\n",
      "train loss:0.002649150735376431\n",
      "train loss:0.0022782051493645053\n",
      "train loss:0.015358052745134259\n",
      "train loss:0.005316603752015738\n",
      "train loss:0.0018464033944870725\n",
      "train loss:0.0003474317593846108\n",
      "train loss:0.0010983015331383005\n",
      "train loss:0.002469283382270883\n",
      "train loss:0.006763370782811633\n",
      "train loss:0.001501141286435735\n",
      "train loss:0.0013596402282561367\n",
      "train loss:0.0016680638824301283\n",
      "train loss:0.01078791198885576\n",
      "train loss:0.004685327759777218\n",
      "train loss:0.013217286072075611\n",
      "train loss:0.0024822106790586052\n",
      "train loss:0.004550769077851183\n",
      "train loss:0.026944570804000288\n",
      "train loss:0.003722420714693065\n",
      "train loss:0.0004409223943011973\n",
      "train loss:0.0031421699480722754\n",
      "train loss:0.0003705720718094013\n",
      "train loss:0.004935963120194093\n",
      "train loss:0.009802240463636884\n",
      "train loss:0.0009745783851284256\n",
      "train loss:0.0006361988144465897\n",
      "train loss:0.0035235856746556127\n",
      "train loss:0.013856926430195331\n",
      "train loss:0.002203138273815596\n",
      "train loss:0.004943050134177217\n",
      "train loss:0.0025087602134054605\n",
      "train loss:0.0411884429993856\n",
      "train loss:0.0004891394659899053\n",
      "train loss:0.008029636269483937\n",
      "train loss:0.0026829300301246094\n",
      "train loss:0.002605410154555588\n",
      "train loss:0.002062772672667455\n",
      "train loss:0.007071603081731662\n",
      "train loss:0.0018849384659693266\n",
      "train loss:0.0035978635502769253\n",
      "train loss:0.005521281323714547\n",
      "train loss:0.0042125997935619185\n",
      "train loss:0.0019365723530461606\n",
      "train loss:0.0002444575054794762\n",
      "train loss:0.00017829765600264717\n",
      "train loss:0.000754204244333584\n",
      "train loss:0.0007437060902246068\n",
      "train loss:0.0010162541577563\n",
      "train loss:0.0055431962063060645\n",
      "train loss:0.00926031384409551\n",
      "train loss:0.016604712574452184\n",
      "=== epoch:15, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.004844090086646385\n",
      "train loss:0.0110496329020301\n",
      "train loss:0.00030885117678565313\n",
      "train loss:0.0006257742248891013\n",
      "train loss:0.008690534453251346\n",
      "train loss:0.0027955190182382354\n",
      "train loss:0.012714365879916383\n",
      "train loss:0.002850231749575192\n",
      "train loss:0.0015810645652109387\n",
      "train loss:0.00031148755374423845\n",
      "train loss:0.0017790916100261472\n",
      "train loss:0.0006035431668567166\n",
      "train loss:0.0003115334639561495\n",
      "train loss:0.013340369649558387\n",
      "train loss:0.0017372213321376145\n",
      "train loss:0.013838429629636037\n",
      "train loss:0.0037537290467991495\n",
      "train loss:0.0007516049140951687\n",
      "train loss:0.001154530777181471\n",
      "train loss:0.0018909544412554918\n",
      "train loss:0.008972331195323736\n",
      "train loss:0.001609652402758388\n",
      "train loss:0.00029667639601149975\n",
      "train loss:0.0012003062156969136\n",
      "train loss:0.00029884403191019095\n",
      "train loss:0.002107090152368031\n",
      "train loss:0.003043212183416845\n",
      "train loss:0.0003906346154938817\n",
      "train loss:0.0027563314807399746\n",
      "train loss:0.001057387703782601\n",
      "train loss:0.0007560362990022392\n",
      "train loss:0.0038880109064106977\n",
      "train loss:0.0015344808532091199\n",
      "train loss:0.0017093035341856993\n",
      "train loss:0.0015481459397390968\n",
      "train loss:0.001188486328330301\n",
      "train loss:0.0003807550739297559\n",
      "train loss:0.0012966719977031051\n",
      "train loss:0.004849585051465368\n",
      "train loss:0.00043484091617540066\n",
      "train loss:0.0008004542097000963\n",
      "train loss:0.00793570104395196\n",
      "train loss:0.0020361056104886586\n",
      "train loss:0.002062056856807735\n",
      "train loss:0.0002629635504915899\n",
      "train loss:0.0004079734391404504\n",
      "train loss:0.0008317606999047663\n",
      "train loss:0.000923662076860069\n",
      "train loss:0.0018804793251054718\n",
      "train loss:0.005986695899547137\n",
      "train loss:0.0006238345837412311\n",
      "train loss:0.0006568701742827686\n",
      "train loss:0.01538113904929619\n",
      "train loss:0.004250040613716221\n",
      "train loss:0.0005402575254131016\n",
      "train loss:0.0015987021408233458\n",
      "train loss:0.0075525834706862425\n",
      "train loss:0.00011905681453011612\n",
      "train loss:0.00018195719812906367\n",
      "train loss:0.0009678067489890954\n",
      "train loss:0.00015816505914351464\n",
      "train loss:0.001088623367322816\n",
      "train loss:0.00437119249746525\n",
      "train loss:0.005794345183576735\n",
      "train loss:0.00321409722325372\n",
      "train loss:0.0022863776721613323\n",
      "train loss:0.0033936734952879134\n",
      "train loss:0.013174445824697265\n",
      "train loss:0.0013077607215589446\n",
      "train loss:0.0007672114104915251\n",
      "train loss:0.0014340410347394048\n",
      "train loss:0.0010267853319247354\n",
      "train loss:0.0002353041465067164\n",
      "train loss:0.0017159654367188359\n",
      "train loss:0.0009738830672919426\n",
      "train loss:0.001254306755043704\n",
      "train loss:0.0009812491313873591\n",
      "train loss:0.0012353564257310894\n",
      "train loss:0.004051551926927016\n",
      "train loss:0.00027530617558459267\n",
      "train loss:0.003573870319600112\n",
      "train loss:0.0031803401756389186\n",
      "train loss:0.00020417564778400728\n",
      "train loss:0.0024676524204072232\n",
      "train loss:0.006341272578415654\n",
      "train loss:0.001437517024603609\n",
      "train loss:0.00030117281689400973\n",
      "train loss:0.0019918884054301077\n",
      "train loss:7.399597070573218e-05\n",
      "train loss:0.007702602801675829\n",
      "train loss:0.0015577898758529177\n",
      "train loss:0.0011915193031596571\n",
      "train loss:0.0007686434368280541\n",
      "train loss:0.004307592185160663\n",
      "train loss:0.03155328466572467\n",
      "train loss:0.0033550704533530516\n",
      "train loss:0.0003662025761471525\n",
      "train loss:0.0008373916242044857\n",
      "train loss:0.0010988527817363922\n",
      "train loss:0.004428842857314114\n",
      "train loss:0.0043680219940753755\n",
      "train loss:0.002223727999964944\n",
      "train loss:0.00173636468725226\n",
      "train loss:0.0010835028422086304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016907394202062447\n",
      "train loss:0.007665275672296504\n",
      "train loss:0.0015821892664162865\n",
      "train loss:0.00037170503532253055\n",
      "train loss:0.0002620199052012624\n",
      "train loss:0.0018888940634303514\n",
      "train loss:0.0052132201861018425\n",
      "train loss:0.0036595804506031437\n",
      "train loss:0.002083993963766473\n",
      "train loss:0.0011859162778643385\n",
      "train loss:0.0005664855244768284\n",
      "train loss:0.0012230372728708903\n",
      "train loss:0.003071942533057446\n",
      "train loss:0.005723420460450406\n",
      "train loss:0.005243232402739811\n",
      "train loss:0.0013524679251422497\n",
      "train loss:0.0007606915720840819\n",
      "train loss:0.001596013906230801\n",
      "train loss:5.9820316296433204e-05\n",
      "train loss:0.000778575154279767\n",
      "train loss:0.0006500449531595127\n",
      "train loss:0.00039467311924568213\n",
      "train loss:0.003546543575775395\n",
      "train loss:0.0018635638061961592\n",
      "train loss:0.008210802828866298\n",
      "train loss:0.0019360951322288777\n",
      "train loss:0.0009676702510890273\n",
      "train loss:0.0013609385021150244\n",
      "train loss:0.0032650574592094188\n",
      "train loss:0.001379928787999117\n",
      "train loss:0.004068784054481809\n",
      "train loss:0.005754279046649357\n",
      "train loss:0.0029686928601864535\n",
      "train loss:0.003895635563827057\n",
      "train loss:0.0020912652814091266\n",
      "train loss:0.0003828352911808635\n",
      "train loss:0.006190192642009529\n",
      "train loss:0.0018014291455050587\n",
      "train loss:0.0002141160923015609\n",
      "train loss:0.012414888433957282\n",
      "train loss:0.0007849747441979189\n",
      "train loss:0.001744222788187585\n",
      "train loss:0.0002501234180994592\n",
      "train loss:0.0005008592610762021\n",
      "train loss:0.0011792318719452328\n",
      "train loss:0.002600067909401801\n",
      "train loss:0.00051551587461758\n",
      "train loss:0.0031113868867295035\n",
      "train loss:0.0049290089223032315\n",
      "train loss:0.00014690584169591004\n",
      "train loss:0.0029414087023293682\n",
      "train loss:0.001977557313819359\n",
      "train loss:0.0030408249456065155\n",
      "train loss:0.00023508722957069333\n",
      "train loss:0.0022990388377003364\n",
      "train loss:0.0002649342239798863\n",
      "train loss:0.00034001045102632395\n",
      "train loss:0.003704586817317854\n",
      "train loss:0.0027783939297874455\n",
      "train loss:0.00044084206784064206\n",
      "train loss:0.0029856558631335328\n",
      "train loss:0.005364716936535828\n",
      "train loss:0.0033282226362090026\n",
      "train loss:0.003767834528588661\n",
      "train loss:0.0049384252738117005\n",
      "train loss:0.000464689495675168\n",
      "train loss:0.0011136655136715786\n",
      "train loss:0.0012964648327288006\n",
      "train loss:0.008426354546491635\n",
      "train loss:0.0018114646437088254\n",
      "train loss:0.010684081620718393\n",
      "train loss:0.0002481775374384471\n",
      "train loss:0.0019545660625696964\n",
      "train loss:0.006712401515918144\n",
      "train loss:0.004782338757729642\n",
      "train loss:0.004714158417810202\n",
      "train loss:0.01648770791841098\n",
      "train loss:0.0029269321329101\n",
      "train loss:0.002022528968945125\n",
      "train loss:0.0007883663689354077\n",
      "train loss:0.008208136708425382\n",
      "train loss:0.00033658339199416217\n",
      "train loss:0.013593211022883111\n",
      "train loss:0.007328580829420954\n",
      "train loss:0.0028204725801887136\n",
      "train loss:0.0016004299129657668\n",
      "train loss:0.004126041575916027\n",
      "train loss:0.0015755438594112956\n",
      "train loss:0.00375663372679508\n",
      "train loss:0.004911674099778884\n",
      "train loss:0.0002340039369072555\n",
      "train loss:0.003357391948158269\n",
      "train loss:0.0007466914120505353\n",
      "train loss:0.004149035237557254\n",
      "train loss:0.00532147747492501\n",
      "train loss:0.00564233193019726\n",
      "train loss:0.001331601970645887\n",
      "train loss:0.004629990104282677\n",
      "train loss:0.0041544480176668695\n",
      "train loss:0.0003437347921087809\n",
      "train loss:0.004093126134831317\n",
      "train loss:0.006031075965587102\n",
      "train loss:0.012822063875787064\n",
      "train loss:0.00044245116368718307\n",
      "train loss:0.0011447172723210988\n",
      "train loss:0.0010252769896498654\n",
      "train loss:0.0006789275604595413\n",
      "train loss:0.004217621935503173\n",
      "train loss:0.02600899776766004\n",
      "train loss:0.001059720717507517\n",
      "train loss:0.0023896531451001704\n",
      "train loss:0.001659033615825038\n",
      "train loss:0.003474999860907038\n",
      "train loss:0.005703511126966078\n",
      "train loss:0.002884560890755359\n",
      "train loss:0.0009620489693019552\n",
      "train loss:0.0032017921505781283\n",
      "train loss:0.0020444964447141525\n",
      "train loss:0.0018058641997220604\n",
      "train loss:0.002685829143924762\n",
      "train loss:0.004719637038297241\n",
      "train loss:0.00508355937965935\n",
      "train loss:0.0032604814355778893\n",
      "train loss:0.005083492836879719\n",
      "train loss:0.0008510264710456515\n",
      "train loss:0.006537134380325419\n",
      "train loss:0.003352234744145188\n",
      "train loss:0.007477232682687488\n",
      "train loss:7.394425224014562e-05\n",
      "train loss:0.0011377917717162516\n",
      "train loss:0.005026956346018443\n",
      "train loss:0.0027997892198996484\n",
      "train loss:0.00478653406880627\n",
      "train loss:0.0029611989637466207\n",
      "train loss:0.0004682316945858522\n",
      "train loss:0.005252460046882896\n",
      "train loss:0.0004186295732780383\n",
      "train loss:0.0008259955745286257\n",
      "train loss:0.002940015029990171\n",
      "train loss:0.004861085083495165\n",
      "train loss:0.0006082739959626938\n",
      "train loss:0.016139426404742748\n",
      "train loss:0.0025650049237935387\n",
      "train loss:0.005482288012878619\n",
      "train loss:0.0036762991231887206\n",
      "train loss:0.005988156016835977\n",
      "train loss:0.001475654245423934\n",
      "train loss:0.0028889744228133584\n",
      "train loss:0.0048685691858883625\n",
      "train loss:0.0005619332856811926\n",
      "train loss:0.0018347481538684776\n",
      "train loss:0.0018380436919810277\n",
      "train loss:0.00021859555370941936\n",
      "train loss:0.0009774356667539938\n",
      "train loss:0.014862789056074459\n",
      "train loss:0.004805726180427966\n",
      "train loss:0.0010080045244087378\n",
      "train loss:0.001955958911783503\n",
      "train loss:0.00636564300013364\n",
      "train loss:0.003253286415379875\n",
      "train loss:0.001829090737782827\n",
      "train loss:0.00816284485214035\n",
      "train loss:0.002051434850997648\n",
      "train loss:0.002207177344271698\n",
      "train loss:0.0015598270270016003\n",
      "train loss:0.0006531788648530764\n",
      "train loss:0.00023882182620926993\n",
      "train loss:0.0027830559764064618\n",
      "train loss:0.006767298882867398\n",
      "train loss:0.019090484622827097\n",
      "train loss:0.005965600604253236\n",
      "train loss:0.00010111341759263142\n",
      "train loss:0.0027822960322704078\n",
      "train loss:0.0049953367596428\n",
      "train loss:0.00047268330502084067\n",
      "train loss:0.00023560203310545082\n",
      "train loss:0.016372734992473773\n",
      "train loss:0.0047392397166071375\n",
      "train loss:0.0002651662068395983\n",
      "train loss:0.004469988255475911\n",
      "train loss:0.018228177593771214\n",
      "train loss:0.001977806020745143\n",
      "train loss:0.0029102318806580223\n",
      "train loss:0.004370461055419906\n",
      "train loss:0.004190715327359524\n",
      "train loss:0.00138190210420994\n",
      "train loss:0.002505942224759801\n",
      "train loss:0.0006349933918496292\n",
      "train loss:0.003612323459103472\n",
      "train loss:0.0016425063130119225\n",
      "train loss:0.0016036329859964212\n",
      "train loss:0.00502028495326021\n",
      "train loss:0.0013561585381504082\n",
      "train loss:0.005632712428549652\n",
      "train loss:0.0021938687631913784\n",
      "train loss:0.00014198387041072693\n",
      "train loss:0.001592254476853465\n",
      "train loss:0.0005609674696495839\n",
      "train loss:0.013524388665148743\n",
      "train loss:0.009092222692432456\n",
      "train loss:0.0003300735905850526\n",
      "train loss:0.001063773523856204\n",
      "train loss:0.0018861247885364047\n",
      "train loss:0.000335531685848521\n",
      "train loss:0.0009100729859633411\n",
      "train loss:0.0019564248294769984\n",
      "train loss:0.0042428782933715565\n",
      "train loss:0.0014522979854946977\n",
      "train loss:0.004461667125944754\n",
      "train loss:0.0041424285588427855\n",
      "train loss:0.0007641059191815329\n",
      "train loss:0.00868198449864121\n",
      "train loss:0.0002227094592864239\n",
      "train loss:0.0017794778771250965\n",
      "train loss:0.00015908368733856735\n",
      "train loss:0.005118566731692125\n",
      "train loss:0.003909925476060671\n",
      "train loss:0.0021799524616340467\n",
      "train loss:0.00025283177804628367\n",
      "train loss:0.00151774030162505\n",
      "train loss:0.0012544637076038535\n",
      "train loss:0.002582040065841154\n",
      "train loss:0.006319246888370433\n",
      "train loss:0.00040065175093654084\n",
      "train loss:0.008574248700161597\n",
      "train loss:0.003096866300980405\n",
      "train loss:0.0003862758091034261\n",
      "train loss:0.0008195821732367472\n",
      "train loss:0.00016103256963178862\n",
      "train loss:0.004066336439770929\n",
      "train loss:0.006708553976253577\n",
      "train loss:0.0012508714562423009\n",
      "train loss:0.002988590494323938\n",
      "train loss:0.00014109705253448373\n",
      "train loss:0.00012660938729139318\n",
      "train loss:0.00020691946014513254\n",
      "train loss:0.0008060279783871649\n",
      "train loss:0.016666875546227176\n",
      "train loss:0.00012428421239778068\n",
      "train loss:0.000644577506055818\n",
      "train loss:0.005990326884917554\n",
      "train loss:0.00235953156774138\n",
      "train loss:0.0023664702871467403\n",
      "train loss:0.0004491347899817078\n",
      "train loss:0.0013192210142054057\n",
      "train loss:0.0007578930061617628\n",
      "train loss:0.0013212188159450516\n",
      "train loss:0.031125912992846796\n",
      "train loss:0.02263615696367755\n",
      "train loss:0.0013560899123597995\n",
      "train loss:0.004327901676587827\n",
      "train loss:0.0009432173002982481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001619059310998617\n",
      "train loss:0.0016415727800315196\n",
      "train loss:0.002530911315097163\n",
      "train loss:0.007846691917246008\n",
      "train loss:0.002325308507170472\n",
      "train loss:0.013581255372307543\n",
      "train loss:0.0011896163090485126\n",
      "train loss:0.00010717737995235806\n",
      "train loss:0.0004978282711034847\n",
      "train loss:0.001404379449097931\n",
      "train loss:0.0028677284064438625\n",
      "train loss:0.0005276475710888816\n",
      "train loss:0.0005675831358657775\n",
      "train loss:0.006420556521229169\n",
      "train loss:0.00024570103512571\n",
      "train loss:0.0015224503583598065\n",
      "train loss:0.0009237683335878705\n",
      "train loss:0.00032365384124594647\n",
      "train loss:0.007458397796518547\n",
      "train loss:0.004070213276284389\n",
      "train loss:0.005059123091075469\n",
      "train loss:0.001137463489397037\n",
      "train loss:0.00043717877178797373\n",
      "train loss:0.009428583327397882\n",
      "train loss:0.0034474602431232527\n",
      "train loss:0.0013780095725155702\n",
      "train loss:0.004338675019006757\n",
      "train loss:0.00025075092351836415\n",
      "train loss:0.003579442436312452\n",
      "train loss:0.0014080302545980215\n",
      "train loss:0.0055528585399659755\n",
      "train loss:0.00041795629308734935\n",
      "train loss:0.00457521345452942\n",
      "train loss:0.0026669844944138764\n",
      "train loss:0.00234000309067569\n",
      "train loss:0.0013349745975372001\n",
      "train loss:0.0026870105151495433\n",
      "train loss:0.0012161668411052751\n",
      "train loss:0.0005320325109140197\n",
      "train loss:0.004764871055868631\n",
      "train loss:0.0009953954954990954\n",
      "train loss:0.00015752735784592558\n",
      "train loss:0.0015880464037783015\n",
      "train loss:0.009372200165108641\n",
      "train loss:0.0016430851394782673\n",
      "train loss:0.0010762753982086696\n",
      "train loss:0.005532344341001474\n",
      "train loss:0.0022019339382623555\n",
      "train loss:0.023971476841677265\n",
      "train loss:0.003632267910282663\n",
      "train loss:0.0013534441009119174\n",
      "train loss:0.00731708887276597\n",
      "train loss:0.0032695241999459463\n",
      "train loss:0.0004985180243591266\n",
      "train loss:0.00151334310024481\n",
      "train loss:0.001724111476961209\n",
      "train loss:0.005895127642138957\n",
      "train loss:0.0044582841896247056\n",
      "train loss:0.00042407397850744463\n",
      "train loss:0.0021377553485984317\n",
      "train loss:0.006472573198935605\n",
      "train loss:0.0046947949734238775\n",
      "train loss:0.0005325483034676326\n",
      "train loss:0.0015614781032021808\n",
      "train loss:0.00661069915613676\n",
      "train loss:0.003762331332734016\n",
      "train loss:8.230354108290744e-05\n",
      "train loss:0.005046311945221293\n",
      "train loss:0.00215033595666169\n",
      "train loss:0.0021749958781816527\n",
      "train loss:0.00040319633367198564\n",
      "train loss:0.0005712164001432283\n",
      "train loss:0.002711015569987712\n",
      "train loss:0.0012940451540124744\n",
      "train loss:0.002860052501560117\n",
      "train loss:0.001947415262836553\n",
      "train loss:0.002272493840097207\n",
      "train loss:0.00014217004473880744\n",
      "train loss:0.0031121626933518403\n",
      "train loss:0.0017194780452798179\n",
      "train loss:0.0002812427142351623\n",
      "train loss:0.005811206037849036\n",
      "train loss:0.005796725857822772\n",
      "train loss:0.0020804408289695746\n",
      "train loss:0.0004339185933688217\n",
      "train loss:0.0013130692505374042\n",
      "train loss:0.0044110810776052355\n",
      "train loss:0.0013317103714321162\n",
      "train loss:0.0031969963638031874\n",
      "train loss:0.0003712246893285341\n",
      "train loss:0.0006785636894554867\n",
      "train loss:0.003059701961848071\n",
      "train loss:0.00021918884289751209\n",
      "train loss:0.0013388675327911772\n",
      "train loss:0.00016610829267056057\n",
      "train loss:0.01085085340186621\n",
      "train loss:0.0009304555316204285\n",
      "train loss:0.0022260330419522894\n",
      "train loss:0.0022092093087283634\n",
      "train loss:3.243923432268048e-05\n",
      "train loss:0.0019270170755038153\n",
      "train loss:0.001654688968831319\n",
      "train loss:0.0009701900974102309\n",
      "train loss:0.0027916909907749047\n",
      "train loss:0.001709312015911785\n",
      "train loss:0.0037445204992011287\n",
      "train loss:0.013861779504531073\n",
      "train loss:0.0018726025644199553\n",
      "train loss:0.009266824145689247\n",
      "train loss:0.016412744450275005\n",
      "train loss:0.0021129614971812987\n",
      "train loss:0.0037141439426373614\n",
      "train loss:0.037018585618577335\n",
      "train loss:0.00015732886092584278\n",
      "train loss:0.032657053894260775\n",
      "train loss:0.004785617570004641\n",
      "train loss:0.0034087160700454417\n",
      "train loss:7.260681412398772e-05\n",
      "train loss:0.005435132918072428\n",
      "train loss:0.0016087305924813008\n",
      "train loss:0.00047273073453759626\n",
      "train loss:0.0041830501009644805\n",
      "train loss:0.0036227003983404023\n",
      "train loss:0.002529660894392392\n",
      "train loss:0.0015188156930364227\n",
      "train loss:0.0018051424459303558\n",
      "train loss:0.002948059008099472\n",
      "train loss:0.0003752263399446136\n",
      "train loss:0.0015899396883157068\n",
      "train loss:0.0018690456202618633\n",
      "train loss:0.0016065729549800392\n",
      "train loss:0.0007680598618613066\n",
      "train loss:0.0022745508162771303\n",
      "train loss:0.002381445227606265\n",
      "train loss:0.0016560435337396955\n",
      "train loss:0.003179899177492534\n",
      "train loss:0.0026900698189148546\n",
      "train loss:0.010351736763736154\n",
      "train loss:0.0014833961283206019\n",
      "train loss:0.00034468728972332594\n",
      "train loss:0.0006706884164541202\n",
      "train loss:8.320162280068274e-05\n",
      "train loss:0.006258226704040241\n",
      "train loss:0.0031624294460105102\n",
      "train loss:0.0027897766260376712\n",
      "train loss:0.0049761893324850705\n",
      "train loss:0.0023535256472657726\n",
      "train loss:0.002367111824516328\n",
      "train loss:0.009839774622442342\n",
      "train loss:0.00538496558310133\n",
      "train loss:0.0025656446248943014\n",
      "train loss:0.004285478813840054\n",
      "train loss:0.0004992870976294057\n",
      "train loss:0.0028673434940968616\n",
      "train loss:0.001570281479756713\n",
      "train loss:0.0053620574034313065\n",
      "train loss:0.003383076269361014\n",
      "train loss:0.00021997868829308476\n",
      "train loss:0.0014879808484254667\n",
      "train loss:0.0023292400838122985\n",
      "train loss:0.004572589400480181\n",
      "train loss:0.0022060487419364536\n",
      "train loss:0.0011627196566590765\n",
      "train loss:0.0014905153937003254\n",
      "train loss:0.0011078930853286157\n",
      "train loss:0.005919400556517399\n",
      "train loss:0.0021538378954910537\n",
      "train loss:0.0002861180216518657\n",
      "train loss:0.0018320736853250257\n",
      "train loss:0.002795519250908477\n",
      "train loss:0.002806381709877175\n",
      "train loss:0.0014269797643596221\n",
      "train loss:0.003872177800016972\n",
      "train loss:0.00021590355245444543\n",
      "train loss:0.0038550820232808496\n",
      "train loss:0.019775307492097854\n",
      "train loss:3.7235989238986264e-05\n",
      "train loss:0.0013263760387419157\n",
      "train loss:0.0016741782978612024\n",
      "train loss:0.001880235090294461\n",
      "train loss:0.0035420972444387315\n",
      "train loss:0.00246212931588533\n",
      "train loss:0.0027778376249977823\n",
      "train loss:0.0034704021111642475\n",
      "train loss:0.000994858836583214\n",
      "train loss:0.0011465946808313665\n",
      "train loss:0.027337796490283225\n",
      "train loss:0.005752079761184612\n",
      "train loss:0.0009586641813603452\n",
      "train loss:0.00021142760904923182\n",
      "train loss:0.0025148062434179924\n",
      "train loss:0.0012547932231721439\n",
      "train loss:0.0032774425164075445\n",
      "train loss:0.0019471535851427746\n",
      "train loss:0.0033776153519712152\n",
      "train loss:0.002561621924014764\n",
      "train loss:0.0005086144651242544\n",
      "train loss:0.002256307008414373\n",
      "train loss:0.004055683700426736\n",
      "train loss:0.001577520499406282\n",
      "train loss:0.012714376247043517\n",
      "train loss:0.002555877284441617\n",
      "train loss:0.0004100073705485065\n",
      "train loss:0.0047772132083071\n",
      "train loss:0.0014585624775488738\n",
      "train loss:0.0016920787266250295\n",
      "train loss:0.0031266979953125103\n",
      "train loss:0.005569340602308512\n",
      "train loss:0.0177765036792477\n",
      "train loss:0.00617930219544069\n",
      "train loss:0.0014655345087492794\n",
      "train loss:0.0010256937441387843\n",
      "train loss:0.0039662125396792945\n",
      "train loss:0.004625501220488476\n",
      "train loss:0.006378981921566681\n",
      "train loss:0.0026739131652231928\n",
      "train loss:0.014594223020885066\n",
      "train loss:0.0025007801218194497\n",
      "train loss:0.0045969491827984425\n",
      "train loss:0.0005396813790106171\n",
      "train loss:0.001505069714934325\n",
      "train loss:0.000851147640942449\n",
      "train loss:0.0010292514652789986\n",
      "train loss:0.003950710711810686\n",
      "train loss:0.006802978780031482\n",
      "train loss:0.0008089312383601104\n",
      "train loss:0.00016895301078670937\n",
      "train loss:0.005588472807183631\n",
      "train loss:0.0057419790245008965\n",
      "train loss:0.0011568108633089034\n",
      "train loss:0.0007795226933233058\n",
      "train loss:0.006098330663725529\n",
      "train loss:0.012676396227063028\n",
      "train loss:0.0015118096897922928\n",
      "train loss:0.002053667376070111\n",
      "train loss:0.030961323296010878\n",
      "train loss:0.0002836136957256741\n",
      "train loss:0.0007149875904882599\n",
      "train loss:0.0008754373106871126\n",
      "train loss:0.005111756427067403\n",
      "train loss:0.0008678225082886817\n",
      "train loss:0.0032613059668947213\n",
      "train loss:0.001288489527035541\n",
      "train loss:0.0016332214569399288\n",
      "=== epoch:16, train acc:0.994, test acc:0.984 ===\n",
      "train loss:0.0065108143218058825\n",
      "train loss:0.004730237592885954\n",
      "train loss:0.008039265436384788\n",
      "train loss:0.0021810853088817454\n",
      "train loss:0.001542283541611216\n",
      "train loss:0.035435171489742255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00195189590712007\n",
      "train loss:0.005152567104282122\n",
      "train loss:0.0035424365510776153\n",
      "train loss:0.0016915235784905594\n",
      "train loss:0.0015078382635749586\n",
      "train loss:0.0018154585841810747\n",
      "train loss:0.002840532938154487\n",
      "train loss:0.011394514137766387\n",
      "train loss:0.002648191599496181\n",
      "train loss:0.0034557146331894934\n",
      "train loss:0.002834111899334989\n",
      "train loss:0.0007701931116290879\n",
      "train loss:0.003696677601119211\n",
      "train loss:0.0005149520419569195\n",
      "train loss:0.00033571155378125565\n",
      "train loss:0.001470869366070594\n",
      "train loss:0.004166646039253433\n",
      "train loss:0.0027765105360695076\n",
      "train loss:0.001812476262802236\n",
      "train loss:0.0032745676237738736\n",
      "train loss:0.004443827939059259\n",
      "train loss:0.0027282638383852096\n",
      "train loss:0.001157499286635626\n",
      "train loss:0.0018061559600714378\n",
      "train loss:0.0006596701321367257\n",
      "train loss:0.0028846543208403785\n",
      "train loss:0.0013145431572768951\n",
      "train loss:0.0008368591587873045\n",
      "train loss:0.00023802652990546593\n",
      "train loss:0.0005839583795711107\n",
      "train loss:0.0002423009677627248\n",
      "train loss:0.0017383097447463797\n",
      "train loss:0.0002929604950551152\n",
      "train loss:0.007272784940585541\n",
      "train loss:0.005743127844656708\n",
      "train loss:0.004714613263109426\n",
      "train loss:0.0028824690611531797\n",
      "train loss:0.0007069682341722557\n",
      "train loss:0.00031847524778242715\n",
      "train loss:0.0016980025071053244\n",
      "train loss:0.0003198339773833271\n",
      "train loss:0.0019076881121373142\n",
      "train loss:0.0003376583341109856\n",
      "train loss:0.011740060072067713\n",
      "train loss:0.0002690184932894805\n",
      "train loss:0.002041130603539615\n",
      "train loss:0.0003530759658179274\n",
      "train loss:0.026758127011938443\n",
      "train loss:0.013837692344874936\n",
      "train loss:0.002581207949171943\n",
      "train loss:0.00451538542034016\n",
      "train loss:0.002232689610091125\n",
      "train loss:0.003146775706348328\n",
      "train loss:0.0022291341553709663\n",
      "train loss:0.0020176720818183445\n",
      "train loss:0.0018264303321603407\n",
      "train loss:0.0027945341483061516\n",
      "train loss:0.0012777276333784853\n",
      "train loss:0.012475995720500335\n",
      "train loss:0.002837390564510559\n",
      "train loss:0.0023585509720286187\n",
      "train loss:0.0059351644088650206\n",
      "train loss:0.0006608311146273435\n",
      "train loss:0.0072408575035907904\n",
      "train loss:0.0011139075937922818\n",
      "train loss:0.0016102712906768126\n",
      "train loss:0.00018401484517666748\n",
      "train loss:0.004781932526814987\n",
      "train loss:0.0016374524273494587\n",
      "train loss:0.00372410181596925\n",
      "train loss:0.0031485431762440772\n",
      "train loss:0.0008062233839287175\n",
      "train loss:0.00131897350754865\n",
      "train loss:0.0018449842222884175\n",
      "train loss:0.0007974769953217943\n",
      "train loss:3.0841696124473784e-05\n",
      "train loss:0.001820537382723919\n",
      "train loss:0.0005154459861718435\n",
      "train loss:0.000512300230645992\n",
      "train loss:0.0003526446040517928\n",
      "train loss:0.012011206757895916\n",
      "train loss:0.0006436785999015679\n",
      "train loss:0.001166101300553642\n",
      "train loss:0.0015857070635973813\n",
      "train loss:0.002831442045748748\n",
      "train loss:0.006449807995326824\n",
      "train loss:0.01962370480968443\n",
      "train loss:0.001583727088708597\n",
      "train loss:0.0009390111916754287\n",
      "train loss:0.0007611347595388049\n",
      "train loss:0.0010521546860274642\n",
      "train loss:0.0008877379921105224\n",
      "train loss:0.0016635084602731245\n",
      "train loss:0.0031466270092568786\n",
      "train loss:0.00046908920790964475\n",
      "train loss:0.006493014226025075\n",
      "train loss:0.0004923099154336458\n",
      "train loss:0.001124094936896077\n",
      "train loss:0.00351696363959323\n",
      "train loss:0.0067925735861553045\n",
      "train loss:0.059351473847586905\n",
      "train loss:0.0022419642329206298\n",
      "train loss:0.001067940026448068\n",
      "train loss:0.001295975050370142\n",
      "train loss:0.005202521793964937\n",
      "train loss:0.0012294569449360511\n",
      "train loss:0.0019983031656690196\n",
      "train loss:0.0016068398782128725\n",
      "train loss:0.014156210578637203\n",
      "train loss:0.00484863109719724\n",
      "train loss:0.003951796032573588\n",
      "train loss:0.004590476663708359\n",
      "train loss:0.005763200718972704\n",
      "train loss:0.0024434038875390295\n",
      "train loss:0.0003914210838845957\n",
      "train loss:0.003101455180142224\n",
      "train loss:0.003849065957871475\n",
      "train loss:0.01039824340851888\n",
      "train loss:0.000527631041898334\n",
      "train loss:0.0017052164188354013\n",
      "train loss:0.00017056846608984314\n",
      "train loss:0.006450345847613481\n",
      "train loss:0.003486241698594309\n",
      "train loss:0.0003866131023864896\n",
      "train loss:0.00032817631268026976\n",
      "train loss:0.00011582416688930253\n",
      "train loss:0.00537741318614474\n",
      "train loss:0.0006610466902397291\n",
      "train loss:0.0024859097824604277\n",
      "train loss:0.0008858672242493454\n",
      "train loss:0.0031907691948365245\n",
      "train loss:0.0012635409433660611\n",
      "train loss:0.0018388662112254648\n",
      "train loss:0.0058915759600007235\n",
      "train loss:0.003506599064114663\n",
      "train loss:0.00026366227687223495\n",
      "train loss:0.002912169405478586\n",
      "train loss:0.0036293468228620262\n",
      "train loss:0.006487857847260351\n",
      "train loss:0.0012863730316499387\n",
      "train loss:0.0005545398351113445\n",
      "train loss:0.0025693214400073884\n",
      "train loss:0.001650385954897007\n",
      "train loss:0.0037093160106737135\n",
      "train loss:0.003640768335489712\n",
      "train loss:0.0035045901014816787\n",
      "train loss:0.003034910579245398\n",
      "train loss:0.00011522426697375387\n",
      "train loss:0.002030665505262106\n",
      "train loss:0.0006000568268738405\n",
      "train loss:0.0006695495844353667\n",
      "train loss:0.0002488476129274056\n",
      "train loss:0.0014939625286761946\n",
      "train loss:0.0007846470597836473\n",
      "train loss:0.0049315797450327535\n",
      "train loss:0.008059824330703175\n",
      "train loss:0.005248206337766748\n",
      "train loss:0.005220832018512622\n",
      "train loss:0.0005191684342678237\n",
      "train loss:0.00219715458466674\n",
      "train loss:0.012830020917540057\n",
      "train loss:0.0006259529072351566\n",
      "train loss:0.00636778772518938\n",
      "train loss:0.029977841194933866\n",
      "train loss:0.0005177372121344933\n",
      "train loss:0.00034541901068821975\n",
      "train loss:0.003024592133990334\n",
      "train loss:0.00025980940865460213\n",
      "train loss:0.0012089698375084405\n",
      "train loss:0.0008426990143303312\n",
      "train loss:0.0009324552793556703\n",
      "train loss:0.0013440775018040679\n",
      "train loss:0.001631497961957185\n",
      "train loss:0.0022548106238174472\n",
      "train loss:0.0007028371979997478\n",
      "train loss:0.0021184939671708776\n",
      "train loss:0.0033451179912838613\n",
      "train loss:0.0016351052520278484\n",
      "train loss:0.021740843493953284\n",
      "train loss:0.00014473833919105425\n",
      "train loss:0.0021481802966285086\n",
      "train loss:0.0006602832547601064\n",
      "train loss:0.00012521199610598805\n",
      "train loss:0.0012084092582147208\n",
      "train loss:0.0008960458843758633\n",
      "train loss:0.0001490630766777431\n",
      "train loss:0.00046545745786727736\n",
      "train loss:0.00046181441565496293\n",
      "train loss:0.00011782586499347908\n",
      "train loss:0.015618068026768796\n",
      "train loss:0.0007287853669157386\n",
      "train loss:0.005026733624605582\n",
      "train loss:0.0027963723258980565\n",
      "train loss:0.00048687431035443983\n",
      "train loss:0.000695889488136663\n",
      "train loss:0.0009761703513369282\n",
      "train loss:0.003779017892914363\n",
      "train loss:0.004412007702989171\n",
      "train loss:0.0011139019856609947\n",
      "train loss:0.0001923713028407526\n",
      "train loss:0.0006349669448497249\n",
      "train loss:0.0055038987577962495\n",
      "train loss:0.0011060674802099376\n",
      "train loss:0.00031809928373126837\n",
      "train loss:0.008285908345075022\n",
      "train loss:0.004917609267340725\n",
      "train loss:0.0012167484737956476\n",
      "train loss:0.00035162783729357776\n",
      "train loss:0.0009957335054822673\n",
      "train loss:0.0037721460229434606\n",
      "train loss:0.0037208367167782573\n",
      "train loss:0.0017157590260263472\n",
      "train loss:0.0007996447912647585\n",
      "train loss:0.001177476803361612\n",
      "train loss:0.010585997356538018\n",
      "train loss:0.0006012721981469868\n",
      "train loss:0.001461404495718687\n",
      "train loss:0.0007637098669636441\n",
      "train loss:0.0032276706229652347\n",
      "train loss:0.005042637827804609\n",
      "train loss:0.0006834806832105102\n",
      "train loss:0.0014672551066536562\n",
      "train loss:0.005388500037989625\n",
      "train loss:0.0011256378814158623\n",
      "train loss:0.0018270057261550205\n",
      "train loss:0.003055120361154878\n",
      "train loss:0.000649637907747144\n",
      "train loss:0.0005134868308781459\n",
      "train loss:0.0016227917081193671\n",
      "train loss:0.0005427066105826424\n",
      "train loss:0.0006221510476520112\n",
      "train loss:0.0036247614899944493\n",
      "train loss:0.004934899311516205\n",
      "train loss:0.0002864863121952825\n",
      "train loss:0.0014776455785246165\n",
      "train loss:0.0010386343792259123\n",
      "train loss:0.0021420332125787383\n",
      "train loss:0.00039799083905104634\n",
      "train loss:0.0022640684923024863\n",
      "train loss:0.0006403151369606066\n",
      "train loss:0.003215334844167159\n",
      "train loss:0.00046718007110662025\n",
      "train loss:0.004821097332475422\n",
      "train loss:0.0006984505768853233\n",
      "train loss:0.003913589389521425\n",
      "train loss:3.896486300273259e-05\n",
      "train loss:0.002056229158484441\n",
      "train loss:0.001979756002563125\n",
      "train loss:0.00032569490130272735\n",
      "train loss:0.002179417541918298\n",
      "train loss:0.002512078131759352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002008024800176971\n",
      "train loss:0.013658280166824988\n",
      "train loss:0.008715416000384509\n",
      "train loss:0.00022397509967099323\n",
      "train loss:0.00047149000427099846\n",
      "train loss:0.0051200040488687095\n",
      "train loss:0.0010996279284378274\n",
      "train loss:0.0008355179130944726\n",
      "train loss:0.0003164196347513557\n",
      "train loss:0.0020296728866210337\n",
      "train loss:0.0007215125487905174\n",
      "train loss:0.0031241892527717825\n",
      "train loss:0.0006938425388427343\n",
      "train loss:0.0009969857258552905\n",
      "train loss:0.0010751380098186739\n",
      "train loss:0.0016143248194074892\n",
      "train loss:0.0007984592237978178\n",
      "train loss:0.004103052650895817\n",
      "train loss:0.0034913370171272464\n",
      "train loss:0.0007182962439269519\n",
      "train loss:0.005488974219026662\n",
      "train loss:0.004436508815022021\n",
      "train loss:0.0013334872848341196\n",
      "train loss:0.0013441634235477288\n",
      "train loss:0.002651202314054395\n",
      "train loss:0.0001813034667815193\n",
      "train loss:0.010197568729982377\n",
      "train loss:0.019836435125526602\n",
      "train loss:0.007317760350823298\n",
      "train loss:0.00032795892024571957\n",
      "train loss:0.004553050851983777\n",
      "train loss:0.0018170258292565175\n",
      "train loss:0.0025278726949362427\n",
      "train loss:0.014884516471702212\n",
      "train loss:0.00011083061592519536\n",
      "train loss:0.0002594068156037316\n",
      "train loss:0.010428931302176455\n",
      "train loss:0.0008474503878440668\n",
      "train loss:0.0034749078374987307\n",
      "train loss:0.0005313898699354568\n",
      "train loss:0.0019216837614073482\n",
      "train loss:0.004155013714887711\n",
      "train loss:0.00029810116224381967\n",
      "train loss:0.008894161811944882\n",
      "train loss:0.0029626242579083332\n",
      "train loss:0.0016061014289667974\n",
      "train loss:0.004554393516052708\n",
      "train loss:0.0016452089909401132\n",
      "train loss:0.0032683932428177447\n",
      "train loss:0.0017179758851115058\n",
      "train loss:0.0019559170941592123\n",
      "train loss:0.001104098709259999\n",
      "train loss:0.003971277028875483\n",
      "train loss:0.003630608014169368\n",
      "train loss:0.0005430617756841268\n",
      "train loss:0.0011426526913315706\n",
      "train loss:0.006335878279767679\n",
      "train loss:0.005930490914814051\n",
      "train loss:0.008171678026767208\n",
      "train loss:0.0004839692540147603\n",
      "train loss:0.0037388121267191354\n",
      "train loss:0.0010852403001897061\n",
      "train loss:0.0006654069771787288\n",
      "train loss:0.002681170884365213\n",
      "train loss:0.001078876158366844\n",
      "train loss:0.001161117249429654\n",
      "train loss:0.0010191808772401975\n",
      "train loss:0.00592070618630113\n",
      "train loss:0.004172584041050618\n",
      "train loss:0.005446656052914021\n",
      "train loss:0.018515624302141587\n",
      "train loss:0.00020367000707832906\n",
      "train loss:0.0007075412208211412\n",
      "train loss:0.0038274531824084184\n",
      "train loss:0.002677930681446182\n",
      "train loss:0.0007920961524605719\n",
      "train loss:0.007807510674921669\n",
      "train loss:0.004017467802641364\n",
      "train loss:0.0004263782003327063\n",
      "train loss:0.03608438116088336\n",
      "train loss:0.0017079541734593368\n",
      "train loss:0.00773816616722143\n",
      "train loss:0.005250930819836765\n",
      "train loss:0.003916402641657654\n",
      "train loss:0.0004213201306584428\n",
      "train loss:0.005405313201409693\n",
      "train loss:0.0006610059346964858\n",
      "train loss:0.042016688338047024\n",
      "train loss:0.001484530348955539\n",
      "train loss:0.04186397710088968\n",
      "train loss:0.00017662760471466102\n",
      "train loss:0.0006394138878183439\n",
      "train loss:0.0016135732342674866\n",
      "train loss:0.0006719686004574209\n",
      "train loss:0.0036296161504480885\n",
      "train loss:0.0005442146890344137\n",
      "train loss:0.00012223310785163221\n",
      "train loss:0.0019134698061607461\n",
      "train loss:0.004776697028865806\n",
      "train loss:0.0030922293444511145\n",
      "train loss:0.0012347387704114557\n",
      "train loss:0.002873117760152483\n",
      "train loss:0.00011670431889406613\n",
      "train loss:0.024160228430180623\n",
      "train loss:0.003938592252358723\n",
      "train loss:0.009734830659806666\n",
      "train loss:0.0030486012977688558\n",
      "train loss:9.828495989725226e-05\n",
      "train loss:0.0014250809690153536\n",
      "train loss:0.0018728347882893633\n",
      "train loss:0.0023042281039793414\n",
      "train loss:0.0013429811588605062\n",
      "train loss:0.0008064508238438605\n",
      "train loss:0.023836440346236484\n",
      "train loss:0.0027484091956574497\n",
      "train loss:0.005805843857648759\n",
      "train loss:0.0005765561867575489\n",
      "train loss:0.0012457788903277034\n",
      "train loss:0.0005651857408965491\n",
      "train loss:0.00047955641251756076\n",
      "train loss:0.00019702135215979134\n",
      "train loss:0.0008219146068645416\n",
      "train loss:0.0027919353840173853\n",
      "train loss:0.0021136826100961025\n",
      "train loss:0.00357104778655556\n",
      "train loss:0.0006025631192827838\n",
      "train loss:0.0003434964110439741\n",
      "train loss:0.02606900747476077\n",
      "train loss:0.0009801246060526776\n",
      "train loss:0.0027619761081390175\n",
      "train loss:0.001115010504730186\n",
      "train loss:0.0006395599477908025\n",
      "train loss:0.0028109828215240455\n",
      "train loss:0.0033162000667507274\n",
      "train loss:0.0006898322478012497\n",
      "train loss:0.0036793019633758347\n",
      "train loss:0.006573535730196625\n",
      "train loss:0.0014770171298342013\n",
      "train loss:0.0114336531739593\n",
      "train loss:0.0017754741406624834\n",
      "train loss:0.0010188967942542835\n",
      "train loss:0.00043331461019985556\n",
      "train loss:0.00558814343442742\n",
      "train loss:0.0004689907739578975\n",
      "train loss:0.024422620601656616\n",
      "train loss:0.0007055397563123047\n",
      "train loss:0.0024212069451553042\n",
      "train loss:0.001254732013979001\n",
      "train loss:0.001534139597296361\n",
      "train loss:0.005739447877822285\n",
      "train loss:0.01149358313505809\n",
      "train loss:0.0019069463010342833\n",
      "train loss:0.007142641277917877\n",
      "train loss:0.03726110671401537\n",
      "train loss:0.007924559766164924\n",
      "train loss:0.0002997225221471119\n",
      "train loss:0.0006098006432070046\n",
      "train loss:0.004129192063952192\n",
      "train loss:0.003542337886978192\n",
      "train loss:0.009110562284909762\n",
      "train loss:0.007926691230702167\n",
      "train loss:0.017493943734626344\n",
      "train loss:0.0008054387887604322\n",
      "train loss:0.015732497621023044\n",
      "train loss:0.0020871121561531493\n",
      "train loss:0.0007939500369763424\n",
      "train loss:0.0005944467833207905\n",
      "train loss:0.0008958208460807372\n",
      "train loss:0.0032212067341858574\n",
      "train loss:0.0011077237145156265\n",
      "train loss:0.0011789047222359407\n",
      "train loss:0.005053642311716439\n",
      "train loss:0.001530647293876466\n",
      "train loss:0.003420241650476297\n",
      "train loss:0.0050808866237613695\n",
      "train loss:0.001213303282180591\n",
      "train loss:0.017242886515319623\n",
      "train loss:0.0002836393724562519\n",
      "train loss:0.009245324908954345\n",
      "train loss:0.0030942458425630135\n",
      "train loss:0.0017307156223823484\n",
      "train loss:0.008870007790390166\n",
      "train loss:0.007027357067326201\n",
      "train loss:0.002207980888138499\n",
      "train loss:0.0008626619655350295\n",
      "train loss:0.008266414450906033\n",
      "train loss:0.0009379318471798028\n",
      "train loss:0.0004803694812148508\n",
      "train loss:0.0003426411594714088\n",
      "train loss:0.0033752812871709757\n",
      "train loss:0.0010914186562301711\n",
      "train loss:0.0018383855965913444\n",
      "train loss:0.002350936052993668\n",
      "train loss:0.0025056992769489756\n",
      "train loss:0.0007124452899843947\n",
      "train loss:0.001554652218221052\n",
      "train loss:0.00041709427917882824\n",
      "train loss:0.004450932031914992\n",
      "train loss:0.0014647224535412615\n",
      "train loss:0.0012397546441829165\n",
      "train loss:0.002181424008490464\n",
      "train loss:0.0025330211064432395\n",
      "train loss:0.002082068604019006\n",
      "train loss:0.0028981155749459343\n",
      "train loss:0.007818139302580141\n",
      "train loss:0.00021777801695878132\n",
      "train loss:0.005157711669115139\n",
      "train loss:0.0005539725500426067\n",
      "train loss:0.00039374731413198167\n",
      "train loss:0.0033583905087432985\n",
      "train loss:0.0002025956436560268\n",
      "train loss:0.009482141323091376\n",
      "train loss:0.0007054207157124597\n",
      "train loss:0.0008347425191569526\n",
      "train loss:0.0003727933641255901\n",
      "train loss:0.0013735051564084451\n",
      "train loss:0.0006727658682561959\n",
      "train loss:0.0015631719832624917\n",
      "train loss:0.0014854401912805116\n",
      "train loss:0.006449692653607361\n",
      "train loss:0.0447417423276972\n",
      "train loss:0.0007382973841743608\n",
      "train loss:0.00030775567911798504\n",
      "train loss:0.0026657821684113294\n",
      "train loss:0.0002855719968285806\n",
      "train loss:0.003362429547535045\n",
      "train loss:0.005789410309758194\n",
      "train loss:0.00264603975734108\n",
      "train loss:0.0013677646184341039\n",
      "train loss:0.0016097381296642781\n",
      "train loss:0.0017519991043895193\n",
      "train loss:0.0019616178615435424\n",
      "train loss:0.020049997944823438\n",
      "train loss:0.00047121690666198556\n",
      "train loss:0.00018982428018266017\n",
      "train loss:0.007025357009566556\n",
      "train loss:0.0011639606367204879\n",
      "train loss:0.0010127509912622355\n",
      "train loss:0.0005790711014597206\n",
      "train loss:0.0017535079040768313\n",
      "train loss:0.0010900835834301281\n",
      "train loss:0.0007901829387082687\n",
      "train loss:0.00040697598030258586\n",
      "train loss:0.0018005930860298359\n",
      "train loss:0.014222585010600166\n",
      "train loss:0.006640772704683473\n",
      "train loss:0.002465324556043451\n",
      "train loss:0.0005322835222830156\n",
      "train loss:0.0006385919584542989\n",
      "train loss:0.0004227625506311797\n",
      "train loss:8.568148030987691e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002978032984050385\n",
      "train loss:0.003300922397783252\n",
      "train loss:0.0002969652433298526\n",
      "train loss:0.0006280090443058124\n",
      "train loss:0.00041581102953863074\n",
      "train loss:0.004350303689684825\n",
      "train loss:0.001279342730621886\n",
      "train loss:0.0016352144314152454\n",
      "train loss:0.0026937271187343725\n",
      "train loss:0.012420432299808914\n",
      "train loss:9.174019320332445e-05\n",
      "train loss:0.0002907316175219596\n",
      "train loss:0.003994217348634426\n",
      "train loss:0.002408934425522063\n",
      "train loss:0.00019405091546923726\n",
      "train loss:0.0018788585308126863\n",
      "train loss:0.00013211759444936946\n",
      "train loss:0.0002957217073573302\n",
      "train loss:0.017929480784166243\n",
      "train loss:0.0007743356630825024\n",
      "train loss:0.00010109500281583217\n",
      "train loss:0.0012910873475023737\n",
      "train loss:0.00042574685254352895\n",
      "train loss:0.00029010871031311336\n",
      "train loss:0.0020109283170394337\n",
      "train loss:0.0010264349173452038\n",
      "train loss:0.0007487594064621982\n",
      "train loss:0.000341329068138345\n",
      "train loss:0.00027506899360161234\n",
      "train loss:0.0009144696728698439\n",
      "train loss:0.0005156425347803682\n",
      "train loss:0.002080342266252715\n",
      "train loss:0.002333620490156545\n",
      "train loss:0.0030903344647629422\n",
      "train loss:0.009081951366045511\n",
      "train loss:0.0010740249808886596\n",
      "train loss:0.001209372539674195\n",
      "train loss:0.0010170921725376752\n",
      "train loss:0.000546130860784988\n",
      "train loss:0.006545534256563361\n",
      "train loss:0.0009149859718779112\n",
      "train loss:0.0016083787873948702\n",
      "train loss:0.0006054007910934324\n",
      "train loss:0.00015878423554900066\n",
      "train loss:0.0012547417389071084\n",
      "train loss:0.01523365837211874\n",
      "train loss:0.006616096900518056\n",
      "train loss:0.0009463823867889587\n",
      "train loss:0.021358770130582353\n",
      "train loss:0.00036893435638960475\n",
      "train loss:0.005232819267923436\n",
      "train loss:0.0011010739626301888\n",
      "train loss:0.00013633766979046508\n",
      "train loss:0.00045628565186297334\n",
      "train loss:0.0022511229118138214\n",
      "train loss:0.001778594510684032\n",
      "train loss:0.0013350181334682901\n",
      "train loss:0.02935735635672452\n",
      "train loss:0.005991320610112656\n",
      "train loss:0.0036962445471831313\n",
      "train loss:0.0008874702504480298\n",
      "train loss:0.0002661149374602415\n",
      "train loss:0.0017401501196220455\n",
      "train loss:0.00042917246281756825\n",
      "train loss:0.003799613770630665\n",
      "train loss:0.0013531649401248417\n",
      "train loss:0.0048872838999282076\n",
      "train loss:0.0029505324443924556\n",
      "train loss:0.0007236807677700628\n",
      "train loss:0.0025022408013947927\n",
      "train loss:0.005403765249336444\n",
      "train loss:0.005186071333586333\n",
      "train loss:0.009737821874256414\n",
      "train loss:0.002313414691860747\n",
      "train loss:0.006340128373440691\n",
      "train loss:0.0012059586254344525\n",
      "train loss:0.0022267063728151713\n",
      "train loss:0.00231422690600095\n",
      "train loss:0.00203034851780082\n",
      "train loss:0.002058845710727712\n",
      "train loss:8.344281080455027e-05\n",
      "train loss:0.001171922470311647\n",
      "train loss:0.001980859465589807\n",
      "train loss:0.0002879124596369174\n",
      "train loss:0.00038227138342050834\n",
      "train loss:0.005368191602258859\n",
      "train loss:0.0003328591431344758\n",
      "train loss:0.006921232371624464\n",
      "train loss:0.00038218462321391514\n",
      "train loss:0.014480015913917666\n",
      "train loss:0.0005990364858478546\n",
      "train loss:0.00043928529574499\n",
      "=== epoch:17, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0003499603361861757\n",
      "train loss:0.0010516441302976442\n",
      "train loss:0.007584873308422179\n",
      "train loss:0.0006457091308841715\n",
      "train loss:0.00020900276932780943\n",
      "train loss:0.0003474235917823558\n",
      "train loss:0.003446884337808387\n",
      "train loss:0.0071767786284603575\n",
      "train loss:0.0017557752334811986\n",
      "train loss:0.002339683734991456\n",
      "train loss:0.0011582141438692577\n",
      "train loss:0.0036234696128857337\n",
      "train loss:0.003667645341998496\n",
      "train loss:0.0007931408518064253\n",
      "train loss:0.000947880731013133\n",
      "train loss:0.0030394478592762103\n",
      "train loss:0.0004382820072707341\n",
      "train loss:0.000224949760257486\n",
      "train loss:0.005153088094488426\n",
      "train loss:0.00036978940315603496\n",
      "train loss:0.0038024701759448516\n",
      "train loss:0.0006721593652011086\n",
      "train loss:0.00019773557699708983\n",
      "train loss:0.002820051768885937\n",
      "train loss:0.00021301714527951275\n",
      "train loss:0.0014168047310764715\n",
      "train loss:0.008490193159772898\n",
      "train loss:0.00015328276232446847\n",
      "train loss:0.0018774136126519293\n",
      "train loss:0.0010235073986156367\n",
      "train loss:0.000908671289391038\n",
      "train loss:0.0003086363705211693\n",
      "train loss:0.0011011714258117428\n",
      "train loss:0.004433925403516084\n",
      "train loss:0.0013280274270430668\n",
      "train loss:0.0007343587503739495\n",
      "train loss:0.001452265789846468\n",
      "train loss:0.007952590105629397\n",
      "train loss:0.0002582533445623411\n",
      "train loss:0.0008211654171050921\n",
      "train loss:0.0025714518741751153\n",
      "train loss:0.0018838731428532315\n",
      "train loss:0.0012219788586399834\n",
      "train loss:0.0019360273935204986\n",
      "train loss:0.0027380820009812496\n",
      "train loss:0.0020624132527709517\n",
      "train loss:0.000312967497442898\n",
      "train loss:0.0005631110600112509\n",
      "train loss:0.0008010020168619449\n",
      "train loss:0.002829457405499435\n",
      "train loss:0.0016729951080790783\n",
      "train loss:0.0005452375285859402\n",
      "train loss:0.0004591185544908617\n",
      "train loss:0.0028383331516338085\n",
      "train loss:0.002918747321582899\n",
      "train loss:0.012812665358564027\n",
      "train loss:0.00019566927900032047\n",
      "train loss:0.0014475459117168185\n",
      "train loss:0.001763116315926446\n",
      "train loss:0.0005179774525224136\n",
      "train loss:0.001255560617770394\n",
      "train loss:0.001527291857283889\n",
      "train loss:0.0009355704000080002\n",
      "train loss:0.00031220420214585654\n",
      "train loss:0.00024295223471260368\n",
      "train loss:0.001302616163405261\n",
      "train loss:0.0001437253433481125\n",
      "train loss:0.0004915038346640204\n",
      "train loss:0.0018163594115742769\n",
      "train loss:0.003928172278731303\n",
      "train loss:2.1186848943189547e-05\n",
      "train loss:0.00017366142343335427\n",
      "train loss:0.000624316975246696\n",
      "train loss:0.0018197332116181256\n",
      "train loss:0.0009337274784756134\n",
      "train loss:0.0006961922085598277\n",
      "train loss:0.0004243304024176672\n",
      "train loss:0.0005595996109009044\n",
      "train loss:0.002416350017781713\n",
      "train loss:0.0005090901777081874\n",
      "train loss:0.0014002153288317928\n",
      "train loss:0.002858038200764525\n",
      "train loss:9.23801048276068e-05\n",
      "train loss:0.001396430596352221\n",
      "train loss:0.0003882550529908772\n",
      "train loss:0.0036607382235822193\n",
      "train loss:0.009630275769765875\n",
      "train loss:0.0008505330929153952\n",
      "train loss:0.0010238572697727243\n",
      "train loss:0.006208611961746738\n",
      "train loss:0.0023690171323570625\n",
      "train loss:0.0007398333621051268\n",
      "train loss:0.0033312316296404986\n",
      "train loss:0.00048425138787903753\n",
      "train loss:0.0002472151201190125\n",
      "train loss:0.00023127122108852484\n",
      "train loss:0.00319721630531487\n",
      "train loss:0.0027022957916006856\n",
      "train loss:0.00023551565684966605\n",
      "train loss:0.00010920205162659824\n",
      "train loss:0.0006035468742730746\n",
      "train loss:0.002934292814369686\n",
      "train loss:0.0008450391770478582\n",
      "train loss:0.004405191741529651\n",
      "train loss:0.00027524008671758667\n",
      "train loss:0.0033271693885202043\n",
      "train loss:0.0005696357809492926\n",
      "train loss:0.001889682509789434\n",
      "train loss:0.004369259775145018\n",
      "train loss:0.0005657700781715293\n",
      "train loss:0.0006972512454677718\n",
      "train loss:0.0012290922275573347\n",
      "train loss:0.0015876223550602786\n",
      "train loss:0.0006192490420245797\n",
      "train loss:8.704489385275661e-05\n",
      "train loss:0.007594910893563733\n",
      "train loss:0.00038253338725379083\n",
      "train loss:0.0003177289646524857\n",
      "train loss:0.000811424837912042\n",
      "train loss:0.0006583705291770011\n",
      "train loss:0.0003917590251996836\n",
      "train loss:0.0009216806739071296\n",
      "train loss:3.3132639766028295e-05\n",
      "train loss:8.324047632179702e-05\n",
      "train loss:0.0005446078707714183\n",
      "train loss:0.014473233906348002\n",
      "train loss:0.0023145900951145734\n",
      "train loss:0.0006149550715918124\n",
      "train loss:0.00015325439587523176\n",
      "train loss:0.00018607468763981488\n",
      "train loss:0.0017587470937883935\n",
      "train loss:0.00014701569692775855\n",
      "train loss:0.006361556647623759\n",
      "train loss:0.0020236163794283253\n",
      "train loss:0.0018045554266075145\n",
      "train loss:0.00019943150116936154\n",
      "train loss:7.767242932741745e-05\n",
      "train loss:0.0014684456541296895\n",
      "train loss:0.001310502366772177\n",
      "train loss:0.001874061714184468\n",
      "train loss:0.0013534443025462262\n",
      "train loss:0.000355424321101685\n",
      "train loss:9.343915995235286e-05\n",
      "train loss:0.002745244363510318\n",
      "train loss:0.0031977087312736346\n",
      "train loss:0.0006782377113799617\n",
      "train loss:0.000826088638657605\n",
      "train loss:0.0014418921952888504\n",
      "train loss:0.0002379335316220379\n",
      "train loss:0.0008073895348544187\n",
      "train loss:0.0013045697236096162\n",
      "train loss:9.232217525700528e-05\n",
      "train loss:0.0011675826341105418\n",
      "train loss:0.0019292209617553938\n",
      "train loss:0.0006808128916946172\n",
      "train loss:0.0004714080829657066\n",
      "train loss:0.0011683538151413984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001644797127323989\n",
      "train loss:0.00010737949376014447\n",
      "train loss:0.0003409422927575514\n",
      "train loss:0.0022631971866710014\n",
      "train loss:0.0007851090427275394\n",
      "train loss:0.0017958361933790056\n",
      "train loss:0.0006889748934649047\n",
      "train loss:7.97198356685191e-05\n",
      "train loss:0.002222312750885887\n",
      "train loss:0.00024307885574054806\n",
      "train loss:0.001015551059664406\n",
      "train loss:0.00013643828775071357\n",
      "train loss:0.0012667840346841169\n",
      "train loss:0.009811135808452423\n",
      "train loss:0.0014755813980415421\n",
      "train loss:0.0051289758314289205\n",
      "train loss:0.002878666155865009\n",
      "train loss:0.0006818161376737028\n",
      "train loss:0.0017613984040738748\n",
      "train loss:0.0003673485898625803\n",
      "train loss:0.0012133436441040702\n",
      "train loss:0.002023279546932923\n",
      "train loss:0.0006525102398339691\n",
      "train loss:0.0012783814679265932\n",
      "train loss:9.119725419701316e-05\n",
      "train loss:0.0016875013763628468\n",
      "train loss:0.00015164749409959515\n",
      "train loss:0.00023415572153900056\n",
      "train loss:0.0006442352500059424\n",
      "train loss:0.004304878405282965\n",
      "train loss:0.00023684791214698234\n",
      "train loss:0.0013977599555473558\n",
      "train loss:0.0004948476844206466\n",
      "train loss:0.00033574611038171104\n",
      "train loss:0.0010146323149235002\n",
      "train loss:0.001815696521757135\n",
      "train loss:0.0021139507177035995\n",
      "train loss:0.008804621888037673\n",
      "train loss:0.00360590989146139\n",
      "train loss:0.00656174358515445\n",
      "train loss:0.005584353443669216\n",
      "train loss:0.0018833793715223618\n",
      "train loss:0.00028004169247457353\n",
      "train loss:0.0030847387342821096\n",
      "train loss:0.0003021708904219287\n",
      "train loss:0.0018410132514573277\n",
      "train loss:0.0006483249361081679\n",
      "train loss:0.0001205277303559373\n",
      "train loss:0.0016886237081477672\n",
      "train loss:3.7108080347281316e-05\n",
      "train loss:0.001715354676619066\n",
      "train loss:0.002642105535583883\n",
      "train loss:0.002326205250382131\n",
      "train loss:0.0012809601937635833\n",
      "train loss:0.0004979053413040421\n",
      "train loss:0.0007291910240355755\n",
      "train loss:0.040909412076827946\n",
      "train loss:0.0011009976068778087\n",
      "train loss:0.003189384684098745\n",
      "train loss:7.456335896858027e-05\n",
      "train loss:0.0004406878112828195\n",
      "train loss:0.0020055582181258626\n",
      "train loss:0.0017951804948779775\n",
      "train loss:0.0019807885432565906\n",
      "train loss:0.000403033095813082\n",
      "train loss:0.0008973532654598664\n",
      "train loss:0.000747734451607278\n",
      "train loss:0.0002900108112077796\n",
      "train loss:0.0007108552339873262\n",
      "train loss:0.00012366905824274626\n",
      "train loss:0.0037471866398409463\n",
      "train loss:0.0006409825513656454\n",
      "train loss:0.0009316319047129924\n",
      "train loss:0.0010868270703808503\n",
      "train loss:0.0003877897862505701\n",
      "train loss:0.04438438600886256\n",
      "train loss:0.0003809151335934738\n",
      "train loss:0.007145042573747461\n",
      "train loss:0.0006905196287857375\n",
      "train loss:0.002430494047678093\n",
      "train loss:0.00019044674750695622\n",
      "train loss:0.00021303608186542478\n",
      "train loss:0.0261532263823573\n",
      "train loss:0.0002514502544133119\n",
      "train loss:0.0014246776752248665\n",
      "train loss:0.0005205637845586146\n",
      "train loss:0.0003832830531588405\n",
      "train loss:0.0025915413465998644\n",
      "train loss:0.0015612413078915249\n",
      "train loss:0.00296819249051425\n",
      "train loss:0.0017982160615044097\n",
      "train loss:0.00305058626753972\n",
      "train loss:0.00016392298624309156\n",
      "train loss:0.0005577212261422503\n",
      "train loss:0.003651192773066793\n",
      "train loss:0.002559264639122981\n",
      "train loss:0.0017470151551091104\n",
      "train loss:0.0012295408541486347\n",
      "train loss:0.0007376959890214615\n",
      "train loss:0.0008390454825659386\n",
      "train loss:0.0003836175520074245\n",
      "train loss:0.0032454188107840258\n",
      "train loss:0.0044202818236387005\n",
      "train loss:0.0008973169776517776\n",
      "train loss:0.0015611287573734148\n",
      "train loss:0.0011160241369672396\n",
      "train loss:0.0010420620187580395\n",
      "train loss:0.0006813626301867841\n",
      "train loss:0.0004100597968235469\n",
      "train loss:0.0016433665834751472\n",
      "train loss:0.00022628509652220983\n",
      "train loss:0.0007788918870566462\n",
      "train loss:0.0018156030513614375\n",
      "train loss:0.0010790320402755198\n",
      "train loss:0.0002540538176167173\n",
      "train loss:0.000503736461304382\n",
      "train loss:0.0010844818275553844\n",
      "train loss:0.00010898055411809995\n",
      "train loss:0.0010499963036547943\n",
      "train loss:0.00022502181704952138\n",
      "train loss:0.00225117829298145\n",
      "train loss:0.0030261368548294655\n",
      "train loss:0.002888724814576796\n",
      "train loss:0.0008589605158004633\n",
      "train loss:0.0001892057210729493\n",
      "train loss:0.00141095027189655\n",
      "train loss:0.000575765479128783\n",
      "train loss:0.003276955799625877\n",
      "train loss:0.00038143844459408166\n",
      "train loss:0.0009075892189588647\n",
      "train loss:0.000154844801021939\n",
      "train loss:0.0006066689155956647\n",
      "train loss:0.000560176239875622\n",
      "train loss:0.0022483140251705115\n",
      "train loss:0.002657737829303389\n",
      "train loss:0.0004056204674699485\n",
      "train loss:0.0011702350179191193\n",
      "train loss:0.001253308335686817\n",
      "train loss:0.002956732246355353\n",
      "train loss:0.00015071800811598362\n",
      "train loss:0.0004482957366692363\n",
      "train loss:0.004882071303917435\n",
      "train loss:0.0003383127452993719\n",
      "train loss:0.00020058701882623407\n",
      "train loss:0.0004294730468893996\n",
      "train loss:0.00030258664455919647\n",
      "train loss:0.0007462451221105444\n",
      "train loss:0.0015258084973640334\n",
      "train loss:0.005314524404552665\n",
      "train loss:0.005899555541427224\n",
      "train loss:0.0005262815850394702\n",
      "train loss:0.011828542173924142\n",
      "train loss:0.0017207924088021743\n",
      "train loss:0.0002419209843914247\n",
      "train loss:0.0018698153890595354\n",
      "train loss:0.002155066698733944\n",
      "train loss:0.0014334691423874802\n",
      "train loss:0.00018551646276137657\n",
      "train loss:0.0003245230000626752\n",
      "train loss:0.00014992967593152324\n",
      "train loss:0.006832795183311801\n",
      "train loss:9.74571624490192e-05\n",
      "train loss:0.00031687834642725926\n",
      "train loss:0.0012866651167011583\n",
      "train loss:0.008263548274483789\n",
      "train loss:0.00045852281966562774\n",
      "train loss:0.00012336952742352618\n",
      "train loss:0.0010428664998061133\n",
      "train loss:0.0010007387973395934\n",
      "train loss:0.0005297325639972307\n",
      "train loss:0.00011102631340546063\n",
      "train loss:0.0013945674272529275\n",
      "train loss:0.0003766044109400808\n",
      "train loss:0.016429222877941477\n",
      "train loss:0.00015148457669386732\n",
      "train loss:0.0003917897211338277\n",
      "train loss:7.17363537429133e-05\n",
      "train loss:0.00027869807067083867\n",
      "train loss:0.006659218198402893\n",
      "train loss:0.0014427992773512028\n",
      "train loss:0.00021429289744745054\n",
      "train loss:0.0028679086813727436\n",
      "train loss:0.00043006534052835045\n",
      "train loss:0.00025275409298286316\n",
      "train loss:0.0013584932288929156\n",
      "train loss:0.0017987671973043917\n",
      "train loss:0.00041636589630937625\n",
      "train loss:0.0011667643913360476\n",
      "train loss:0.001266373292255603\n",
      "train loss:0.0020601755679770556\n",
      "train loss:0.0025620978350266604\n",
      "train loss:0.0007500167148963794\n",
      "train loss:0.0012246319390462638\n",
      "train loss:0.004794860849997685\n",
      "train loss:0.0021741567084212097\n",
      "train loss:0.0007696509233411369\n",
      "train loss:0.0021096481282765617\n",
      "train loss:0.000514651935541895\n",
      "train loss:0.00229919215394294\n",
      "train loss:0.0008709937735692647\n",
      "train loss:0.0009049084387497178\n",
      "train loss:0.00010969231561880952\n",
      "train loss:0.0002949322517887521\n",
      "train loss:0.00046864627684165965\n",
      "train loss:0.0005045361401058339\n",
      "train loss:0.0010880754435482042\n",
      "train loss:5.31384906557868e-05\n",
      "train loss:0.0010422398924571396\n",
      "train loss:0.0005281267137986693\n",
      "train loss:0.0002536308367417953\n",
      "train loss:0.010224402737648408\n",
      "train loss:0.00020362946647689337\n",
      "train loss:0.0002772141485193998\n",
      "train loss:0.0018452529301202234\n",
      "train loss:0.001210544387433259\n",
      "train loss:0.0004633432188129808\n",
      "train loss:0.0009656289319736492\n",
      "train loss:0.0009365659031662297\n",
      "train loss:0.0007969368639670055\n",
      "train loss:0.00045684209250884336\n",
      "train loss:0.0001649989912712949\n",
      "train loss:0.005108376325118767\n",
      "train loss:0.0007172812177882176\n",
      "train loss:0.0009128957336362395\n",
      "train loss:0.000747680478902243\n",
      "train loss:0.0010488128903459655\n",
      "train loss:0.0005548858873515713\n",
      "train loss:0.00011917158683779323\n",
      "train loss:0.0010680333570051122\n",
      "train loss:0.0035820778397859256\n",
      "train loss:0.0007863393911214109\n",
      "train loss:0.0016667002480206191\n",
      "train loss:0.00015646852588559437\n",
      "train loss:0.0006804498692936452\n",
      "train loss:0.0010551462110029196\n",
      "train loss:0.0027113933872346054\n",
      "train loss:0.00022661692296451096\n",
      "train loss:0.0017360611485923644\n",
      "train loss:0.0018107661499930329\n",
      "train loss:0.00010550049464729927\n",
      "train loss:0.00020391364515562837\n",
      "train loss:0.0021916547400239587\n",
      "train loss:0.003521645062749859\n",
      "train loss:0.0005538386287469282\n",
      "train loss:0.002587135657216228\n",
      "train loss:9.331807851610704e-05\n",
      "train loss:0.0009277007215206318\n",
      "train loss:0.0007888188864674562\n",
      "train loss:0.0023123957879572065\n",
      "train loss:0.0033860517569201725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007583525741955035\n",
      "train loss:0.0006660072780714424\n",
      "train loss:0.00012202697667922178\n",
      "train loss:0.0013715367467270333\n",
      "train loss:9.963339449245266e-05\n",
      "train loss:0.00016035354063133694\n",
      "train loss:0.0009728748120362722\n",
      "train loss:0.0003964771142448817\n",
      "train loss:0.0012943039503715804\n",
      "train loss:0.003416960551321022\n",
      "train loss:0.0008810881851329496\n",
      "train loss:0.0032742066280607414\n",
      "train loss:0.0012047741090583438\n",
      "train loss:0.00032835797125471396\n",
      "train loss:0.0031196684204772857\n",
      "train loss:0.0002090616585019169\n",
      "train loss:0.0028443913236632493\n",
      "train loss:0.0005287267761226977\n",
      "train loss:0.007584208051943348\n",
      "train loss:0.0007925228284430833\n",
      "train loss:7.478104289334788e-05\n",
      "train loss:0.00016049358735406696\n",
      "train loss:0.0007506497831182634\n",
      "train loss:6.80014289833034e-05\n",
      "train loss:5.6286369684494744e-05\n",
      "train loss:0.006583210568954683\n",
      "train loss:0.0005919075494201782\n",
      "train loss:0.008465273087472662\n",
      "train loss:0.0025979675118412366\n",
      "train loss:0.002541232114773635\n",
      "train loss:0.0007861382771570222\n",
      "train loss:0.0013897346252308479\n",
      "train loss:0.0027972472351675643\n",
      "train loss:0.0029583977271207657\n",
      "train loss:0.0056166402542617054\n",
      "train loss:0.0001945067953804766\n",
      "train loss:0.00015211700191988356\n",
      "train loss:0.008620816829821897\n",
      "train loss:0.031481600329413155\n",
      "train loss:0.0008199941510329501\n",
      "train loss:0.009306508385672237\n",
      "train loss:0.009667833511466557\n",
      "train loss:0.00380089599797552\n",
      "train loss:0.0002331025422734283\n",
      "train loss:0.0018112884727767736\n",
      "train loss:0.0008185617635292855\n",
      "train loss:0.003772991256975932\n",
      "train loss:0.0033641632825049755\n",
      "train loss:0.001846266714362457\n",
      "train loss:0.009453837826995026\n",
      "train loss:0.002075419037401039\n",
      "train loss:0.0016597266993719267\n",
      "train loss:0.000576465412832031\n",
      "train loss:0.0008403052851343189\n",
      "train loss:0.0019620812332884065\n",
      "train loss:0.0010161897867601\n",
      "train loss:0.006702070898316964\n",
      "train loss:0.0036758645872229756\n",
      "train loss:0.001966957702829254\n",
      "train loss:0.002027548462784177\n",
      "train loss:0.0033961347064238247\n",
      "train loss:0.00034421914163722\n",
      "train loss:0.0007640233239635685\n",
      "train loss:0.004705743302194159\n",
      "train loss:0.0004959183884146365\n",
      "train loss:0.0044283380197241125\n",
      "train loss:0.00289278457908695\n",
      "train loss:0.0021446039065823605\n",
      "train loss:0.006739744802050529\n",
      "train loss:0.0007907655956320166\n",
      "train loss:0.004811501395365185\n",
      "train loss:0.0031015816548071516\n",
      "train loss:0.0004667952218673127\n",
      "train loss:0.004721012002675408\n",
      "train loss:0.0023329014701983617\n",
      "train loss:0.003056414790567138\n",
      "train loss:0.0015302224417749232\n",
      "train loss:0.0004391715903139939\n",
      "train loss:0.0018635092115096927\n",
      "train loss:0.0010679740644952238\n",
      "train loss:0.007191667191452585\n",
      "train loss:0.004926526185860771\n",
      "train loss:0.007852097214282403\n",
      "train loss:0.004613334619286954\n",
      "train loss:0.002443591372583127\n",
      "train loss:0.0008444381595007665\n",
      "train loss:0.0008672594675098078\n",
      "train loss:0.02438364450927439\n",
      "train loss:0.0017017580604248262\n",
      "train loss:0.005319071951636481\n",
      "train loss:0.0019754286341864117\n",
      "train loss:0.01295501570882593\n",
      "train loss:0.0002879933057922528\n",
      "train loss:0.0011680425079557378\n",
      "train loss:0.007108823515872085\n",
      "train loss:0.010335733833849205\n",
      "train loss:0.008694341601210754\n",
      "train loss:0.00027979136992209913\n",
      "train loss:0.0037484737785223976\n",
      "train loss:0.002843026242988586\n",
      "train loss:0.0008630987690802654\n",
      "train loss:0.0028506034140221466\n",
      "train loss:0.0014936667156383557\n",
      "train loss:0.0004028185581022653\n",
      "train loss:0.0015515381812817347\n",
      "train loss:0.006835455237151095\n",
      "train loss:0.0004779930369868141\n",
      "train loss:0.0021937639432234026\n",
      "train loss:1.5490745424945137e-05\n",
      "train loss:0.012257576224186398\n",
      "train loss:0.003221489969909984\n",
      "train loss:0.0007069138489689138\n",
      "train loss:0.0006632189026063603\n",
      "train loss:0.001549524237051652\n",
      "train loss:0.0007893818109760181\n",
      "train loss:0.0020882666353528433\n",
      "train loss:0.00029003824782306985\n",
      "train loss:0.005319531746138711\n",
      "train loss:0.004916105289091547\n",
      "train loss:0.000263092050833607\n",
      "train loss:0.00011882738020561148\n",
      "train loss:0.0009270838185119889\n",
      "train loss:0.001955803772624848\n",
      "train loss:0.0007415245481012726\n",
      "train loss:0.000216154873607579\n",
      "train loss:0.0022883504705118332\n",
      "train loss:0.004199496275457973\n",
      "train loss:0.003612343614141648\n",
      "train loss:0.000244765460137353\n",
      "train loss:0.0005877793647028369\n",
      "train loss:0.00024265002008564988\n",
      "train loss:0.0002685673890633991\n",
      "train loss:0.001867975533162901\n",
      "train loss:0.00012626305098786507\n",
      "train loss:0.002503776114146479\n",
      "train loss:0.00020689177277510043\n",
      "train loss:0.00081589309410649\n",
      "train loss:0.006688755622416127\n",
      "train loss:0.005565448149273166\n",
      "train loss:0.00027471765934822576\n",
      "train loss:0.0015022045704091705\n",
      "train loss:0.0004937761491351166\n",
      "train loss:0.005145498340912189\n",
      "train loss:0.002174478668039505\n",
      "train loss:0.00031078944938452277\n",
      "train loss:0.00039563306647185536\n",
      "train loss:0.003168770201333976\n",
      "train loss:0.00038860778319592675\n",
      "train loss:0.00045553155059390913\n",
      "train loss:0.0004020852531384285\n",
      "train loss:0.0002179990731630625\n",
      "train loss:0.00022064276160152586\n",
      "train loss:0.0030948153853530154\n",
      "train loss:0.0004806297207863682\n",
      "train loss:0.0023727901550901287\n",
      "train loss:0.0007224139869196041\n",
      "train loss:0.0008847727565650675\n",
      "train loss:0.0017832506069702166\n",
      "train loss:0.0009931305262416252\n",
      "train loss:0.015538245969530193\n",
      "train loss:0.0004443751881838081\n",
      "train loss:0.0026293691248452113\n",
      "train loss:0.0008752120192678015\n",
      "train loss:0.0022919272367494686\n",
      "train loss:0.001292903572206656\n",
      "train loss:0.00019565421552145815\n",
      "train loss:0.0004974731443217821\n",
      "train loss:0.005644993877270901\n",
      "train loss:0.0001963847144054498\n",
      "train loss:0.003897678671370179\n",
      "train loss:0.0008589359851252306\n",
      "train loss:0.00393397192874855\n",
      "train loss:0.004717894801286221\n",
      "train loss:0.00029938378705055897\n",
      "train loss:0.00045450514921289515\n",
      "train loss:0.0007716424408921552\n",
      "train loss:0.0026380032157057227\n",
      "train loss:0.0005522504579847235\n",
      "train loss:0.0019022985318562918\n",
      "train loss:0.0003129897119496685\n",
      "train loss:0.0040629140352703525\n",
      "train loss:0.003879731802298305\n",
      "train loss:0.0016453155097024184\n",
      "train loss:0.00038984533608124345\n",
      "train loss:0.0005903355661984086\n",
      "train loss:0.0005521900611004641\n",
      "train loss:0.0006497799577572869\n",
      "train loss:0.0002568682383958215\n",
      "train loss:0.0007119255509557385\n",
      "train loss:0.00032506124576667906\n",
      "train loss:0.009897802861662038\n",
      "train loss:0.004216752180553426\n",
      "train loss:0.0007194567343969587\n",
      "=== epoch:18, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.0001334897319008038\n",
      "train loss:0.0007970983683054954\n",
      "train loss:0.00036496150485103486\n",
      "train loss:0.0008444912848086991\n",
      "train loss:0.002388553819948402\n",
      "train loss:0.00012916910645692958\n",
      "train loss:0.00019350767509677112\n",
      "train loss:0.001759661707700923\n",
      "train loss:0.0015065661224477995\n",
      "train loss:0.001838932110705809\n",
      "train loss:0.0009146355781589397\n",
      "train loss:0.000681693446928398\n",
      "train loss:0.0035180593304444075\n",
      "train loss:0.0007333691165382713\n",
      "train loss:0.0020650885465418973\n",
      "train loss:0.0026248396078662837\n",
      "train loss:0.0002246756089475902\n",
      "train loss:0.005899612917952793\n",
      "train loss:0.0002701229517062004\n",
      "train loss:0.0001264432704172399\n",
      "train loss:0.00044891472609449564\n",
      "train loss:0.00023192928833307304\n",
      "train loss:0.0027172259454571602\n",
      "train loss:0.001412164212781285\n",
      "train loss:0.0009434184260517606\n",
      "train loss:0.0010825408304278394\n",
      "train loss:0.00217867360486877\n",
      "train loss:0.0006164199671497007\n",
      "train loss:0.0009771860716746997\n",
      "train loss:0.0014116253679443184\n",
      "train loss:0.0011067483012981202\n",
      "train loss:0.0009850375090904575\n",
      "train loss:0.001156722613447774\n",
      "train loss:0.0005989474988407635\n",
      "train loss:0.00048491860479945843\n",
      "train loss:0.001974408141889564\n",
      "train loss:0.0003016041280818949\n",
      "train loss:0.001371821736868852\n",
      "train loss:0.0004081453762265642\n",
      "train loss:0.00115303860173007\n",
      "train loss:0.0011338990289378585\n",
      "train loss:0.001986133626952498\n",
      "train loss:0.0013650452689263235\n",
      "train loss:0.00032256150110998425\n",
      "train loss:0.0010589610965607574\n",
      "train loss:0.0005651647791290445\n",
      "train loss:0.0018321821148297498\n",
      "train loss:0.0020423632988097033\n",
      "train loss:0.0001048980248290525\n",
      "train loss:0.00022305840463232173\n",
      "train loss:0.000965072236616606\n",
      "train loss:0.0003320342236921146\n",
      "train loss:0.0011146279163903674\n",
      "train loss:0.0010614619714120377\n",
      "train loss:0.000220301021726801\n",
      "train loss:0.0055827593060129325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5687276400615435e-05\n",
      "train loss:0.00023698049160004924\n",
      "train loss:0.0061654985258949545\n",
      "train loss:0.00013641680065282308\n",
      "train loss:0.005050247974528521\n",
      "train loss:0.0042051854847644085\n",
      "train loss:0.0013943508757265862\n",
      "train loss:0.004933302180860943\n",
      "train loss:0.0002169752467519467\n",
      "train loss:0.003169300346181997\n",
      "train loss:0.004537686888221666\n",
      "train loss:0.009994814610283967\n",
      "train loss:0.004627874703332837\n",
      "train loss:0.0019955765025474583\n",
      "train loss:0.0038966586222736344\n",
      "train loss:0.0004920722016644773\n",
      "train loss:0.0049650066410504715\n",
      "train loss:0.00022976780162820755\n",
      "train loss:0.0006636383923362173\n",
      "train loss:4.098374357040996e-05\n",
      "train loss:2.9445004651846454e-05\n",
      "train loss:0.002758958932291987\n",
      "train loss:0.0006573118957861877\n",
      "train loss:0.0013527485408131577\n",
      "train loss:0.0066911910171025095\n",
      "train loss:0.000732189604821416\n",
      "train loss:0.0017170439276851155\n",
      "train loss:0.0062286628823765774\n",
      "train loss:0.000733183555327727\n",
      "train loss:0.001731857463563304\n",
      "train loss:0.005949049671788852\n",
      "train loss:0.0023572088562060535\n",
      "train loss:0.002731143811251328\n",
      "train loss:0.0009643160581177944\n",
      "train loss:0.0017775197903735329\n",
      "train loss:0.0020426991173073147\n",
      "train loss:0.0028916473987225465\n",
      "train loss:0.0009932887799526007\n",
      "train loss:0.0019724589041450772\n",
      "train loss:0.00013776066879906624\n",
      "train loss:0.00038623451083692224\n",
      "train loss:0.000957432712280604\n",
      "train loss:0.000620193142959508\n",
      "train loss:0.0014773663500703372\n",
      "train loss:0.004480375901455369\n",
      "train loss:0.00018308878803139917\n",
      "train loss:0.016287316554486238\n",
      "train loss:0.0012747729098258867\n",
      "train loss:0.012940401998854975\n",
      "train loss:0.0019205007735203284\n",
      "train loss:0.0003090985123135706\n",
      "train loss:0.0019325121959495955\n",
      "train loss:0.00022982962477580187\n",
      "train loss:0.00019903223502990578\n",
      "train loss:0.0012545458484626787\n",
      "train loss:0.00029629243277093674\n",
      "train loss:0.0010191179209806773\n",
      "train loss:0.0058072046200121265\n",
      "train loss:0.02135294664277242\n",
      "train loss:0.00012868097186961673\n",
      "train loss:2.1387011529426953e-05\n",
      "train loss:0.0001784435784134566\n",
      "train loss:0.0005756901174801825\n",
      "train loss:0.00022504460035156204\n",
      "train loss:0.00027120759763613473\n",
      "train loss:0.0014827765444655322\n",
      "train loss:0.0007405429760644678\n",
      "train loss:0.0008602557171063418\n",
      "train loss:0.0019071697783163177\n",
      "train loss:0.0007893542180435109\n",
      "train loss:0.0022846969239086255\n",
      "train loss:0.0014867412672798282\n",
      "train loss:0.0013743073391873062\n",
      "train loss:0.0015468946366208128\n",
      "train loss:0.0004198096315348278\n",
      "train loss:0.0011843111038969318\n",
      "train loss:0.0008258138533915416\n",
      "train loss:4.356868592638937e-05\n",
      "train loss:0.002357882144633227\n",
      "train loss:0.0007178663163110142\n",
      "train loss:0.0007023193949641922\n",
      "train loss:0.0032525400789219483\n",
      "train loss:0.001247852457269876\n",
      "train loss:0.0009355381458358286\n",
      "train loss:0.00032598151965087787\n",
      "train loss:0.00022787907157841364\n",
      "train loss:0.0012925648835956877\n",
      "train loss:0.005191846512557318\n",
      "train loss:0.003908466614395007\n",
      "train loss:0.0007121096505756415\n",
      "train loss:0.002414487728859769\n",
      "train loss:0.000521801207572164\n",
      "train loss:0.0010179295430086807\n",
      "train loss:0.0013571981281167572\n",
      "train loss:0.00044320830152828574\n",
      "train loss:0.001410733863808428\n",
      "train loss:0.0032371172565702445\n",
      "train loss:0.002470239984834071\n",
      "train loss:0.00031138174009030957\n",
      "train loss:0.0003993005215141203\n",
      "train loss:0.0023722435016050565\n",
      "train loss:0.0005189131388835252\n",
      "train loss:0.0022737096603568942\n",
      "train loss:0.0003804271195955394\n",
      "train loss:0.0005228268102090602\n",
      "train loss:0.0027708380063408\n",
      "train loss:0.0034875325752074817\n",
      "train loss:0.00015589191020906447\n",
      "train loss:0.02570563260142915\n",
      "train loss:0.005068226072518234\n",
      "train loss:0.0005452076262122495\n",
      "train loss:0.003504743820894837\n",
      "train loss:0.00043315415774296083\n",
      "train loss:0.0008209188979322655\n",
      "train loss:0.001780575267542123\n",
      "train loss:0.00029423549299761214\n",
      "train loss:0.00021380643697860597\n",
      "train loss:0.0004475919588864689\n",
      "train loss:0.0019064658204041105\n",
      "train loss:0.0026463640970008384\n",
      "train loss:0.00037773808256644974\n",
      "train loss:0.002938736055111359\n",
      "train loss:0.0020447131562534426\n",
      "train loss:0.0019510715167467697\n",
      "train loss:0.0011888773612178487\n",
      "train loss:0.002439085920739185\n",
      "train loss:0.00028216887532622905\n",
      "train loss:0.0001196005642705871\n",
      "train loss:0.0018439608327082218\n",
      "train loss:7.361213439268767e-05\n",
      "train loss:0.00047821958304600996\n",
      "train loss:0.00016197304248500652\n",
      "train loss:0.0016328834500498165\n",
      "train loss:0.0037139260997881996\n",
      "train loss:0.000722265283847378\n",
      "train loss:0.0002575240343549894\n",
      "train loss:0.0022338164045556806\n",
      "train loss:0.0003384770194289742\n",
      "train loss:0.001395379767666102\n",
      "train loss:0.0019521118733840028\n",
      "train loss:0.0005411324778906719\n",
      "train loss:0.0002511864050030982\n",
      "train loss:0.0014787315380036285\n",
      "train loss:0.002097887201270695\n",
      "train loss:0.0015004123422255019\n",
      "train loss:0.001571773720430656\n",
      "train loss:0.00032618332760312845\n",
      "train loss:0.0009540336191335402\n",
      "train loss:0.0010514717034078806\n",
      "train loss:7.741613175238257e-05\n",
      "train loss:0.0012327096754287778\n",
      "train loss:0.0010989801702935157\n",
      "train loss:0.0006492439274674702\n",
      "train loss:0.000434761144001151\n",
      "train loss:0.00010614792120843103\n",
      "train loss:0.0004090151510807413\n",
      "train loss:0.007754647091308139\n",
      "train loss:9.69501767819099e-05\n",
      "train loss:0.005933095560650814\n",
      "train loss:0.0017559270895424054\n",
      "train loss:0.00022490718862818815\n",
      "train loss:0.0002246652255335659\n",
      "train loss:0.00136042449884225\n",
      "train loss:0.002789833385022754\n",
      "train loss:0.002667152717394723\n",
      "train loss:0.0009971268436202258\n",
      "train loss:0.00019766413136518903\n",
      "train loss:0.0002806442445439409\n",
      "train loss:0.0005323396965483278\n",
      "train loss:0.0022035965637432057\n",
      "train loss:0.0007731367034604141\n",
      "train loss:0.0015577527983826188\n",
      "train loss:0.0006801336439133392\n",
      "train loss:0.0006818458884300027\n",
      "train loss:0.0002795614138493787\n",
      "train loss:0.0002057823126699689\n",
      "train loss:0.0016510448180563613\n",
      "train loss:0.0038473608898181373\n",
      "train loss:0.0014462185401409875\n",
      "train loss:0.005020182159436021\n",
      "train loss:0.00014755430919034384\n",
      "train loss:0.0012897941123291875\n",
      "train loss:0.00043346624427897137\n",
      "train loss:0.00012703543396023204\n",
      "train loss:0.003160279475483384\n",
      "train loss:0.00031757520711893876\n",
      "train loss:0.0014288567538532223\n",
      "train loss:0.00030799522313786814\n",
      "train loss:0.0003083333705196443\n",
      "train loss:0.008065354926001704\n",
      "train loss:0.0008245694184521418\n",
      "train loss:0.002358235138605482\n",
      "train loss:0.0009024069205519614\n",
      "train loss:0.00014657703737574763\n",
      "train loss:0.003135412369967356\n",
      "train loss:0.001904859384044905\n",
      "train loss:0.0017737749773955374\n",
      "train loss:0.0003238400818222804\n",
      "train loss:0.0005450735658532666\n",
      "train loss:0.0033776295888335657\n",
      "train loss:0.0009850825349198243\n",
      "train loss:0.00029329111459854\n",
      "train loss:0.0006875127249676345\n",
      "train loss:0.0025575263309266794\n",
      "train loss:0.00010981426420781374\n",
      "train loss:0.0009943993895266817\n",
      "train loss:0.004925495677061114\n",
      "train loss:0.0002870814893701454\n",
      "train loss:0.014091988376892538\n",
      "train loss:0.00016756741959653192\n",
      "train loss:0.0004839191839718502\n",
      "train loss:0.0009115191572939196\n",
      "train loss:0.0032640456008571793\n",
      "train loss:0.0001602024746628544\n",
      "train loss:0.0010344539567848506\n",
      "train loss:0.0007078269418725079\n",
      "train loss:0.0011278242105317493\n",
      "train loss:0.002210928290260412\n",
      "train loss:0.0010404631966414227\n",
      "train loss:0.0019201319233834396\n",
      "train loss:0.0010868505008843699\n",
      "train loss:4.518567557770094e-05\n",
      "train loss:0.003006898272887389\n",
      "train loss:0.00044427550622267565\n",
      "train loss:0.0033467907440009313\n",
      "train loss:0.0049940997010088336\n",
      "train loss:0.0013922090030591336\n",
      "train loss:0.00012671394247388917\n",
      "train loss:0.0007844235917558016\n",
      "train loss:0.000668221482759521\n",
      "train loss:0.0033993019241271615\n",
      "train loss:8.415330024250481e-06\n",
      "train loss:0.00012760207564837335\n",
      "train loss:0.003091321198145291\n",
      "train loss:0.0004912959537206976\n",
      "train loss:0.0018005651473642624\n",
      "train loss:8.742913440652507e-05\n",
      "train loss:0.00024252143334459213\n",
      "train loss:0.0013654450042523303\n",
      "train loss:0.0008772162062680297\n",
      "train loss:0.0012317445662906783\n",
      "train loss:0.001076701503993845\n",
      "train loss:0.0001583983051293322\n",
      "train loss:0.006036779140134255\n",
      "train loss:0.00019376699813558325\n",
      "train loss:0.00040403969470968894\n",
      "train loss:0.00011153942137143292\n",
      "train loss:0.0033052478242167733\n",
      "train loss:0.0001880509360771952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018098909379149245\n",
      "train loss:0.0005880536101796538\n",
      "train loss:0.008892258726930337\n",
      "train loss:0.0019019779805206857\n",
      "train loss:9.167222641857544e-05\n",
      "train loss:7.316084838976034e-05\n",
      "train loss:8.836188594255971e-05\n",
      "train loss:0.0002012715436212044\n",
      "train loss:0.003420730703872079\n",
      "train loss:0.002563013109443923\n",
      "train loss:0.0007133138623606083\n",
      "train loss:0.00023401877381954095\n",
      "train loss:0.0053407168267984115\n",
      "train loss:0.005549023290190742\n",
      "train loss:7.595665360839111e-05\n",
      "train loss:0.013186497331628785\n",
      "train loss:0.00025995951347430266\n",
      "train loss:0.0002505588370655577\n",
      "train loss:0.0026898690623262055\n",
      "train loss:0.003853713543387365\n",
      "train loss:0.007615127228804522\n",
      "train loss:0.0013344854609313285\n",
      "train loss:0.0005647090076492386\n",
      "train loss:0.0025321933755746884\n",
      "train loss:9.872225163101662e-05\n",
      "train loss:0.004198553292240256\n",
      "train loss:0.003148952907041432\n",
      "train loss:0.0009884591535047134\n",
      "train loss:0.0010447166209472684\n",
      "train loss:0.0010587572229879805\n",
      "train loss:0.0005906481372578369\n",
      "train loss:0.002138235921812153\n",
      "train loss:0.00012919795406408845\n",
      "train loss:0.000991519115765202\n",
      "train loss:0.004894597324964315\n",
      "train loss:0.0038167146439664836\n",
      "train loss:0.0008900138540439833\n",
      "train loss:0.00025149085043128566\n",
      "train loss:0.014100609125798951\n",
      "train loss:0.0007734902169049155\n",
      "train loss:0.0004289122009528773\n",
      "train loss:0.000723948320564796\n",
      "train loss:0.0022651109608087723\n",
      "train loss:0.001222967353762442\n",
      "train loss:0.003482778682668542\n",
      "train loss:0.004557314244300326\n",
      "train loss:0.0004437883072910423\n",
      "train loss:0.002354338979026661\n",
      "train loss:8.750672355250308e-05\n",
      "train loss:0.012721365118308996\n",
      "train loss:0.0026998580359029545\n",
      "train loss:0.0004309528853471087\n",
      "train loss:0.0017991018223726541\n",
      "train loss:0.0022654162975311444\n",
      "train loss:0.0005476786598563199\n",
      "train loss:0.00037131675919047\n",
      "train loss:0.0007428713223702665\n",
      "train loss:0.0003913134917845663\n",
      "train loss:0.008774491594328674\n",
      "train loss:0.002383635994859125\n",
      "train loss:0.0015550022152416682\n",
      "train loss:0.0008420526140293844\n",
      "train loss:0.0001246587790197855\n",
      "train loss:0.0019145062596863994\n",
      "train loss:0.009269791981597225\n",
      "train loss:0.0006134261894648028\n",
      "train loss:0.014997072747721201\n",
      "train loss:0.00013442834296413796\n",
      "train loss:0.005085328655742876\n",
      "train loss:0.00010318797583908853\n",
      "train loss:0.002134487457796722\n",
      "train loss:0.00015119660706011068\n",
      "train loss:0.00013386931606691066\n",
      "train loss:0.0010476345059803201\n",
      "train loss:0.000241650981053288\n",
      "train loss:0.00015356509408088448\n",
      "train loss:0.003764471703023164\n",
      "train loss:0.002115088325540282\n",
      "train loss:0.0009445982795381148\n",
      "train loss:0.0037440191552911522\n",
      "train loss:0.0024739669912347832\n",
      "train loss:0.0008478546546801871\n",
      "train loss:0.0004497912348219944\n",
      "train loss:0.0006769061415392213\n",
      "train loss:0.0026933941785318933\n",
      "train loss:0.0014131206875836685\n",
      "train loss:0.0014160379418284492\n",
      "train loss:0.0015503279346832691\n",
      "train loss:0.0027277574962012263\n",
      "train loss:0.0012098101418064257\n",
      "train loss:0.0026207371141029902\n",
      "train loss:0.015689728223223745\n",
      "train loss:0.0007114770410335441\n",
      "train loss:0.0029117855566542627\n",
      "train loss:0.0012626479934569456\n",
      "train loss:0.0002767743526040747\n",
      "train loss:0.0005019799162196324\n",
      "train loss:0.0015640977399481529\n",
      "train loss:0.0010704620352185244\n",
      "train loss:0.002723763836165659\n",
      "train loss:0.0012610679150700235\n",
      "train loss:0.0019441060833644919\n",
      "train loss:0.002920882982495666\n",
      "train loss:0.0017112045760462585\n",
      "train loss:0.002750364427380582\n",
      "train loss:0.0014186687716856664\n",
      "train loss:0.0030314327481963162\n",
      "train loss:0.0033221715082346072\n",
      "train loss:0.0022895123614401396\n",
      "train loss:0.00215452996515443\n",
      "train loss:0.00039882462503192437\n",
      "train loss:0.0007760811609569925\n",
      "train loss:4.3963394023480834e-05\n",
      "train loss:0.014823633585122334\n",
      "train loss:0.0002999621642254718\n",
      "train loss:0.0021402625402256485\n",
      "train loss:0.001374431216050401\n",
      "train loss:0.00047925798500698605\n",
      "train loss:0.00056286482017449\n",
      "train loss:0.003532334172990351\n",
      "train loss:0.004833358078688044\n",
      "train loss:0.00013338514482890833\n",
      "train loss:0.0021300722212712346\n",
      "train loss:0.0009872485922994708\n",
      "train loss:0.0013210238489124598\n",
      "train loss:0.0001652943414922934\n",
      "train loss:0.0020103161342663062\n",
      "train loss:0.0019627364390681513\n",
      "train loss:0.0032627323064688346\n",
      "train loss:0.011891973862145572\n",
      "train loss:0.007130034892441671\n",
      "train loss:2.710541577215328e-05\n",
      "train loss:0.001617880352873613\n",
      "train loss:0.009017317419483471\n",
      "train loss:0.01241827758864784\n",
      "train loss:0.0007683550242609481\n",
      "train loss:0.0035275747464920074\n",
      "train loss:0.00017944224333043345\n",
      "train loss:0.005227013164566655\n",
      "train loss:0.0019187970896312292\n",
      "train loss:0.004355773418317692\n",
      "train loss:0.02641858432380626\n",
      "train loss:0.0008827318803055354\n",
      "train loss:0.00040880838473209176\n",
      "train loss:0.001372795839149872\n",
      "train loss:0.000688208463360049\n",
      "train loss:0.00031337017947487354\n",
      "train loss:0.0031181910310174145\n",
      "train loss:0.03409451830971101\n",
      "train loss:0.002712700913181037\n",
      "train loss:0.0011270275801941532\n",
      "train loss:0.002270926566739789\n",
      "train loss:0.0032235431818667943\n",
      "train loss:0.003263068376389865\n",
      "train loss:7.143403283922223e-05\n",
      "train loss:0.005812167164316178\n",
      "train loss:0.00016051031175524192\n",
      "train loss:0.00020765898563355155\n",
      "train loss:0.0011251348430491074\n",
      "train loss:0.002076237323834847\n",
      "train loss:0.007191325556733393\n",
      "train loss:0.01880009411007293\n",
      "train loss:0.004001778585346809\n",
      "train loss:0.002318733566693316\n",
      "train loss:0.0005313618840792058\n",
      "train loss:5.18495151910631e-05\n",
      "train loss:0.0035403811772854966\n",
      "train loss:0.0007724648220123722\n",
      "train loss:0.0003804066408113257\n",
      "train loss:0.004164861722771585\n",
      "train loss:0.0045451598056714245\n",
      "train loss:0.00100545019593733\n",
      "train loss:0.000464850458241489\n",
      "train loss:0.015367781132838064\n",
      "train loss:0.001979909147540149\n",
      "train loss:0.0005549893490736907\n",
      "train loss:0.003741466226019867\n",
      "train loss:0.0009225796512445575\n",
      "train loss:0.0006081628547293155\n",
      "train loss:0.0014745196120039955\n",
      "train loss:0.012830026284700938\n",
      "train loss:0.0025626598710571697\n",
      "train loss:0.0009503030335778538\n",
      "train loss:0.00018394271520192978\n",
      "train loss:0.0002607197923512485\n",
      "train loss:0.000292902203097226\n",
      "train loss:0.0006549398327799207\n",
      "train loss:0.0014701395414864341\n",
      "train loss:0.00011579232005689482\n",
      "train loss:0.0007927966660481646\n",
      "train loss:0.004168530468270399\n",
      "train loss:0.0008309495730614884\n",
      "train loss:0.00698253294462521\n",
      "train loss:0.0008402590991068741\n",
      "train loss:0.005675963219118895\n",
      "train loss:0.0012921987813374258\n",
      "train loss:0.0007162840636556759\n",
      "train loss:0.0008484956774526167\n",
      "train loss:0.0033333954226987582\n",
      "train loss:0.008399091434993467\n",
      "train loss:0.0002602817588376365\n",
      "train loss:0.0024060523543443014\n",
      "train loss:0.0005918377437972965\n",
      "train loss:0.0009118072355456763\n",
      "train loss:0.0024888137239966702\n",
      "train loss:0.000237917189571819\n",
      "train loss:6.325026096593786e-06\n",
      "train loss:4.85302746986034e-05\n",
      "train loss:0.00012852325702712126\n",
      "train loss:0.028842310852457677\n",
      "train loss:5.979069773164814e-05\n",
      "train loss:0.002689533738923958\n",
      "train loss:0.0028482162229721934\n",
      "train loss:6.788688248169268e-05\n",
      "train loss:0.0005911489847692024\n",
      "train loss:0.0005802262278325217\n",
      "train loss:0.0008956653806560516\n",
      "train loss:0.0015929758252647387\n",
      "train loss:0.00020857278626882557\n",
      "train loss:0.0037707073237595854\n",
      "train loss:0.0017772401874685325\n",
      "train loss:0.00024275853887839875\n",
      "train loss:0.003950858439786162\n",
      "train loss:0.01139897823127564\n",
      "train loss:0.0006875620992197523\n",
      "train loss:0.0008218366702766313\n",
      "train loss:0.00041545278229196446\n",
      "train loss:0.011447382699658469\n",
      "train loss:0.00026592569252519526\n",
      "train loss:0.0023595157876396735\n",
      "train loss:0.0008190461339043216\n",
      "train loss:2.788978216788053e-05\n",
      "train loss:0.00014552864617077012\n",
      "train loss:0.0034819261622283477\n",
      "train loss:0.0011224331292042573\n",
      "train loss:0.0002238155688081767\n",
      "train loss:3.06771695927717e-05\n",
      "train loss:0.005710038162834004\n",
      "train loss:0.00044235908909714684\n",
      "train loss:0.0014127717527280714\n",
      "train loss:0.0009272983380108857\n",
      "train loss:3.4932001224344184e-05\n",
      "train loss:0.0011439074218794244\n",
      "train loss:0.001313685186541565\n",
      "train loss:0.0016684754845592087\n",
      "train loss:1.1567560673999264e-05\n",
      "train loss:0.0037153880812729394\n",
      "train loss:0.0002250500563585127\n",
      "train loss:0.0006509202865255605\n",
      "train loss:0.0017498290658547319\n",
      "train loss:0.005183609408503377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001248234823989139\n",
      "train loss:0.0029689073575319587\n",
      "train loss:0.0007940252611079479\n",
      "train loss:0.000166283112416898\n",
      "train loss:0.0009345927101121123\n",
      "train loss:0.0010086873882380791\n",
      "train loss:0.007928194760893043\n",
      "train loss:0.00027009276098586025\n",
      "train loss:0.009532090161876297\n",
      "train loss:0.0018075638053489833\n",
      "train loss:0.0002532394717983341\n",
      "train loss:0.0010579748873047047\n",
      "train loss:0.002870032247938829\n",
      "train loss:0.0032557575801326496\n",
      "train loss:0.002859708403823509\n",
      "train loss:0.00041368365554762766\n",
      "train loss:0.000282465614405492\n",
      "train loss:0.0005488046750230922\n",
      "train loss:0.0003894519721187811\n",
      "train loss:0.0007074189133444675\n",
      "train loss:6.899408760798589e-05\n",
      "train loss:0.00038872992014284374\n",
      "train loss:0.0010389051572061642\n",
      "train loss:0.0011660558737860032\n",
      "train loss:0.023734516696933872\n",
      "train loss:0.00041659996096457346\n",
      "train loss:0.00044044789785391216\n",
      "train loss:0.003872322359807033\n",
      "train loss:0.0006743954837719608\n",
      "train loss:0.00016665877336657648\n",
      "train loss:0.0009114334483205036\n",
      "train loss:0.0028887081425060385\n",
      "train loss:0.00094778290461031\n",
      "train loss:0.004193560536386714\n",
      "train loss:5.5998459185592546e-05\n",
      "train loss:0.0001616911191373668\n",
      "train loss:4.89810774975987e-05\n",
      "train loss:0.000476983715167556\n",
      "train loss:0.002746109360068832\n",
      "train loss:0.0008746559034651527\n",
      "train loss:0.0005798740083791927\n",
      "train loss:9.58828839256031e-05\n",
      "train loss:0.00040068129165428705\n",
      "train loss:0.003786827453228816\n",
      "=== epoch:19, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0008031481988031477\n",
      "train loss:0.0018385151427977484\n",
      "train loss:0.00036243076245509625\n",
      "train loss:0.0006943882301796156\n",
      "train loss:0.00023746187547981046\n",
      "train loss:0.0006789228695183426\n",
      "train loss:0.003022502413604613\n",
      "train loss:5.932319679145221e-05\n",
      "train loss:0.0001421483565428028\n",
      "train loss:0.0005035582785464222\n",
      "train loss:0.00019075322078902684\n",
      "train loss:0.00115442289984884\n",
      "train loss:0.0006849584813997905\n",
      "train loss:0.0003715155412169623\n",
      "train loss:0.0001414896534579652\n",
      "train loss:0.0014986678889930616\n",
      "train loss:0.002226952084588561\n",
      "train loss:0.0004730260182690249\n",
      "train loss:4.875028587110637e-05\n",
      "train loss:0.00034954203040895026\n",
      "train loss:0.00010163205154131662\n",
      "train loss:0.0010001714256578447\n",
      "train loss:0.00028330928802336447\n",
      "train loss:0.0001672677213843965\n",
      "train loss:0.0011191227095737404\n",
      "train loss:0.00025923565538300597\n",
      "train loss:0.0034182275580264\n",
      "train loss:0.0006512952597578589\n",
      "train loss:0.0002382198313746618\n",
      "train loss:9.330944999433723e-05\n",
      "train loss:0.011248996574863737\n",
      "train loss:0.0017973769987358675\n",
      "train loss:0.00011437010293960971\n",
      "train loss:0.003222759067367269\n",
      "train loss:0.0007633211836202705\n",
      "train loss:0.0010612430612364397\n",
      "train loss:0.0001897738883155689\n",
      "train loss:7.059103382886549e-05\n",
      "train loss:0.0032361229321026374\n",
      "train loss:0.0012684209461800227\n",
      "train loss:0.003096909909005643\n",
      "train loss:0.00013501058867797583\n",
      "train loss:0.00019133173025543865\n",
      "train loss:0.0002656544189044359\n",
      "train loss:0.00419252086655921\n",
      "train loss:6.471118969888908e-05\n",
      "train loss:0.0006757243135871568\n",
      "train loss:0.0025600068831747565\n",
      "train loss:0.000609756580192885\n",
      "train loss:0.0021051914771951894\n",
      "train loss:0.000879913261852952\n",
      "train loss:0.005281941939662142\n",
      "train loss:0.00014030076136882098\n",
      "train loss:7.679204315389579e-05\n",
      "train loss:0.003187838094530428\n",
      "train loss:0.0032437058604205854\n",
      "train loss:0.0006187429203647791\n",
      "train loss:0.0004560524876760114\n",
      "train loss:0.00022287889182473098\n",
      "train loss:0.0005759512363861563\n",
      "train loss:0.00021458510833295602\n",
      "train loss:0.00022729646795854034\n",
      "train loss:0.0012695350495655758\n",
      "train loss:0.016501727580024154\n",
      "train loss:0.006632131460628607\n",
      "train loss:0.0002251387223963225\n",
      "train loss:0.0005623700355785836\n",
      "train loss:0.0013757941653213136\n",
      "train loss:0.00344923972083563\n",
      "train loss:0.0001018909774118961\n",
      "train loss:0.0010923072482828128\n",
      "train loss:0.00037457256087526354\n",
      "train loss:0.00017468978585550768\n",
      "train loss:0.007834375874815428\n",
      "train loss:0.0020210955995525214\n",
      "train loss:0.0027255693978036535\n",
      "train loss:7.200689985632696e-05\n",
      "train loss:0.001089486135636438\n",
      "train loss:0.003538138342988104\n",
      "train loss:0.001015480154136552\n",
      "train loss:0.0002511983862867701\n",
      "train loss:0.0009184081359200654\n",
      "train loss:0.0010434720566515731\n",
      "train loss:0.00017149766000206494\n",
      "train loss:0.0050887775765208355\n",
      "train loss:9.391762885799115e-05\n",
      "train loss:0.0011619695152979808\n",
      "train loss:0.00523756668510798\n",
      "train loss:0.00045089053811016847\n",
      "train loss:0.0010284052589988213\n",
      "train loss:0.00043362655058721796\n",
      "train loss:0.013731541302496262\n",
      "train loss:0.0004601896790803626\n",
      "train loss:0.000135265567601327\n",
      "train loss:0.0016728318081687557\n",
      "train loss:0.0009590005333729745\n",
      "train loss:0.0008392056842004966\n",
      "train loss:0.0023518935543164945\n",
      "train loss:0.002695515966061894\n",
      "train loss:0.0010189426834807508\n",
      "train loss:0.0012965625872797177\n",
      "train loss:0.0004669503205630614\n",
      "train loss:8.818975015315906e-05\n",
      "train loss:0.000883575017343445\n",
      "train loss:0.003489977303802187\n",
      "train loss:0.0002645657695122764\n",
      "train loss:0.0009809963744408323\n",
      "train loss:0.0003356046009964066\n",
      "train loss:0.00029294652171731495\n",
      "train loss:0.00654866379284844\n",
      "train loss:0.0016013450697117074\n",
      "train loss:0.0002679378458432809\n",
      "train loss:0.0008164755438649501\n",
      "train loss:0.0008511731532313022\n",
      "train loss:0.0002817835437289058\n",
      "train loss:0.0004564740319910291\n",
      "train loss:0.0003290017861140367\n",
      "train loss:0.0001959135477667244\n",
      "train loss:0.00013144597107802563\n",
      "train loss:0.004227994406752583\n",
      "train loss:0.0007494679619970441\n",
      "train loss:0.0004662476900398642\n",
      "train loss:0.0004129044419359977\n",
      "train loss:0.00054482329887647\n",
      "train loss:0.0005337919300985698\n",
      "train loss:0.0007934436640107712\n",
      "train loss:0.0051061135486221475\n",
      "train loss:0.00040848864839849064\n",
      "train loss:0.0008994947460713889\n",
      "train loss:0.0003481643322098137\n",
      "train loss:0.00013740883084490408\n",
      "train loss:0.002111914188530239\n",
      "train loss:0.0016945483199877279\n",
      "train loss:0.0003909390160936391\n",
      "train loss:0.0007418583708892289\n",
      "train loss:0.0005963310866379922\n",
      "train loss:0.0014592972947489297\n",
      "train loss:0.00042033355674122094\n",
      "train loss:0.0002342038377601765\n",
      "train loss:0.00045408482706221824\n",
      "train loss:0.0009018389200203703\n",
      "train loss:0.0003051115801692057\n",
      "train loss:3.79325451704351e-05\n",
      "train loss:0.0007286662696153434\n",
      "train loss:0.00020985433169779942\n",
      "train loss:0.0003932534832312722\n",
      "train loss:0.0015640545469182325\n",
      "train loss:0.00036729329223005855\n",
      "train loss:0.0012805165227981208\n",
      "train loss:0.025285597868976425\n",
      "train loss:0.0008582683881059028\n",
      "train loss:0.00020789451966030112\n",
      "train loss:7.470058478514107e-05\n",
      "train loss:0.0019028828373813228\n",
      "train loss:0.0006993099826220305\n",
      "train loss:0.0008055260009163676\n",
      "train loss:0.0032383840284778615\n",
      "train loss:0.002372711357107723\n",
      "train loss:0.0013947063916141963\n",
      "train loss:0.001947394243306147\n",
      "train loss:0.0018699229122709764\n",
      "train loss:0.0009648294237760976\n",
      "train loss:0.0011546593113486983\n",
      "train loss:0.008772884403469114\n",
      "train loss:0.0004542983638817205\n",
      "train loss:0.0029979989145173034\n",
      "train loss:0.0026276041619516448\n",
      "train loss:0.007453009750750703\n",
      "train loss:0.0005058695419198469\n",
      "train loss:0.0025464078098658216\n",
      "train loss:0.00010140414478452417\n",
      "train loss:0.0001572065086393903\n",
      "train loss:0.0005717187690605501\n",
      "train loss:0.0010354981566404746\n",
      "train loss:0.0031691962567169025\n",
      "train loss:0.0017720872588017536\n",
      "train loss:0.0018040982761604078\n",
      "train loss:0.005738912751151365\n",
      "train loss:0.004991429396624236\n",
      "train loss:0.0003817514550734595\n",
      "train loss:0.0008246777877723259\n",
      "train loss:0.0004181054395481892\n",
      "train loss:0.00041731268020973785\n",
      "train loss:0.00014475017744311618\n",
      "train loss:0.0007147875855848801\n",
      "train loss:0.0003025976620464333\n",
      "train loss:0.0016616345355503948\n",
      "train loss:0.00035131850814247795\n",
      "train loss:0.0005019129991076679\n",
      "train loss:0.003445351711359383\n",
      "train loss:0.0016831839218267436\n",
      "train loss:9.100014490239835e-05\n",
      "train loss:0.0001062356295321979\n",
      "train loss:0.006101416096669647\n",
      "train loss:0.0006610264578740319\n",
      "train loss:0.011092049152962816\n",
      "train loss:0.002094557531458881\n",
      "train loss:0.0003212841116596208\n",
      "train loss:0.000983370719926363\n",
      "train loss:0.0027358497099597644\n",
      "train loss:0.0037615072638016627\n",
      "train loss:0.0038253296128286903\n",
      "train loss:0.0019136570147741411\n",
      "train loss:0.0013735465357273436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0020374224823902975\n",
      "train loss:0.0010660071593820597\n",
      "train loss:0.0009042319876320228\n",
      "train loss:0.00012608383904989256\n",
      "train loss:0.0008277429422958266\n",
      "train loss:0.00386927870615375\n",
      "train loss:0.00039520483404210466\n",
      "train loss:0.00411538484613884\n",
      "train loss:0.0020539645039953443\n",
      "train loss:0.015074994899163816\n",
      "train loss:0.001683457836380857\n",
      "train loss:0.0013411966484033187\n",
      "train loss:9.336669539114652e-05\n",
      "train loss:0.002675106373215784\n",
      "train loss:0.004429234000559341\n",
      "train loss:0.00021349052098729813\n",
      "train loss:0.00029277290105384033\n",
      "train loss:0.0009244039479249559\n",
      "train loss:0.0005118166107835268\n",
      "train loss:0.00269412897278109\n",
      "train loss:0.001980585884461453\n",
      "train loss:0.0008259083006729115\n",
      "train loss:0.003944754820819078\n",
      "train loss:0.0022284172066454637\n",
      "train loss:3.524175510496087e-05\n",
      "train loss:0.007728444896844804\n",
      "train loss:0.0022477224317418508\n",
      "train loss:0.00031357919584182293\n",
      "train loss:0.0005727038022670805\n",
      "train loss:0.003036637991539615\n",
      "train loss:0.013442177479323542\n",
      "train loss:0.001546352032702654\n",
      "train loss:0.007447180427733099\n",
      "train loss:7.913152559815378e-05\n",
      "train loss:0.00023987791035472\n",
      "train loss:0.001029074557448144\n",
      "train loss:0.0014637181808484405\n",
      "train loss:0.0018411440397246592\n",
      "train loss:0.0032263679939608077\n",
      "train loss:0.00010367192678069947\n",
      "train loss:0.00042831498306232534\n",
      "train loss:0.0003604262690631099\n",
      "train loss:0.0004149284676725762\n",
      "train loss:0.0002823746162260721\n",
      "train loss:0.0019297279976440373\n",
      "train loss:0.0010209897508681803\n",
      "train loss:0.038186447120969566\n",
      "train loss:0.0004182007903783422\n",
      "train loss:0.0007934479132454303\n",
      "train loss:0.0017830612202628993\n",
      "train loss:0.0005715903025254228\n",
      "train loss:0.0004615329798312044\n",
      "train loss:0.0004255207239135617\n",
      "train loss:0.0021941980483419095\n",
      "train loss:0.015066760326207287\n",
      "train loss:0.001908272130358124\n",
      "train loss:0.0011933197206353652\n",
      "train loss:0.0007017694719491681\n",
      "train loss:0.011320692971886476\n",
      "train loss:0.00039552924133941914\n",
      "train loss:0.0006514840866703188\n",
      "train loss:0.008582481762112308\n",
      "train loss:0.00034468896094636854\n",
      "train loss:0.0008637598803284738\n",
      "train loss:0.00012381867228078937\n",
      "train loss:0.0017281225642132125\n",
      "train loss:0.0005178679443627694\n",
      "train loss:0.0003538356498958391\n",
      "train loss:0.00020300465656159593\n",
      "train loss:0.0004326424299238583\n",
      "train loss:0.004213583769260667\n",
      "train loss:0.00609723275198168\n",
      "train loss:0.013249054840507092\n",
      "train loss:0.0032396840926856695\n",
      "train loss:0.0005211999656386163\n",
      "train loss:0.0009617015761174047\n",
      "train loss:0.0014022286847327153\n",
      "train loss:0.004049106589037052\n",
      "train loss:4.2881840621428665e-05\n",
      "train loss:0.0021846145236382912\n",
      "train loss:0.0001434965850212587\n",
      "train loss:0.002052011153963236\n",
      "train loss:0.0019309714691572125\n",
      "train loss:0.0028982149471843644\n",
      "train loss:0.00467570330358377\n",
      "train loss:0.0006704758794596638\n",
      "train loss:0.00033710735332061854\n",
      "train loss:0.00022303421267446617\n",
      "train loss:0.0003827230525253553\n",
      "train loss:0.0006527160813029645\n",
      "train loss:0.013276457823323736\n",
      "train loss:0.00036585454806057163\n",
      "train loss:0.0006390318562301835\n",
      "train loss:0.00047324720739868784\n",
      "train loss:0.00011042656636404354\n",
      "train loss:0.0007381134279777654\n",
      "train loss:0.00120138368415722\n",
      "train loss:0.00012495271244918212\n",
      "train loss:0.00017129306631473069\n",
      "train loss:0.0012044553924708016\n",
      "train loss:0.0006451942188054235\n",
      "train loss:0.0006360617318714773\n",
      "train loss:0.0012129003235855163\n",
      "train loss:0.003122682079978902\n",
      "train loss:0.005337975590324128\n",
      "train loss:0.0013823920072665405\n",
      "train loss:0.001952302650107432\n",
      "train loss:0.0003754387225062963\n",
      "train loss:0.0027502349552540276\n",
      "train loss:0.001031678411903792\n",
      "train loss:0.0005195086059277852\n",
      "train loss:1.695219349450513e-05\n",
      "train loss:0.0005811196379582335\n",
      "train loss:0.0004866942230310275\n",
      "train loss:0.00070564341178521\n",
      "train loss:0.00027736516292617885\n",
      "train loss:0.00025812343453229716\n",
      "train loss:8.634651391573998e-05\n",
      "train loss:0.0008391305500641598\n",
      "train loss:8.89772075799793e-05\n",
      "train loss:0.0005947664735273107\n",
      "train loss:0.006955219914289443\n",
      "train loss:0.0003638960490590863\n",
      "train loss:0.0017261405506769313\n",
      "train loss:0.001695880994847854\n",
      "train loss:0.00016216147241000824\n",
      "train loss:0.0011492238086524863\n",
      "train loss:0.0002688821405182927\n",
      "train loss:0.0002023367355139257\n",
      "train loss:0.0006511191502518131\n",
      "train loss:0.0005881433996383254\n",
      "train loss:0.001057305608098538\n",
      "train loss:0.0036592326845111254\n",
      "train loss:0.0010920900332847823\n",
      "train loss:0.00038423915838639876\n",
      "train loss:0.0015209914030622994\n",
      "train loss:0.0005620752165699641\n",
      "train loss:0.0013803551594438548\n",
      "train loss:5.561229700599624e-05\n",
      "train loss:0.0028140673435315088\n",
      "train loss:0.0016530844360286342\n",
      "train loss:0.000722062292907883\n",
      "train loss:0.003268055572239174\n",
      "train loss:0.0012557263833944178\n",
      "train loss:0.0004715246929144319\n",
      "train loss:0.0013737611468534006\n",
      "train loss:0.0026958219814280358\n",
      "train loss:0.0008837344922336057\n",
      "train loss:0.0004912612778207817\n",
      "train loss:0.0004005694106964049\n",
      "train loss:0.001749090756690567\n",
      "train loss:0.0018402955744190401\n",
      "train loss:0.0006841745443535428\n",
      "train loss:0.0035204846186053284\n",
      "train loss:0.0017514910456181473\n",
      "train loss:0.0006848102375117012\n",
      "train loss:0.001748724397357563\n",
      "train loss:0.0020945517722811306\n",
      "train loss:1.6625109683144085e-05\n",
      "train loss:0.0029497617391013864\n",
      "train loss:0.003219575723694418\n",
      "train loss:0.00039008029011126553\n",
      "train loss:0.0004292818093283912\n",
      "train loss:0.0005077401078359717\n",
      "train loss:0.000885977338046209\n",
      "train loss:0.0012223915241129637\n",
      "train loss:0.0005026509528343636\n",
      "train loss:0.00018981167509683324\n",
      "train loss:0.000271474211600023\n",
      "train loss:0.0006230437479560948\n",
      "train loss:0.0005691515314867644\n",
      "train loss:0.0012015911747638173\n",
      "train loss:0.00021354203718579388\n",
      "train loss:0.0019231435404254245\n",
      "train loss:0.0006771831858519489\n",
      "train loss:0.0002022642079392175\n",
      "train loss:0.0004801390557210845\n",
      "train loss:6.237725152432543e-05\n",
      "train loss:0.005455307189877706\n",
      "train loss:0.00012932878962386855\n",
      "train loss:0.0008405936997870211\n",
      "train loss:0.0008284559201553341\n",
      "train loss:0.0001706246616984703\n",
      "train loss:0.0009730346300428975\n",
      "train loss:1.843527740797602e-05\n",
      "train loss:0.0011889729985727834\n",
      "train loss:0.000596315318741067\n",
      "train loss:0.0014706905869119303\n",
      "train loss:0.00013593079267659256\n",
      "train loss:0.0022845701665990896\n",
      "train loss:0.00017783436195266937\n",
      "train loss:0.00020629676593257877\n",
      "train loss:0.0022718203957360276\n",
      "train loss:0.0021339433850932504\n",
      "train loss:0.0011057115477692303\n",
      "train loss:0.0013327188968476431\n",
      "train loss:6.57327090116014e-05\n",
      "train loss:0.0014868036797226133\n",
      "train loss:0.00034269073923354107\n",
      "train loss:0.0001179613008555031\n",
      "train loss:9.56794918767824e-05\n",
      "train loss:0.0003920023645808543\n",
      "train loss:0.0002538311241229949\n",
      "train loss:0.0002359820932222404\n",
      "train loss:0.0010468346639095768\n",
      "train loss:0.004339060112683743\n",
      "train loss:0.0060754494682270736\n",
      "train loss:0.00047531581337809873\n",
      "train loss:0.0009618245061014628\n",
      "train loss:0.0003944000538628313\n",
      "train loss:0.0013680226186543582\n",
      "train loss:4.28705005100209e-05\n",
      "train loss:0.0013498513404320489\n",
      "train loss:0.00014518817786739614\n",
      "train loss:0.00014077671048378488\n",
      "train loss:0.0004661223743742702\n",
      "train loss:0.014772757832055948\n",
      "train loss:0.00011018153182014191\n",
      "train loss:0.0015735889364022248\n",
      "train loss:0.00040686376391415924\n",
      "train loss:0.006394444890536837\n",
      "train loss:0.0004573977840310147\n",
      "train loss:0.0029921303920849374\n",
      "train loss:0.0008939239578022991\n",
      "train loss:0.007666043090346481\n",
      "train loss:0.00020672627896914863\n",
      "train loss:0.000936833087687381\n",
      "train loss:0.00039039554392498505\n",
      "train loss:0.0008108280626872394\n",
      "train loss:0.0002769359545118276\n",
      "train loss:9.19249867152933e-05\n",
      "train loss:0.0008983394120785295\n",
      "train loss:0.0009413891027672258\n",
      "train loss:0.0033812003578278112\n",
      "train loss:0.002627810007870066\n",
      "train loss:0.0003020988398190242\n",
      "train loss:0.000746318166283128\n",
      "train loss:0.0007455603200463476\n",
      "train loss:0.01131705618421189\n",
      "train loss:0.005167642360520232\n",
      "train loss:0.0034287976327148904\n",
      "train loss:0.001700355956117193\n",
      "train loss:0.0022485878992346145\n",
      "train loss:0.0005473729507391608\n",
      "train loss:0.0011893138957051698\n",
      "train loss:0.0019286399873500362\n",
      "train loss:0.0033116961807629747\n",
      "train loss:0.0002297232349571502\n",
      "train loss:0.00011390349533152307\n",
      "train loss:0.0009118275291144248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004276303698338954\n",
      "train loss:0.0011297377730853527\n",
      "train loss:0.0003349841937928205\n",
      "train loss:0.011647335076800058\n",
      "train loss:0.000277060825793122\n",
      "train loss:0.0006405317712872738\n",
      "train loss:0.0004458179506216079\n",
      "train loss:0.000593636675403628\n",
      "train loss:0.0007864739666424085\n",
      "train loss:0.0012694215545094418\n",
      "train loss:0.0004855680968872257\n",
      "train loss:0.0032467121638085224\n",
      "train loss:0.001379866237267715\n",
      "train loss:0.003408758109280569\n",
      "train loss:0.0015698216447408695\n",
      "train loss:0.0001014024070217507\n",
      "train loss:0.0054806625875974515\n",
      "train loss:0.0006533580556079602\n",
      "train loss:0.0009578642649233074\n",
      "train loss:0.004552150940793899\n",
      "train loss:0.00028051912805189733\n",
      "train loss:0.00040136864248255943\n",
      "train loss:0.01931117635334902\n",
      "train loss:0.0001291864599529531\n",
      "train loss:0.000956832522014604\n",
      "train loss:0.0006639622081767971\n",
      "train loss:0.0013932445542121654\n",
      "train loss:0.0016169554212361948\n",
      "train loss:0.0013089923318637953\n",
      "train loss:0.0023646045703556748\n",
      "train loss:0.002082821236373416\n",
      "train loss:0.0008395152631015818\n",
      "train loss:0.0008297481036529776\n",
      "train loss:6.963611009691253e-05\n",
      "train loss:0.002244735182048235\n",
      "train loss:0.0012849726254244651\n",
      "train loss:0.0011781733888739042\n",
      "train loss:0.0005393452251915891\n",
      "train loss:0.002471049257918475\n",
      "train loss:0.00019259055213872712\n",
      "train loss:0.004038416870502407\n",
      "train loss:0.00034595480676936517\n",
      "train loss:3.550781111024514e-05\n",
      "train loss:0.0017495280086530609\n",
      "train loss:0.008486312051206358\n",
      "train loss:1.2511267082168318e-05\n",
      "train loss:0.00031203610750624606\n",
      "train loss:4.5425629241262644e-05\n",
      "train loss:0.002010019652055037\n",
      "train loss:0.002150360737785733\n",
      "train loss:0.0014044932753019053\n",
      "train loss:0.00042359818488313703\n",
      "train loss:0.0005286260256327071\n",
      "train loss:0.0036580343205561915\n",
      "train loss:0.00010482613100644196\n",
      "train loss:0.0004892924469986005\n",
      "train loss:0.004087416802522516\n",
      "train loss:0.0007511271091311369\n",
      "train loss:0.0014620871991158375\n",
      "train loss:0.00036213498598016954\n",
      "train loss:0.0001307857419908002\n",
      "train loss:0.00020420266440453235\n",
      "train loss:0.0011988988989733143\n",
      "train loss:6.774590907519088e-05\n",
      "train loss:0.0005608654824309563\n",
      "train loss:0.0006427911276276816\n",
      "train loss:0.002596111848707593\n",
      "train loss:0.005269181921947023\n",
      "train loss:0.0004872448396845099\n",
      "train loss:0.001009723369555972\n",
      "train loss:0.00015116848304460944\n",
      "train loss:0.0012243162631126472\n",
      "train loss:0.00206039846632517\n",
      "train loss:0.0007814749356137436\n",
      "train loss:0.002161073552014646\n",
      "train loss:0.0002349281542091336\n",
      "train loss:0.0016012360957269297\n",
      "train loss:0.003641444214232401\n",
      "train loss:3.767364760765881e-05\n",
      "train loss:0.00038060913852745455\n",
      "train loss:0.0019025155332452349\n",
      "train loss:0.0006957262664932741\n",
      "train loss:0.004443071563066367\n",
      "train loss:0.000282562129832383\n",
      "train loss:0.0009602481855149798\n",
      "train loss:0.0029437414707259085\n",
      "train loss:0.0023141902773644945\n",
      "train loss:0.0002364874127474902\n",
      "train loss:0.0033492633818400334\n",
      "train loss:0.00031299531839974157\n",
      "train loss:0.0009724481861507031\n",
      "train loss:0.0010824278392342498\n",
      "train loss:0.0010657372259265602\n",
      "train loss:0.0005171682386670831\n",
      "train loss:0.006450945029008377\n",
      "train loss:0.0012996578816517708\n",
      "train loss:0.0006857479000234529\n",
      "train loss:0.0009955498989261278\n",
      "train loss:0.00016144634022920124\n",
      "train loss:0.0024917134662660306\n",
      "train loss:6.359230482447859e-05\n",
      "train loss:0.0015201153663422834\n",
      "train loss:2.0494077109696863e-05\n",
      "train loss:0.0032406013267761748\n",
      "train loss:0.0022684879016801997\n",
      "train loss:0.003224978456291809\n",
      "train loss:0.0003827616359439568\n",
      "train loss:0.00028161679661919617\n",
      "train loss:0.0004230319270651264\n",
      "train loss:0.0011452469337039682\n",
      "train loss:0.0064482377776918665\n",
      "train loss:0.00028536707628076363\n",
      "train loss:0.00500847049875736\n",
      "train loss:4.914014773980648e-05\n",
      "train loss:0.0001911306241540741\n",
      "train loss:0.0012981771666520142\n",
      "train loss:0.027467478101435332\n",
      "train loss:0.0037987650669323992\n",
      "train loss:0.0030110799000415706\n",
      "train loss:0.00030418254020476906\n",
      "train loss:8.132215731857382e-05\n",
      "train loss:0.0017854798602073606\n",
      "train loss:0.014079508946567761\n",
      "train loss:0.0021257806137265213\n",
      "train loss:0.0006125246534266054\n",
      "train loss:0.0032327239625615733\n",
      "train loss:0.002254945694406988\n",
      "train loss:0.0009818738016556163\n",
      "train loss:0.0016856056493341558\n",
      "train loss:3.87758550767272e-05\n",
      "train loss:0.0002408592931610968\n",
      "train loss:0.0003144224488465009\n",
      "train loss:0.0014907426602503227\n",
      "train loss:0.0016206063188504282\n",
      "train loss:0.0004334195356790287\n",
      "train loss:0.008063864247264073\n",
      "train loss:7.519846186448766e-05\n",
      "train loss:0.003947577039565919\n",
      "train loss:1.6933405678897192e-05\n",
      "train loss:0.0004317110737831733\n",
      "train loss:0.0008598765165925233\n",
      "train loss:0.005192156633514534\n",
      "train loss:9.370566425347178e-05\n",
      "train loss:0.0016403265035887151\n",
      "train loss:0.00016020602633989408\n",
      "train loss:0.0013071226404355691\n",
      "=== epoch:20, train acc:0.997, test acc:0.981 ===\n",
      "train loss:0.0020232820915937334\n",
      "train loss:0.00022999474978864685\n",
      "train loss:0.0017659512391068866\n",
      "train loss:0.004908747374274885\n",
      "train loss:0.0023018536616766917\n",
      "train loss:0.01252073087877557\n",
      "train loss:0.006609908597133516\n",
      "train loss:0.00016889528628298383\n",
      "train loss:0.00035618235640304024\n",
      "train loss:0.00023733737035986922\n",
      "train loss:0.00036090556098640036\n",
      "train loss:0.0012757611823342302\n",
      "train loss:0.0003318319119571803\n",
      "train loss:0.002111700065438206\n",
      "train loss:0.0020968459942328913\n",
      "train loss:4.2728299546355515e-05\n",
      "train loss:0.0016421777616545444\n",
      "train loss:0.003313086838429133\n",
      "train loss:0.000701211280488705\n",
      "train loss:0.002545710924298278\n",
      "train loss:0.0011091057011303619\n",
      "train loss:0.0009036505554481666\n",
      "train loss:0.0037362567698849027\n",
      "train loss:0.002811919396617463\n",
      "train loss:0.001879034070376448\n",
      "train loss:0.002299722817036228\n",
      "train loss:0.0021119627388942815\n",
      "train loss:4.822437600616873e-05\n",
      "train loss:0.001653045180720127\n",
      "train loss:0.0002588848157563118\n",
      "train loss:0.0034531709354852285\n",
      "train loss:0.0014325124495349092\n",
      "train loss:9.300498077960138e-05\n",
      "train loss:0.0010627345326174981\n",
      "train loss:0.0008618202837091094\n",
      "train loss:0.0031797538472716556\n",
      "train loss:0.0020037573324328687\n",
      "train loss:0.002630008026040623\n",
      "train loss:0.00048538431396230093\n",
      "train loss:0.002672079314621081\n",
      "train loss:0.0005769457913446337\n",
      "train loss:0.004042934861338803\n",
      "train loss:0.0008001104952170346\n",
      "train loss:0.0011841626909152199\n",
      "train loss:0.0011609344314891317\n",
      "train loss:0.001306560218252099\n",
      "train loss:0.0006768721531790806\n",
      "train loss:0.00013296233269140023\n",
      "train loss:0.0009337255607416267\n",
      "train loss:0.0021338755889733305\n",
      "train loss:0.0005731133911392979\n",
      "train loss:0.0009077651798715679\n",
      "train loss:0.0014061062805423863\n",
      "train loss:0.001614358332514893\n",
      "train loss:0.00043769355399469334\n",
      "train loss:0.00015248513242602384\n",
      "train loss:0.00010089060272174665\n",
      "train loss:0.0002773943764893653\n",
      "train loss:0.0009065994511554449\n",
      "train loss:0.003187505070502679\n",
      "train loss:0.0016957032903963734\n",
      "train loss:0.00041669768543360094\n",
      "train loss:0.000651076964662502\n",
      "train loss:0.0025649013435876783\n",
      "train loss:0.0032822991301555944\n",
      "train loss:0.004477684197845683\n",
      "train loss:0.008944576616328984\n",
      "train loss:7.382524289905104e-05\n",
      "train loss:5.127185304650114e-05\n",
      "train loss:0.001447855757894929\n",
      "train loss:0.00014417746288709706\n",
      "train loss:0.0006547416472012165\n",
      "train loss:0.001236044604736724\n",
      "train loss:0.00025161095229682184\n",
      "train loss:0.0006367215567142208\n",
      "train loss:0.00030713130570653115\n",
      "train loss:0.001704378022671319\n",
      "train loss:0.001825362628065798\n",
      "train loss:0.0009112163171172863\n",
      "train loss:0.0005841811283736012\n",
      "train loss:0.004663329240620014\n",
      "train loss:0.0007623714966907409\n",
      "train loss:0.001490482111778704\n",
      "train loss:0.0028442704243467733\n",
      "train loss:0.002389207452242842\n",
      "train loss:0.0008524648858411748\n",
      "train loss:0.00014224694941866237\n",
      "train loss:8.885163680680672e-05\n",
      "train loss:0.0011160985118192142\n",
      "train loss:0.00027485238691713013\n",
      "train loss:0.0009318458467642085\n",
      "train loss:0.0025731700013047324\n",
      "train loss:0.00022362140375464722\n",
      "train loss:0.0007903590205221764\n",
      "train loss:0.000349854233478649\n",
      "train loss:0.00015907336395716676\n",
      "train loss:0.0014650835831596046\n",
      "train loss:0.00069557622514083\n",
      "train loss:0.00010154315216491169\n",
      "train loss:0.00011922043864128821\n",
      "train loss:4.6687119109920015e-05\n",
      "train loss:9.078129299760094e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00017473009620009997\n",
      "train loss:0.00011908870590612146\n",
      "train loss:0.0007480008664452079\n",
      "train loss:0.0018044940907628224\n",
      "train loss:0.0001351349179912681\n",
      "train loss:0.001024212768972235\n",
      "train loss:0.0006996614230433487\n",
      "train loss:0.00021656418433253265\n",
      "train loss:7.928205246347278e-05\n",
      "train loss:0.0001755749026293929\n",
      "train loss:0.0005692594164074762\n",
      "train loss:0.007343495896575089\n",
      "train loss:0.0002398891844848939\n",
      "train loss:0.0003980215463428447\n",
      "train loss:0.00020504158713374743\n",
      "train loss:0.0008930759103979735\n",
      "train loss:0.00029786608541185644\n",
      "train loss:0.001924316352522992\n",
      "train loss:0.0008221665226949193\n",
      "train loss:0.0012174105667411552\n",
      "train loss:7.694239372819673e-05\n",
      "train loss:0.0030267221877237752\n",
      "train loss:0.0007926210236625782\n",
      "train loss:0.0005279822546388005\n",
      "train loss:0.0005198670342907599\n",
      "train loss:9.113111081554532e-05\n",
      "train loss:0.0001518512970710401\n",
      "train loss:5.101211618050273e-05\n",
      "train loss:0.0011465759713828265\n",
      "train loss:0.00038686395054681534\n",
      "train loss:0.00026957977526179003\n",
      "train loss:0.010670250699104038\n",
      "train loss:0.0018200559461827113\n",
      "train loss:0.0023305153417442987\n",
      "train loss:0.00035323267426952957\n",
      "train loss:0.0010877025313529242\n",
      "train loss:0.000272063402023991\n",
      "train loss:0.00010316180919446161\n",
      "train loss:0.00021836024095192775\n",
      "train loss:0.0006112703070994541\n",
      "train loss:0.00045929700276391253\n",
      "train loss:0.0011800890112575663\n",
      "train loss:0.0008500071856310224\n",
      "train loss:0.0019432382902694798\n",
      "train loss:0.00037589923862264667\n",
      "train loss:0.0013117569303147424\n",
      "train loss:0.0006170828905657563\n",
      "train loss:0.00016632739225059284\n",
      "train loss:0.0001587696112379776\n",
      "train loss:0.0006402305668970045\n",
      "train loss:0.0001238189403279576\n",
      "train loss:0.0005843166067739996\n",
      "train loss:0.0003784641081887307\n",
      "train loss:0.0005285794696544561\n",
      "train loss:0.0004687595844862799\n",
      "train loss:0.0009106353640232495\n",
      "train loss:0.00017792375950769642\n",
      "train loss:0.0008120534201676335\n",
      "train loss:0.0009911328523933354\n",
      "train loss:0.0018398130151489258\n",
      "train loss:0.0011722898411809966\n",
      "train loss:0.0029536391048967155\n",
      "train loss:0.00021078314483163164\n",
      "train loss:0.000868765731237616\n",
      "train loss:0.0004955967029286856\n",
      "train loss:0.0003238689913481302\n",
      "train loss:0.0007200905977335086\n",
      "train loss:0.0003002132157222891\n",
      "train loss:0.00136005722423615\n",
      "train loss:0.0037770135109621516\n",
      "train loss:0.0002502827482800555\n",
      "train loss:0.0007272417360287051\n",
      "train loss:0.0009503637447215157\n",
      "train loss:0.0029979616531941563\n",
      "train loss:0.0002572629674811009\n",
      "train loss:0.00015324083039521794\n",
      "train loss:1.360635360287763e-05\n",
      "train loss:0.0015565789248254524\n",
      "train loss:0.003762648084540211\n",
      "train loss:0.0007457888585823841\n",
      "train loss:1.3518882892598012e-05\n",
      "train loss:0.000157616840157112\n",
      "train loss:0.0018127618204797815\n",
      "train loss:0.0001997236736560239\n",
      "train loss:0.000774718086306597\n",
      "train loss:0.00039245733852210485\n",
      "train loss:0.00014347795907029042\n",
      "train loss:0.0007774324965819867\n",
      "train loss:0.00013840600474982858\n",
      "train loss:0.0019326042150375484\n",
      "train loss:0.0028082496115312407\n",
      "train loss:0.0011226250719946827\n",
      "train loss:0.001871177213551901\n",
      "train loss:0.00010838806001413131\n",
      "train loss:0.00104994351949066\n",
      "train loss:0.001332997308630008\n",
      "train loss:0.0021409860793663127\n",
      "train loss:0.00033020101545666375\n",
      "train loss:0.0007805005316505757\n",
      "train loss:0.0008382896613709375\n",
      "train loss:0.0005266347958482105\n",
      "train loss:0.002063152670873304\n",
      "train loss:0.000966033512250156\n",
      "train loss:0.0010325523522317635\n",
      "train loss:0.000240533005746683\n",
      "train loss:0.0006134657073412077\n",
      "train loss:0.003022962315543476\n",
      "train loss:0.0018661587005956216\n",
      "train loss:6.317515757410928e-05\n",
      "train loss:0.0002106678671855729\n",
      "train loss:0.0021420682507982515\n",
      "train loss:0.0008227422592602459\n",
      "train loss:0.00030578984975654854\n",
      "train loss:6.838510072470614e-05\n",
      "train loss:0.0016118165481515412\n",
      "train loss:0.0002749339047631966\n",
      "train loss:0.002131062998333864\n",
      "train loss:0.008839824352936091\n",
      "train loss:0.0018800639809665465\n",
      "train loss:0.00014006705374112937\n",
      "train loss:0.000520706561844966\n",
      "train loss:5.5140134680382377e-05\n",
      "train loss:0.005673476968521518\n",
      "train loss:0.0005370182475361164\n",
      "train loss:0.0013308137917886448\n",
      "train loss:0.0007212242069244774\n",
      "train loss:0.0015448079273438318\n",
      "train loss:4.30985976166608e-05\n",
      "train loss:0.0003288459380013952\n",
      "train loss:0.0011667505879047857\n",
      "train loss:0.0012174079168285328\n",
      "train loss:0.0001183802337302612\n",
      "train loss:0.0001517120177974128\n",
      "train loss:0.00029133114839906586\n",
      "train loss:0.0003310661761517495\n",
      "train loss:0.00011889925455130946\n",
      "train loss:1.1095813539703677e-05\n",
      "train loss:0.0003896476039837074\n",
      "train loss:0.0023771526730108432\n",
      "train loss:0.0009616696032485541\n",
      "train loss:0.000752246573585148\n",
      "train loss:0.0005589354659032133\n",
      "train loss:0.0005998761513880047\n",
      "train loss:0.00035160786245590805\n",
      "train loss:0.00014719119107074462\n",
      "train loss:0.00031843857837832173\n",
      "train loss:6.448465311690213e-05\n",
      "train loss:0.001364484074794388\n",
      "train loss:0.001021446776161853\n",
      "train loss:3.3175792393124594e-06\n",
      "train loss:9.167610126255616e-05\n",
      "train loss:0.00025676856132955184\n",
      "train loss:4.573530104788463e-05\n",
      "train loss:3.735702636344135e-05\n",
      "train loss:1.2194903810051052e-05\n",
      "train loss:0.000211456157895012\n",
      "train loss:0.00016749290131732667\n",
      "train loss:0.0015010568002332778\n",
      "train loss:0.0010967648931508097\n",
      "train loss:0.00018241946526534686\n",
      "train loss:0.00018210002027399468\n",
      "train loss:0.00020140217873707003\n",
      "train loss:0.00026062388701194336\n",
      "train loss:2.4454369679247134e-05\n",
      "train loss:0.013491168320913835\n",
      "train loss:0.00010553921448757873\n",
      "train loss:0.00046708363553789453\n",
      "train loss:0.002048351310095964\n",
      "train loss:4.346248902556862e-05\n",
      "train loss:0.0018258713486284453\n",
      "train loss:0.0019601093650809705\n",
      "train loss:0.004678022475400642\n",
      "train loss:0.0008722976070262428\n",
      "train loss:0.021243522616724863\n",
      "train loss:0.0004875587269476391\n",
      "train loss:0.00042558637881246657\n",
      "train loss:0.0019769121749724375\n",
      "train loss:0.0002019140121253691\n",
      "train loss:0.0011966977456515824\n",
      "train loss:0.001181790869228386\n",
      "train loss:0.001684918901051811\n",
      "train loss:0.001103414593334294\n",
      "train loss:0.0010215781268294892\n",
      "train loss:0.0001569335458969997\n",
      "train loss:7.624268827631267e-05\n",
      "train loss:0.0032321681472546045\n",
      "train loss:1.9597829911431368e-05\n",
      "train loss:0.00039591773372975216\n",
      "train loss:0.002795128558590895\n",
      "train loss:0.0018342826071010765\n",
      "train loss:2.5384209866735572e-05\n",
      "train loss:0.003967113660778541\n",
      "train loss:0.0006160666316696917\n",
      "train loss:0.00021346659650961982\n",
      "train loss:6.259303854024528e-05\n",
      "train loss:0.0004214158093627559\n",
      "train loss:0.00023516463958072126\n",
      "train loss:0.0007238221295793424\n",
      "train loss:0.0012790244584184875\n",
      "train loss:0.0009045088443521053\n",
      "train loss:8.7325387075291e-05\n",
      "train loss:0.0001804501652336355\n",
      "train loss:0.0013459276540647039\n",
      "train loss:0.000714787364913914\n",
      "train loss:0.0002758038594612552\n",
      "train loss:0.00732464174564322\n",
      "train loss:0.0014669981938711545\n",
      "train loss:0.0008427888278647827\n",
      "train loss:0.00114248698233897\n",
      "train loss:5.213822891245991e-05\n",
      "train loss:9.440416872613277e-05\n",
      "train loss:0.00012777863851486256\n",
      "train loss:0.00020974334448349026\n",
      "train loss:4.985625541389006e-05\n",
      "train loss:8.576155451472909e-06\n",
      "train loss:0.0022322016207279665\n",
      "train loss:0.0013708688777562938\n",
      "train loss:0.00011227517988206983\n",
      "train loss:0.0011883429866012673\n",
      "train loss:0.00206401944769193\n",
      "train loss:0.0010501091766141383\n",
      "train loss:0.00018736531921572438\n",
      "train loss:0.00028797660271905366\n",
      "train loss:0.0010461389009692216\n",
      "train loss:0.0011020521009594084\n",
      "train loss:0.0011778743403919323\n",
      "train loss:0.0024791291461209327\n",
      "train loss:0.0001352751374227932\n",
      "train loss:0.004918566728993431\n",
      "train loss:0.00011364430918719844\n",
      "train loss:0.0011586676022929258\n",
      "train loss:0.000493338557738006\n",
      "train loss:4.2546375550903576e-05\n",
      "train loss:0.001023613321410718\n",
      "train loss:0.0014602578554400525\n",
      "train loss:0.0011583482467440495\n",
      "train loss:0.0015013045710657238\n",
      "train loss:0.0009808282325471187\n",
      "train loss:0.00037316326794772307\n",
      "train loss:0.0017796970580571262\n",
      "train loss:0.001511792855734611\n",
      "train loss:0.0003070471796780917\n",
      "train loss:5.0305810501344174e-05\n",
      "train loss:0.000788092104561107\n",
      "train loss:0.0019371116261707366\n",
      "train loss:0.0004507860893577141\n",
      "train loss:0.001903311897909773\n",
      "train loss:0.003127330082575734\n",
      "train loss:0.00039721512016465814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007959956263159175\n",
      "train loss:0.00595309893474839\n",
      "train loss:0.002727991120534462\n",
      "train loss:0.0006692485455785752\n",
      "train loss:0.0015313320305381268\n",
      "train loss:7.919041023957662e-06\n",
      "train loss:0.007800707072381207\n",
      "train loss:0.00025749465808415806\n",
      "train loss:0.0007359881646277513\n",
      "train loss:0.003662206880403596\n",
      "train loss:0.0010902012399076316\n",
      "train loss:0.010317467478435836\n",
      "train loss:0.00011700124140274843\n",
      "train loss:4.4539544457817394e-05\n",
      "train loss:0.0005314569081122201\n",
      "train loss:0.0013884395911510073\n",
      "train loss:0.0042462682007635985\n",
      "train loss:5.337359475601939e-05\n",
      "train loss:5.685839963876012e-05\n",
      "train loss:0.0022819651815052726\n",
      "train loss:0.0012436711623518741\n",
      "train loss:6.134660022058178e-05\n",
      "train loss:0.0020140228058979056\n",
      "train loss:0.00013301750270584706\n",
      "train loss:0.010093447714653637\n",
      "train loss:0.002217018439286725\n",
      "train loss:0.00014970074140008163\n",
      "train loss:0.002881162609775374\n",
      "train loss:0.0015160939119991809\n",
      "train loss:0.014878331613215215\n",
      "train loss:0.00048386358935383734\n",
      "train loss:0.0009029307484401578\n",
      "train loss:1.1721695281492919e-05\n",
      "train loss:0.0001792339331590447\n",
      "train loss:3.574731197156186e-05\n",
      "train loss:0.0003577762439551695\n",
      "train loss:0.0003715149426927132\n",
      "train loss:0.00032783353770350057\n",
      "train loss:0.0002256689209820409\n",
      "train loss:0.0001547374056640007\n",
      "train loss:0.001888580557073554\n",
      "train loss:0.02314062311780988\n",
      "train loss:0.002042216328690225\n",
      "train loss:0.02892726055232483\n",
      "train loss:0.0029485118739884155\n",
      "train loss:0.00046455230193048514\n",
      "train loss:0.0007059838939119711\n",
      "train loss:0.00032233274384008213\n",
      "train loss:0.002277197342555852\n",
      "train loss:0.004954572820759112\n",
      "train loss:0.00028275201591235904\n",
      "train loss:0.024517515571373903\n",
      "train loss:0.000625964922760765\n",
      "train loss:0.0012445071301696983\n",
      "train loss:0.00670772543548781\n",
      "train loss:0.0005607184709395347\n",
      "train loss:0.00035935460211807685\n",
      "train loss:0.000192573921659287\n",
      "train loss:0.0019253810279302357\n",
      "train loss:0.0009300459930800703\n",
      "train loss:0.0003302341620572574\n",
      "train loss:0.0009680379045353177\n",
      "train loss:0.003314946969271319\n",
      "train loss:0.0004957671366928084\n",
      "train loss:0.0006531291566935448\n",
      "train loss:0.0022292459340900912\n",
      "train loss:0.000540629858933294\n",
      "train loss:0.0006032314651367404\n",
      "train loss:0.0033867313827182217\n",
      "train loss:0.00011062121557972971\n",
      "train loss:0.0014100876078743574\n",
      "train loss:0.0012116880781472504\n",
      "train loss:0.0005721609836152896\n",
      "train loss:0.003924588328623632\n",
      "train loss:0.0013164013370336933\n",
      "train loss:0.000576402647167399\n",
      "train loss:0.0002289987963763501\n",
      "train loss:0.00022106954787304203\n",
      "train loss:0.002790622045946786\n",
      "train loss:0.0024791055072239253\n",
      "train loss:7.97553421511198e-05\n",
      "train loss:0.0008339294766869579\n",
      "train loss:0.0009601157395721694\n",
      "train loss:0.001449480479119126\n",
      "train loss:0.0003527413087069417\n",
      "train loss:0.0031266507386643856\n",
      "train loss:0.00015001028268858392\n",
      "train loss:0.0003596959223539805\n",
      "train loss:0.0013110136144862694\n",
      "train loss:0.00048063611473907224\n",
      "train loss:0.00020900037556250163\n",
      "train loss:0.0015787884233948435\n",
      "train loss:5.0389847088106495e-05\n",
      "train loss:0.00017720067023563893\n",
      "train loss:0.002805586138651203\n",
      "train loss:0.003112499421679465\n",
      "train loss:0.0026354444325759076\n",
      "train loss:0.0010063488844474487\n",
      "train loss:2.1132571110813535e-05\n",
      "train loss:0.001319950673519312\n",
      "train loss:6.863413137105539e-05\n",
      "train loss:0.00038683445848835423\n",
      "train loss:0.0002723039260025443\n",
      "train loss:0.0007083088463881884\n",
      "train loss:0.0017085681951396542\n",
      "train loss:0.0005557071464786152\n",
      "train loss:0.0016229185373304368\n",
      "train loss:0.001211402466720315\n",
      "train loss:0.004152603235266047\n",
      "train loss:0.0004570457561675244\n",
      "train loss:0.00017312233030241072\n",
      "train loss:0.0009468524119739596\n",
      "train loss:0.00012344250687162074\n",
      "train loss:5.094540881705774e-05\n",
      "train loss:0.00024326402408761323\n",
      "train loss:0.0003224803215123126\n",
      "train loss:0.013099458283657208\n",
      "train loss:0.0004899001899949075\n",
      "train loss:0.0003016168562477442\n",
      "train loss:0.0013568938600701558\n",
      "train loss:0.0008246331191490447\n",
      "train loss:0.002427404547793915\n",
      "train loss:0.0005602280207399315\n",
      "train loss:0.0025855590776269373\n",
      "train loss:0.007857836600872619\n",
      "train loss:0.00020020085783266982\n",
      "train loss:0.001622311394262498\n",
      "train loss:0.0008133953462500995\n",
      "train loss:0.0007380822543247485\n",
      "train loss:0.0020076035562884027\n",
      "train loss:0.00022404140418773977\n",
      "train loss:0.00021202065092248103\n",
      "train loss:0.00019795176666809056\n",
      "train loss:0.0007722999958509886\n",
      "train loss:0.001248447935568375\n",
      "train loss:0.000671733102601364\n",
      "train loss:0.0022287896696089188\n",
      "train loss:0.0005531073745456068\n",
      "train loss:0.00017069939036346214\n",
      "train loss:0.001981114546275647\n",
      "train loss:0.0004110491515643264\n",
      "train loss:0.002138914112901941\n",
      "train loss:0.0005981658595724124\n",
      "train loss:0.0019203817773517128\n",
      "train loss:0.011185303031663008\n",
      "train loss:0.004485684574984325\n",
      "train loss:0.000781912496241258\n",
      "train loss:0.0021919968770864806\n",
      "train loss:0.00016413828948575504\n",
      "train loss:0.00010852196708395564\n",
      "train loss:0.0002092999663510689\n",
      "train loss:0.0012598262653399815\n",
      "train loss:0.00046484412484786887\n",
      "train loss:0.00026489960107677817\n",
      "train loss:0.001003364937900591\n",
      "train loss:0.00038291081696425843\n",
      "train loss:0.002050368847819649\n",
      "train loss:6.15059374534199e-05\n",
      "train loss:0.013881878101680432\n",
      "train loss:0.006794600676111243\n",
      "train loss:0.0015533106651373445\n",
      "train loss:0.0006409031512500252\n",
      "train loss:0.0003849524219658583\n",
      "train loss:8.269117547115011e-05\n",
      "train loss:7.849424610346889e-05\n",
      "train loss:0.0017093324857424372\n",
      "train loss:0.0003192206045093068\n",
      "train loss:0.0003343909871604632\n",
      "train loss:0.004076893279372603\n",
      "train loss:0.00016317154010376977\n",
      "train loss:0.00017073998473836238\n",
      "train loss:0.00013062837500615594\n",
      "train loss:6.950343092820518e-05\n",
      "train loss:0.00012717444352009535\n",
      "train loss:0.0018480624159098982\n",
      "train loss:0.0005594621137298819\n",
      "train loss:0.0007007809904185948\n",
      "train loss:0.00022793093124453677\n",
      "train loss:0.0004891100366579287\n",
      "train loss:0.0016440580071309882\n",
      "train loss:0.0006742425308013048\n",
      "train loss:0.0034397552574183974\n",
      "train loss:0.0016746276379983576\n",
      "train loss:0.00031797698237430146\n",
      "train loss:0.001107584207372273\n",
      "train loss:0.0005481592678611051\n",
      "train loss:0.003979052781113842\n",
      "train loss:0.00020795630415348506\n",
      "train loss:0.000995899469070842\n",
      "train loss:0.0002951988249384015\n",
      "train loss:0.0010789410214465233\n",
      "train loss:0.0006433439515675598\n",
      "train loss:0.004766802796517051\n",
      "train loss:0.0038857218704350404\n",
      "train loss:0.0015187918424807323\n",
      "train loss:0.00014261245041408946\n",
      "train loss:0.00022842921330505715\n",
      "train loss:0.001932302547226988\n",
      "train loss:6.210309809162709e-05\n",
      "train loss:9.106226825400174e-05\n",
      "train loss:0.003486772359313866\n",
      "train loss:0.0011715000403429792\n",
      "train loss:0.0006272506835358494\n",
      "train loss:0.000233647385654194\n",
      "train loss:0.0029469406696629894\n",
      "train loss:0.0011345398720217928\n",
      "train loss:0.0002614533553250289\n",
      "train loss:6.598522101067952e-05\n",
      "train loss:0.0007834297921073298\n",
      "train loss:0.0005462294286666368\n",
      "train loss:0.001122170311843542\n",
      "train loss:0.0011775307416854103\n",
      "train loss:0.001568441760770134\n",
      "train loss:0.0016500906141330228\n",
      "train loss:6.0089249961253946e-05\n",
      "train loss:0.0036170781592776086\n",
      "train loss:0.00037510830470564215\n",
      "train loss:0.0004353857298872114\n",
      "train loss:0.00029840863384241573\n",
      "train loss:0.00019520971055969505\n",
      "train loss:0.003711242517529396\n",
      "train loss:0.0006282455926890827\n",
      "train loss:6.552604123195448e-05\n",
      "train loss:0.0003047621212184368\n",
      "train loss:7.398178620067957e-05\n",
      "train loss:0.0001480531471175995\n",
      "train loss:0.00019986006679079577\n",
      "train loss:0.0007066042691697018\n",
      "train loss:8.610630378751963e-05\n",
      "train loss:0.013219973874313506\n",
      "train loss:0.000714176485592436\n",
      "train loss:0.00028584678188860424\n",
      "train loss:0.000201193452142863\n",
      "train loss:0.0012670069235455079\n",
      "train loss:0.0003751134757313559\n",
      "train loss:1.5541592909542517e-05\n",
      "train loss:0.00048426714530602473\n",
      "train loss:0.0016670523215150351\n",
      "train loss:0.002220478313223158\n",
      "train loss:0.0015320013744955718\n",
      "train loss:0.0016123678941654404\n",
      "train loss:0.0006932287682498751\n",
      "train loss:0.00011200565397111619\n",
      "train loss:0.00024317743682399518\n",
      "train loss:0.0003169086137114608\n",
      "train loss:0.0012454869943620123\n",
      "train loss:0.00014328392034388014\n",
      "train loss:0.00045976972110590053\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9883\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from DLfromscratch.dataset.mnist import load_mnist\n",
    "from DLfromscratch.common.trainer import Trainer\n",
    "from DLfromscratch.ch07.simple_convnet import SimpleConvNet as SCN\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SCN(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
